#!/usr/bin/env python3
"""
Ralph Wiggum - Autonomous AI Development Loop
https://ghuntley.com/ralph/

Usage: ralph [command] [options]
  ralph              - Construct mode, unlimited iterations
  ralph 10           - Construct mode, max 10 iterations
  ralph plan         - Plan mode, generate implementation plan
  ralph init         - Initialize ralph in current repo
  ralph status       - Show current status
  ralph validate     - Check plan.jsonl for dangling deps and other issues
  ralph compact      - Convert legacy accepted tasks to tombstones
  ralph watch        - Live dashboard with cost tracking

Options:
  --profile, -p PROFILE    Cost profile: budget, balanced, hybrid, cost_smart, quality
  --max-cost N             Stop when cumulative cost exceeds $N
  --max-failures N         Circuit breaker: stop after N consecutive failures (default: 3)
  --timeout N              Kill iteration after N milliseconds (default: 900000)
  --context-limit N        Context window size in tokens (default: 200000)
  --completion-promise T   Stop when output contains TEXT

Cost Profiles (use --profile or RALPH_PROFILE env var):
  opus   - Full power, best results (use when you have quota)
  sonnet - Balanced fallback (when Opus quota exhausted)
  haiku  - Budget mode (Haiku for BUILD, Sonnet for reasoning stages)
  
  If no profile is specified, you will be prompted to select one.
  Skip the prompt by setting --profile <name> or RALPH_PROFILE=<name>.
  
  Example: ralph -p haiku 50
           RALPH_PROFILE=sonnet ralph

Safety Features:
  - Iterations are killed if they exceed the timeout (prevents stuck agents)
  - Iterations are killed if context usage exceeds 80% (prevents context overflow)
  - A warning is shown when context usage exceeds 50%
  - After a kill, the next iteration receives guidance to break down the problem
"""

import argparse
import io
import json
import os
import re
import select
import stat
import subprocess
import sys
import threading
import time
from collections import deque
from contextlib import redirect_stdout
from dataclasses import dataclass, field
from datetime import datetime
from enum import Enum, auto
from pathlib import Path
from typing import Optional, Callable

# Textual TUI framework (lazy import to avoid startup penalty for non-TUI commands)
_textual_available = None
def _check_textual():
    global _textual_available
    if _textual_available is None:
        try:
            import textual
            _textual_available = True
        except ImportError:
            _textual_available = False
    return _textual_available


# =============================================================================
# Global Configuration System
# =============================================================================
# Config file location: ~/.config/ralph/config.toml
# Supports profiles for different environments (work, home, etc.)
#
# Example config.toml:
#   [default]
#   model = "anthropic/claude-sonnet-4"
#   
#   [profiles.work]
#   model = "anthropic/claude-opus-4"
#   
#   [profiles.home]
#   model = "openrouter/anthropic/claude-opus-4"
#   provider = "openrouter"
#
# Set RALPH_PROFILE=work to use a specific profile

@dataclass
class GlobalConfig:
    """Global Ralph configuration loaded from ~/.config/ralph/config.toml
    
    Model Selection
    ===============
    - model: Main model for reasoning stages (INVESTIGATE, VERIFY, DECOMPOSE, PLAN)
             Also used as fallback when BUILD struggles
    - model_build: Fast/cheap model for BUILD stage
    
    No hardcoded defaults - config.toml is required.
    """
    # Models - must be set via config.toml
    model: str = ''  # Main model for reasoning + fallback
    model_build: str = ''  # Fast model for BUILD
    
    # Context limits
    context_window: int = 200_000
    context_warn_pct: int = 70
    context_compact_pct: int = 85
    context_kill_pct: int = 95
    
    # Timeouts (milliseconds)
    stage_timeout_ms: int = 900_000  # 15 minutes
    iteration_timeout_ms: int = 900_000  # 15 minutes
    
    # Circuit breaker
    max_failures: int = 3
    
    # Decomposition
    max_decompose_depth: int = 3
    
    # Git settings
    commit_prefix: str = 'ralph:'
    recent_commits_display: int = 3
    
    # UI settings
    art_style: str = 'braille'
    dashboard_buffer_lines: int = 2000
    
    # Directories (relative to repo root, or absolute)
    ralph_dir: str = 'ralph'
    log_dir: str = '/tmp/ralph-logs'
    
    # Profile name (for display/debugging)
    _profile_name: str = 'default'

    @classmethod
    def load(cls) -> 'GlobalConfig':
        """Load config from ~/.config/ralph/config.toml with profile support."""
        config_path = Path.home() / '.config' / 'ralph' / 'config.toml'
        
        if not config_path.exists():
            return cls()
        
        try:
            import tomllib
        except ImportError:
            # Python < 3.11 fallback
            try:
                import tomli as tomllib
            except ImportError:
                # No TOML parser available, use defaults
                return cls()
        
        try:
            with open(config_path, 'rb') as f:
                data = tomllib.load(f)
        except Exception:
            return cls()
        
        # Config priority:
        # 1. Top-level keys (not in [default] or [profiles])
        # 2. [default] section (deprecated, for backward compat)
        # 3. RALPH_PROFILE overlay (if set)
        config_dict = {}
        
        # First, load top-level keys (excluding 'profiles' and 'default' sections)
        for key, value in data.items():
            if key not in ('profiles', 'default') and not isinstance(value, dict):
                config_dict[key] = value
        
        # Then overlay [default] section if it exists (backward compat)
        if 'default' in data:
            config_dict.update(data['default'])
        
        # Apply profile if RALPH_PROFILE is set
        profile_name = os.environ.get('RALPH_PROFILE', '')
        if profile_name and 'profiles' in data and profile_name in data['profiles']:
            config_dict.update(data['profiles'][profile_name])
            config_dict['_profile_name'] = profile_name
        
        # Also check RALPH_ART_STYLE env var for backward compatibility
        if 'RALPH_ART_STYLE' in os.environ:
            config_dict['art_style'] = os.environ['RALPH_ART_STYLE']
        
        # Build config object
        return cls(**{k: v for k, v in config_dict.items() if hasattr(cls, k) or k.startswith('_')})


# Global singleton - loaded once at import time
_global_config: Optional[GlobalConfig] = None

def get_global_config() -> GlobalConfig:
    """Get the global configuration singleton."""
    global _global_config
    if _global_config is None:
        _global_config = GlobalConfig.load()
    return _global_config


def reload_global_config() -> GlobalConfig:
    """Force reload of global configuration."""
    global _global_config
    _global_config = GlobalConfig.load()
    return _global_config


# Colors
class Colors:
    RED = '\033[0;31m'
    GREEN = '\033[0;32m'
    YELLOW = '\033[1;33m'
    BLUE = '\033[0;34m'
    MAGENTA = '\033[0;35m'
    CYAN = '\033[0;36m'
    WHITE = '\033[0;37m'
    NC = '\033[0m'  # No Color
    
    # Extended colors for Ralph ASCII art
    BRIGHT_YELLOW = '\033[93m'
    BRIGHT_RED = '\033[91m'
    BRIGHT_WHITE = '\033[97m'
    BRIGHT_BLUE = '\033[94m'
    BRIGHT_MAGENTA = '\033[95m'
    DIM = '\033[2m'
    PINK = '\033[38;5;218m'
    SKIN = '\033[38;5;223m'
    HAIR = '\033[38;5;220m'
    SHIRT_BLUE = '\033[38;5;39m'
    SHIRT_DARK = '\033[38;5;25m'


# =============================================================================
# Context and Timeout Limits
# =============================================================================
# These are now loaded from global config, but we keep module-level constants
# for backward compatibility. They're initialized lazily on first access.

def _get_default_context_window():
    return get_global_config().context_window

def _get_context_soft_limit_pct():
    return get_global_config().context_warn_pct

def _get_context_compact_limit_pct():
    return get_global_config().context_compact_pct

def _get_context_hard_limit_pct():
    return get_global_config().context_kill_pct

def _get_default_stage_timeout_ms():
    return get_global_config().stage_timeout_ms

def _get_default_iteration_timeout_ms():
    return get_global_config().iteration_timeout_ms

# Legacy constants (kept for backward compatibility in code that imports them directly)
DEFAULT_CONTEXT_WINDOW = 200_000
CONTEXT_SOFT_LIMIT_PCT = 70
CONTEXT_COMPACT_LIMIT_PCT = 85
CONTEXT_HARD_LIMIT_PCT = 95
DEFAULT_STAGE_TIMEOUT_MS = 900000  # 15 minutes
DEFAULT_ITERATION_TIMEOUT_MS = 900000  # 15 minutes

# Skeleton animation frames - pulsing bar for waiting indicator
SKELETON_FRAMES = [
    "\033[90m‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë\033[0m",
    "\033[90m‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë\033[0m",
    "\033[90m‚ñì‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë\033[0m",
    "\033[90m‚ñí‚ñì‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë\033[0m",
    "\033[90m‚ñë‚ñí‚ñì‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë\033[0m",
    "\033[90m‚ñë‚ñë‚ñí‚ñì‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë\033[0m",
    "\033[90m‚ñë‚ñë‚ñë‚ñí‚ñì‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë\033[0m",
    "\033[90m‚ñë‚ñë‚ñë‚ñë‚ñí‚ñì‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë\033[0m",
    "\033[90m‚ñë‚ñë‚ñë‚ñë‚ñë‚ñí‚ñì‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë\033[0m",
    "\033[90m‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñí‚ñì‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë\033[0m",
    "\033[90m‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñí‚ñì‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë\033[0m",
    "\033[90m‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñí‚ñì‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë\033[0m",
    "\033[90m‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñí‚ñì‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë\033[0m",
    "\033[90m‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñí‚ñì‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë\033[0m",
    "\033[90m‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñí‚ñì‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë\033[0m",
    "\033[90m‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñí‚ñì‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë\033[0m",
    "\033[90m‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñí‚ñì‚ñà‚ñë‚ñë‚ñë‚ñë\033[0m",
    "\033[90m‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñí‚ñì‚ñà‚ñë‚ñë‚ñë\033[0m",
    "\033[90m‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñí‚ñì‚ñà‚ñë‚ñë\033[0m",
    "\033[90m‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñí‚ñì‚ñà‚ñë\033[0m",
    "\033[90m‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñí‚ñì‚ñà\033[0m",
    "\033[90m‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñí‚ñì\033[0m",
    "\033[90m‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñí\033[0m",
    "\033[90m‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë\033[0m",
]


# =============================================================================
# Ralph Wiggum ASCII Art Options
# =============================================================================
# Art style can be set via config file or RALPH_ART_STYLE environment variable:
#   - "braille" (default): Braille dot art with colored regions (11 lines)
#   - "braille_full": Full-body braille art (15 lines, includes legs)
#   - "blocks": Block art using ‚ñë‚ñí‚ñì‚ñà characters (11 lines)
#   - "minimal": Simple/minimal text art (5 lines)
#   - "none": No art displayed

def _colorize_art(raw_lines, color_map_list, color_codes):
    """Build colored art lines from raw art and color map."""
    result = []
    for line_idx, line in enumerate(raw_lines):
        if line_idx >= len(color_map_list):
            result.append(line + Colors.NC)
            continue
        colored_line = ""
        colors = color_map_list[line_idx]
        for start, end, color_name in colors:
            segment = line[start:end]
            colored_line += f"{color_codes.get(color_name, '')}{segment}"
        colored_line += Colors.NC
        result.append(colored_line)
    return result

# Color code mapping
_COLOR_CODES = {
    'HAIR': Colors.HAIR,
    'SKIN': Colors.SKIN,
    'SHIRT_BLUE': Colors.SHIRT_BLUE,
    'NC': Colors.NC,
}

# -----------------------------------------------------------------------------
# Style 1: Braille dot art (default) - compact upper body
# -----------------------------------------------------------------------------
_BRAILLE_RAW = [
    "‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚£Ä‚£§‚£∂‚°∂‚¢õ‚†ü‚°ø‚†ª‚¢ª‚¢ø‚¢∂‚¢¶‚£Ñ‚°Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä",
    "‚†Ä‚†Ä‚†Ä‚¢Ä‚£†‚°æ‚°´‚¢ä‚†å‚°ê‚¢°‚†ä‚¢∞‚†Å‚°é‚†ò‚°Ñ‚¢¢‚†ô‚°õ‚°∑‚¢§‚°Ä‚†Ä‚†Ä‚†Ä",
    "‚†Ä‚†Ä‚¢†‚¢™‚¢ã‚°û‚¢†‚†É‚°ú‚†Ä‚†é‚†Ä‚†â‚†Ä‚†É‚†Ä‚†É‚†Ä‚†É‚†ô‚†ò‚†ä‚¢ª‚†¶‚†Ä‚†Ä",
    "‚†Ä‚†Ä‚¢á‚°á‚°ú‚†Ä‚†ú‚†Ä‚†Å‚†Ä‚¢Ä‚†î‚†â‚†â‚†ë‚†Ñ‚†Ä‚†Ä‚°∞‚†ä‚†â‚†ë‚°Ñ‚°á‚†Ä‚†Ä",
    "‚†Ä‚†Ä‚°∏‚†ß‚†Ñ‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†ò‚°Ä‚†æ‚†Ä‚†Ä‚£∏‚†Ä‚†Ä‚¢ß‚†Ä‚†õ‚†Ä‚†å‚°á‚†Ä‚†Ä",
    "‚†Ä‚†ò‚°á‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†ô‚†í‚†í‚†ö‚†Å‚†à‚†â‚†≤‚°ç‚†í‚†à‚†Ä‚°á‚†Ä‚†Ä",
    "‚†Ä‚†Ä‚†à‚†≤‚£Ü‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚£†‚†ñ‚†â‚°π‚†§‚†∂‚†Å‚†Ä‚†Ä‚†Ä‚†à‚¢¶‚†Ä",
    "‚†Ä‚†Ä‚†Ä‚†Ä‚†à‚£¶‚°Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†ß‚£¥‚†Å‚†Ä‚†ò‚†ì‚¢≤‚£Ñ‚£Ä‚£Ä‚£Ä‚°§‚†î‚†É‚†Ä",
    "‚†Ä‚†Ä‚†Ä‚†Ä‚£ú‚†Ä‚†à‚†ì‚†¶‚¢Ñ‚£Ä‚£Ä‚£∏‚†Ä‚†Ä‚†Ä‚†Ä‚†Å‚¢à‚¢á‚£º‚°Å‚†Ä‚†Ä‚†Ä‚†Ä",
    "‚†Ä‚†Ä‚¢†‚†í‚†õ‚†≤‚£Ñ‚†Ä‚†Ä‚†Ä‚£†‚†è‚†Ä‚†â‚†≤‚£§‚†Ä‚¢∏‚†ã‚¢ª‚£§‚°õ‚£Ñ‚†Ä‚†Ä‚†Ä",
    "‚†Ä‚†Ä‚¢°‚†Ä‚†Ä‚†Ä‚†Ä‚†â‚¢≤‚†æ‚†Å‚†Ä‚†Ä‚†Ä‚†Ä‚†à‚¢≥‚°æ‚£§‚†ü‚†Å‚†π‚£ø‚¢Ü‚†Ä‚†Ä",
]
_BRAILLE_COLORS = [
    [(0, 26, 'HAIR')],
    [(0, 26, 'HAIR')],
    [(0, 26, 'HAIR')],
    [(0, 5, 'HAIR'), (5, 22, 'SKIN'), (22, 26, 'HAIR')],
    [(0, 5, 'HAIR'), (5, 22, 'SKIN'), (22, 26, 'HAIR')],
    [(0, 3, 'HAIR'), (3, 22, 'SKIN'), (22, 26, 'HAIR')],
    [(0, 26, 'SKIN')],
    [(0, 26, 'SKIN')],
    [(0, 10, 'SKIN'), (10, 17, 'SHIRT_BLUE'), (17, 26, 'SKIN')],
    [(0, 2, 'SKIN'), (2, 26, 'SHIRT_BLUE')],
    [(0, 26, 'SHIRT_BLUE')],
]
_BRAILLE_WIDTH = 26

# -----------------------------------------------------------------------------
# Style 2: Full-body braille art (from emojicombos.com)
# -----------------------------------------------------------------------------
_BRAILLE_FULL_RAW = [
    "‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚£Ä‚£§‚£∂‚°∂‚¢õ‚†ü‚°ø‚†ª‚¢ª‚¢ø‚¢∂‚¢¶‚£Ñ‚°Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä",
    "‚†Ä‚†Ä‚†Ä‚¢Ä‚£†‚°æ‚°´‚¢ä‚†å‚°ê‚¢°‚†ä‚¢∞‚†Å‚°é‚†ò‚°Ñ‚¢¢‚†ô‚°õ‚°∑‚¢§‚°Ä‚†Ä‚†Ä‚†Ä",
    "‚†Ä‚†Ä‚¢†‚¢™‚¢ã‚°û‚¢†‚†É‚°ú‚†Ä‚†é‚†Ä‚†â‚†Ä‚†É‚†Ä‚†É‚†Ä‚†É‚†ô‚†ò‚†ä‚¢ª‚†¶‚†Ä‚†Ä",
    "‚†Ä‚†Ä‚¢á‚°á‚°ú‚†Ä‚†ú‚†Ä‚†Å‚†Ä‚¢Ä‚†î‚†â‚†â‚†ë‚†Ñ‚†Ä‚†Ä‚°∞‚†ä‚†â‚†ë‚°Ñ‚°á‚†Ä‚†Ä",
    "‚†Ä‚†Ä‚°∏‚†ß‚†Ñ‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†ò‚°Ä‚†æ‚†Ä‚†Ä‚£∏‚†Ä‚†Ä‚¢ß‚†Ä‚†õ‚†Ä‚†å‚°á‚†Ä‚†Ä",
    "‚†Ä‚†ò‚°á‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†ô‚†í‚†í‚†ö‚†Å‚†à‚†â‚†≤‚°ç‚†í‚†à‚†Ä‚°á‚†Ä‚†Ä",
    "‚†Ä‚†Ä‚†à‚†≤‚£Ü‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚£†‚†ñ‚†â‚°π‚†§‚†∂‚†Å‚†Ä‚†Ä‚†Ä‚†à‚¢¶‚†Ä",
    "‚†Ä‚†Ä‚†Ä‚†Ä‚†à‚£¶‚°Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†ß‚£¥‚†Å‚†Ä‚†ò‚†ì‚¢≤‚£Ñ‚£Ä‚£Ä‚£Ä‚°§‚†î‚†É‚†Ä",
    "‚†Ä‚†Ä‚†Ä‚†Ä‚£ú‚†Ä‚†à‚†ì‚†¶‚¢Ñ‚£Ä‚£Ä‚£∏‚†Ä‚†Ä‚†Ä‚†Ä‚†Å‚¢à‚¢á‚£º‚°Å‚†Ä‚†Ä‚†Ä‚†Ä",
    "‚†Ä‚†Ä‚¢†‚†í‚†õ‚†≤‚£Ñ‚†Ä‚†Ä‚†Ä‚£†‚†è‚†Ä‚†â‚†≤‚£§‚†Ä‚¢∏‚†ã‚¢ª‚£§‚°õ‚£Ñ‚†Ä‚†Ä‚†Ä",
    "‚†Ä‚†Ä‚¢°‚†Ä‚†Ä‚†Ä‚†Ä‚†â‚¢≤‚†æ‚†Å‚†Ä‚†Ä‚†Ä‚†Ä‚†à‚¢≥‚°æ‚£§‚†ü‚†Å‚†π‚£ø‚¢Ü‚†Ä‚†Ä",
    "‚†Ä‚¢Ä‚†º‚£Ü‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚£º‚†É‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†à‚£ß‚†Ä",
    "‚†Ä‚°è‚†Ä‚†ò‚¢¶‚°Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚£†‚†û‚†Å‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚¢∏‚£ß",
    "‚¢∞‚£Ñ‚†Ä‚†Ä‚†Ä‚†â‚†≥‚†¶‚£§‚£§‚°§‚†¥‚†ñ‚†ã‚†Å‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚¢Ø",
    "‚¢∏‚£â‚†â‚†ì‚†≤‚¢¶‚£§‚£Ñ‚£Ä‚£Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚¢Ä‚£Ä‚£Ä‚£Ä‚£†‚£º",
]
_BRAILLE_FULL_COLORS = [
    [(0, 26, 'HAIR')],
    [(0, 26, 'HAIR')],
    [(0, 26, 'HAIR')],
    [(0, 5, 'HAIR'), (5, 22, 'SKIN'), (22, 26, 'HAIR')],
    [(0, 5, 'HAIR'), (5, 22, 'SKIN'), (22, 26, 'HAIR')],
    [(0, 3, 'HAIR'), (3, 22, 'SKIN'), (22, 26, 'HAIR')],
    [(0, 26, 'SKIN')],
    [(0, 26, 'SKIN')],
    [(0, 10, 'SKIN'), (10, 17, 'SHIRT_BLUE'), (17, 26, 'SKIN')],
    [(0, 2, 'SKIN'), (2, 26, 'SHIRT_BLUE')],
    [(0, 26, 'SHIRT_BLUE')],
    [(0, 26, 'SHIRT_BLUE')],
    [(0, 26, 'SHIRT_BLUE')],
    [(0, 26, 'SHIRT_BLUE')],
    [(0, 26, 'SHIRT_BLUE')],
]
_BRAILLE_FULL_WIDTH = 30

# -----------------------------------------------------------------------------
# Style 3: Block art (using ‚ñë‚ñí‚ñì‚ñà characters)
# -----------------------------------------------------------------------------
_BLOCKS_RAW = [
    "   ‚ñì‚ñë  ‚ñì  ‚ñë‚ñì   ",
    "  ‚ñì‚ñì‚ñì‚ñì‚ñì‚ñì‚ñì‚ñì‚ñì‚ñì‚ñì  ",
    " ‚ñì‚ñì‚ñí‚ñí‚ñí‚ñí‚ñí‚ñí‚ñí‚ñí‚ñí‚ñì‚ñì ",
    " ‚ñì‚ñí‚ñí‚ñí‚ñí‚ñí‚ñí‚ñí‚ñí‚ñí‚ñí‚ñí‚ñì ",
    " ‚ñì‚ñí ‚óè‚ñí‚ñí‚ñí‚ñí‚ñí‚óè ‚ñí‚ñì ",
    " ‚ñì‚ñí‚ñí‚ñí‚ñí o ‚ñí‚ñí‚ñí‚ñí‚ñì ",
    " ‚ñì‚ñí‚ñí ~~~~~ ‚ñí‚ñí‚ñì ",
    " ‚ñì‚ñí‚ñí‚ñí‚ñí‚ñí‚ñí‚ñí‚ñí‚ñí‚ñí‚ñí‚ñì ",
    "  ‚ñì‚ñì‚ñí‚ñí‚ñí‚ñí‚ñí‚ñí‚ñí‚ñì‚ñì  ",
    "   ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà ",
    "   ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   ",
]
_BLOCKS_COLORS = [
    [(0, 15, 'HAIR')],                                           # hair spikes
    [(0, 15, 'HAIR')],                                           # hair band
    [(0, 3, 'HAIR'), (3, 12, 'SKIN'), (12, 15, 'HAIR')],         # forehead
    [(0, 2, 'HAIR'), (2, 13, 'SKIN'), (13, 15, 'HAIR')],         # face
    [(0, 2, 'HAIR'), (2, 13, 'SKIN'), (13, 15, 'HAIR')],         # eyes
    [(0, 2, 'HAIR'), (2, 13, 'SKIN'), (13, 15, 'HAIR')],         # nose
    [(0, 2, 'HAIR'), (2, 13, 'SKIN'), (13, 15, 'HAIR')],         # mouth
    [(0, 2, 'HAIR'), (2, 13, 'SKIN'), (13, 15, 'HAIR')],         # chin
    [(0, 3, 'HAIR'), (3, 12, 'SKIN'), (12, 15, 'HAIR')],         # jaw
    [(0, 15, 'SHIRT_BLUE')],                                     # shirt
    [(0, 15, 'SHIRT_BLUE')],                                     # shirt
]
_BLOCKS_WIDTH = 18

# -----------------------------------------------------------------------------
# Style 4: Minimal text art
# -----------------------------------------------------------------------------
_MINIMAL_RAW = [
    f"{Colors.HAIR}  .-~~~-.  {Colors.NC}",
    f"{Colors.HAIR} /  {Colors.SKIN}o o{Colors.HAIR}  \\ {Colors.NC}",
    f"{Colors.SKIN}|    <    |{Colors.NC}",
    f"{Colors.SKIN} \\  ===  / {Colors.NC}",
    f"{Colors.SHIRT_BLUE}  '-----'  {Colors.NC}",
]
_MINIMAL_COLORS = []  # Pre-colored
_MINIMAL_WIDTH = 14

# -----------------------------------------------------------------------------
# Build the active art based on environment variable
# -----------------------------------------------------------------------------
def _get_ralph_art():
    """Get Ralph art based on RALPH_ART_STYLE environment variable."""
    style = os.environ.get('RALPH_ART_STYLE', 'braille').lower()
    
    if style == 'none':
        return [], 0
    elif style == 'braille_full':
        return _colorize_art(_BRAILLE_FULL_RAW, _BRAILLE_FULL_COLORS, _COLOR_CODES), _BRAILLE_FULL_WIDTH
    elif style == 'blocks':
        return _colorize_art(_BLOCKS_RAW, _BLOCKS_COLORS, _COLOR_CODES), _BLOCKS_WIDTH
    elif style == 'minimal':
        return _MINIMAL_RAW, _MINIMAL_WIDTH  # Already colored
    else:  # default: braille
        return _colorize_art(_BRAILLE_RAW, _BRAILLE_COLORS, _COLOR_CODES), _BRAILLE_WIDTH

RALPH_ART, RALPH_WIDTH = _get_ralph_art()


@dataclass
class Metrics:
    """In-memory metrics for the current session."""
    total_cost: float = 0.0
    total_iterations: int = 0
    total_tokens_in: int = 0
    total_tokens_out: int = 0
    failures: int = 0
    successes: int = 0
    kills_timeout: int = 0
    kills_context: int = 0
    started_at: Optional[str] = None
    last_kill_reason: str = ""  # "timeout" or "context_limit"
    last_kill_activity: str = ""  # What agent was doing when killed


@dataclass
class IterationKillInfo:
    """Information about why an iteration was killed."""
    reason: str  # "timeout", "context_limit", "compaction_failed", or "none"
    task_name: Optional[str] = None
    tokens_used: int = 0
    context_limit: int = 0
    timeout_seconds: int = 0
    elapsed_seconds: int = 0
    last_activity: Optional[str] = None  # What the agent was doing when killed
    
    def to_prompt_injection(self) -> str:
        """Generate prompt text to inject into the next iteration."""
        if self.reason == "none":
            return ""
        
        lines = [
            "# CRITICAL: Previous Iteration Failed",
            "",
        ]
        
        if self.reason == "timeout":
            lines.extend([
                f"The previous iteration was KILLED after {self.elapsed_seconds}s (timeout: {self.timeout_seconds}s).",
                f"Task: {self.task_name or 'unknown'}",
                "",
                f"Last activity before kill: {self.last_activity or 'unknown'}",
                "",
                "## Required Actions:",
                "1. DO NOT repeat the same approach - it will fail again",
                "2. Break down the problem into SMALLER steps",
                "3. If investigating code, use targeted searches instead of reading entire files",
                "4. If the task is too complex, create sub-tasks using `ralph task add`",
                "5. Complete ONE small step, then EXIT to let the next iteration continue",
                "",
            ])
        elif self.reason == "context_limit" or self.reason == "compaction_failed":
            pct_used = (self.tokens_used / self.context_limit * 100) if self.context_limit > 0 else 0
            reason_text = "compaction failed (still >80% after attempt)" if self.reason == "compaction_failed" else "context overflow"
            lines.extend([
                f"The previous iteration was KILLED due to {reason_text} ({self.tokens_used:,} tokens, {pct_used:.0f}% of {self.context_limit:,} limit).",
                f"Task: {self.task_name or 'unknown'}",
                "",
                f"Last activity before kill: {self.last_activity or 'unknown'}",
                "",
                "## Required Actions - YOU MUST USE SUBAGENTS:",
                "",
                "You are reading too much code directly. USE THE TASK TOOL to spawn subagents:",
                "",
                "```",
                'Task: "Research how [X] works in this codebase. Find the relevant files, understand the implementation, and report back: 1) which files, 2) how it works, 3) what needs to change"',
                "```",
                "",
                "Each subagent gets a FRESH context window. Spawn multiple subagents in parallel for different research questions.",
                "",
                "DO NOT:",
                "- Read files directly (use subagents)",
                "- Explore broadly (be specific in subagent prompts)", 
                "- Try to understand everything at once",
                "",
                "DO:",
                "- Spawn a subagent for each research question",
                "- Wait for subagent results before proceeding",
                "- Make targeted edits based on subagent findings",
                "",
            ])
        
        lines.append("---\n")
        return "\n".join(lines)


@dataclass
class ToolSummaries:
    """Summarized tool activity from conversation."""
    files_read: dict  # path -> summary of content
    files_edited: list  # paths that were edited
    searches_performed: list  # list of search summaries
    tests_run: list  # test execution summaries
    subagents_spawned: list  # task summaries


@dataclass
class CompactedContext:
    """Compacted context for resuming execution after context pressure."""
    task_name: str
    task_notes: Optional[str]
    task_accept: Optional[str]
    progress_summary: str
    uncommitted_changes: str
    key_files: list
    blockers: list
    next_step: str
    key_decisions: list
    tool_summaries: Optional[ToolSummaries] = None
    
    def to_prompt(self) -> str:
        """Generate the compacted context prompt for resumption."""
        lines = [
            "=== COMPACTED CONTEXT ===",
            "",
            f"Task: {self.task_name}",
            "",
        ]
        
        if self.task_notes:
            lines.append(f"Notes: {self.task_notes}")
            lines.append("")
        
        if self.task_accept:
            lines.append(f"Accept criteria: {self.task_accept}")
            lines.append("")
        
        lines.extend([
            f"Progress: {self.progress_summary}",
            "",
            f"Current state: Execution was compacted due to context pressure",
            "",
        ])
        
        if self.key_files:
            lines.append(f"Key files: {', '.join(self.key_files)}")
            lines.append("")
        
        if self.uncommitted_changes:
            lines.extend([
                "Uncommitted changes:",
                "```",
                self.uncommitted_changes[:2000],  # Truncate to avoid bloating context
                "```" if len(self.uncommitted_changes) <= 2000 else "``` (truncated)",
                "",
            ])
        
        if self.blockers:
            lines.append(f"Blockers: {'; '.join(self.blockers)}")
            lines.append("")
        
        if self.key_decisions:
            lines.append("Key decisions made:")
            for decision in self.key_decisions:
                lines.append(f"  - {decision}")
            lines.append("")
        
        if self.tool_summaries:
            ts = self.tool_summaries
            
            if ts.searches_performed:
                lines.append("Exploration performed:")
                for search in ts.searches_performed[:10]:
                    lines.append(f"  - {search}")
                lines.append("")
            
            if ts.files_read:
                lines.append("Files read:")
                for path, summary in list(ts.files_read.items())[:15]:
                    lines.append(f"  - {path}: {summary}")
                lines.append("")
            
            if ts.files_edited:
                lines.append(f"Files edited: {', '.join(ts.files_edited[:20])}")
                lines.append("")
            
            if ts.tests_run:
                lines.append("Tests run:")
                for test in ts.tests_run[:5]:
                    lines.append(f"  - {test}")
                lines.append("")
            
            if ts.subagents_spawned:
                lines.append("Subagent tasks:")
                for task in ts.subagents_spawned[:10]:
                    lines.append(f"  - {task}")
                lines.append("")
        
        lines.extend([
            f"Next step: {self.next_step}",
            "",
            "=== END COMPACTED ===",
            "",
            "## IMPORTANT: You are resuming from a compacted context",
            "",
            "The previous execution was stopped due to context pressure. Your context has been compacted.",
            "Continue from where you left off. Do NOT re-explore the codebase - use the information above.",
            "",
            "If you need to explore more code, use subagents (Task tool) to avoid filling context again.",
            "",
        ])
        
        return "\n".join(lines)


def capture_uncommitted_changes(repo_root: Path) -> str:
    """Capture git diff of uncommitted changes (staged + unstaged)."""
    try:
        # Get combined diff of staged and unstaged changes
        result = subprocess.run(
            ['git', 'diff', 'HEAD'],
            capture_output=True, text=True, cwd=repo_root, timeout=10
        )
        if result.returncode == 0 and result.stdout.strip():
            return result.stdout.strip()
        
        # If no HEAD diff, try just unstaged
        result = subprocess.run(
            ['git', 'diff'],
            capture_output=True, text=True, cwd=repo_root, timeout=10
        )
        return result.stdout.strip() if result.returncode == 0 else ""
    except (subprocess.TimeoutExpired, Exception):
        return ""


def extract_key_files_from_diff(diff_text: str) -> list:
    """Extract file paths from a git diff."""
    files = []
    for line in diff_text.split('\n'):
        if line.startswith('diff --git a/'):
            # Extract path from "diff --git a/path b/path"
            parts = line.split(' ')
            if len(parts) >= 3:
                path = parts[2][2:]  # Remove "a/" prefix
                files.append(path)
    return files[:10]  # Limit to 10 most relevant files


def _strip_ansi(text: str) -> str:
    """Remove ANSI escape codes from text."""
    return re.sub(r'\x1b\[[0-9;]*m', '', text)


def _extract_tool_summaries(output_text: str) -> ToolSummaries:
    """Extract detailed summaries of tool usage from output.
    
    Parses the formatted tool output (with emojis and ANSI codes) to produce
    detailed summaries for:
    - Exploration results (glob, grep)
    - Code reads (file contents)
    - Test execution (bash tests)
    - File edits
    - Subagent tasks
    """
    lines = output_text.split('\n')
    
    files_read = {}  # path -> summary
    files_edited = []
    searches_performed = []
    tests_run = []
    subagents_spawned = []
    
    i = 0
    while i < len(lines):
        line = _strip_ansi(lines[i])
        
        # Glob: üìÅ Glob: <pattern>
        if 'üìÅ' in line and 'Glob:' in line:
            pattern_match = re.search(r'Glob:\s*(.+)', line)
            pattern = pattern_match.group(1).strip() if pattern_match else "?"
            
            # Look for result count in next few lines
            file_count = 0
            for j in range(i+1, min(i+5, len(lines))):
                next_line = _strip_ansi(lines[j])
                count_match = re.search(r'\((\d+)\s*(?:files?|matches?|lines?)\)', next_line)
                if count_match:
                    file_count = int(count_match.group(1))
                    break
                # Check for "Found X" pattern
                found_match = re.search(r'Found\s+(\d+)', next_line)
                if found_match:
                    file_count = int(found_match.group(1))
                    break
            
            if file_count > 0:
                searches_performed.append(f"Glob '{pattern}': found {file_count} files")
            else:
                searches_performed.append(f"Glob '{pattern}'")
        
        # Grep: üîç Grep: <pattern>
        elif 'üîç' in line and 'Grep:' in line:
            pattern_match = re.search(r'Grep:\s*(.+)', line)
            pattern = pattern_match.group(1).strip() if pattern_match else "?"
            
            # Look for result count in next few lines
            match_count = 0
            for j in range(i+1, min(i+5, len(lines))):
                next_line = _strip_ansi(lines[j])
                count_match = re.search(r'\((\d+)\s*(?:files?|matches?|lines?)\)', next_line)
                if count_match:
                    match_count = int(count_match.group(1))
                    break
                found_match = re.search(r'Found\s+(\d+)', next_line)
                if found_match:
                    match_count = int(found_match.group(1))
                    break
            
            if match_count > 0:
                searches_performed.append(f"Grep '{pattern}': found {match_count} matches")
            else:
                searches_performed.append(f"Grep '{pattern}'")
        
        # Read: üìñ Read: <path>
        elif 'üìñ' in line and 'Read:' in line:
            path_match = re.search(r'Read:\s*(.+)', line)
            path = path_match.group(1).strip() if path_match else "?"
            
            # Try to extract meaningful summary from context
            filename = os.path.basename(path)
            ext = os.path.splitext(path)[1].lower()
            
            summary = _infer_file_summary(path, ext, lines, i)
            files_read[path] = summary
        
        # Edit: ‚úèÔ∏è Edit: <path>
        elif '‚úèÔ∏è' in line and 'Edit:' in line:
            path_match = re.search(r'Edit:\s*(.+)', line)
            path = path_match.group(1).strip() if path_match else "?"
            if path not in files_edited:
                files_edited.append(path)
        
        # Write: üìù Write: <path>
        elif 'üìù' in line and 'Write:' in line:
            path_match = re.search(r'Write:\s*(.+)', line)
            path = path_match.group(1).strip() if path_match else "?"
            if path not in files_edited:
                files_edited.append(path)
        
        # Bash: ‚ö° Bash: <cmd>
        elif '‚ö°' in line and 'Bash:' in line:
            cmd_match = re.search(r'Bash:\s*(.+)', line)
            cmd = cmd_match.group(1).strip() if cmd_match else ""
            
            # Check if this is a test command
            test_cmds = ['test', 'pytest', 'jest', 'npm test', 'npm run test', 'cargo test', 
                        'go test', 'make test', 'unittest', 'vitest', 'mocha']
            is_test = any(tc in cmd.lower() for tc in test_cmds)
            
            if is_test:
                # Try to extract test results from subsequent lines
                test_result = _extract_test_results(lines, i)
                if test_result:
                    tests_run.append(test_result)
                else:
                    tests_run.append(f"Ran: {cmd[:60]}")
        
        # Task: ü§ñ Task: <description>
        elif 'ü§ñ' in line and 'Task:' in line:
            desc_match = re.search(r'Task:\s*(.+)', line)
            desc = desc_match.group(1).strip() if desc_match else "?"
            subagents_spawned.append(desc[:80])
        
        i += 1
    
    return ToolSummaries(
        files_read=files_read,
        files_edited=files_edited,
        searches_performed=searches_performed,
        tests_run=tests_run,
        subagents_spawned=subagents_spawned
    )


def _infer_file_summary(path: str, ext: str, lines: list, start_idx: int) -> str:
    """Infer a summary of file contents based on context and path."""
    filename = os.path.basename(path)
    
    # Look at assistant text after the read for clues
    for j in range(start_idx + 1, min(start_idx + 20, len(lines))):
        text = _strip_ansi(lines[j]).lower()
        
        # Look for function/class mentions
        func_match = re.search(r'(?:exports?|defines?|contains?|implements?)\s+(?:functions?|methods?|classes?)?\s*[`\']?(\w+)[`\']?', text)
        if func_match:
            return f"contains {func_match.group(0)[:50]}"
        
        # Look for "X functions" or "X classes" pattern
        count_match = re.search(r'(\d+)\s+(functions?|classes?|methods?|components?)', text)
        if count_match:
            return f"{count_match.group(1)} {count_match.group(2)}"
    
    # Fallback: describe by file type
    type_hints = {
        '.ts': 'TypeScript source',
        '.tsx': 'React component',
        '.js': 'JavaScript source', 
        '.jsx': 'React component',
        '.py': 'Python source',
        '.go': 'Go source',
        '.rs': 'Rust source',
        '.md': 'documentation',
        '.json': 'config/data',
        '.yaml': 'config',
        '.yml': 'config',
        '.css': 'styles',
        '.scss': 'styles',
        '.html': 'HTML template',
    }
    
    return type_hints.get(ext, 'source file')


def _extract_test_results(lines: list, start_idx: int) -> Optional[str]:
    """Extract test results summary from output following a test command."""
    for j in range(start_idx + 1, min(start_idx + 50, len(lines))):
        text = _strip_ansi(lines[j])
        
        # Common test result patterns
        # pytest: "5 passed, 2 failed"
        pytest_match = re.search(r'(\d+)\s*passed(?:.*?(\d+)\s*failed)?', text, re.IGNORECASE)
        if pytest_match:
            passed = pytest_match.group(1)
            failed = pytest_match.group(2) or "0"
            return f"{passed} passed, {failed} failed"
        
        # Jest/vitest: "Tests: 5 passed, 2 failed"
        jest_match = re.search(r'Tests?:\s*(\d+)\s*passed,?\s*(\d+)\s*failed', text, re.IGNORECASE)
        if jest_match:
            return f"{jest_match.group(1)} passed, {jest_match.group(2)} failed"
        
        # Generic: "X tests passed" or "all tests passed"
        generic_match = re.search(r'(\d+|all)\s*tests?\s*passed', text, re.IGNORECASE)
        if generic_match:
            return f"{generic_match.group(1)} tests passed"
        
        # Failure only: "X failed"
        fail_match = re.search(r'(\d+)\s*(?:tests?\s*)?failed', text, re.IGNORECASE)
        if fail_match and int(fail_match.group(1)) > 0:
            return f"{fail_match.group(1)} tests failed"
        
        # OK pattern (unittest)
        if re.search(r'\bOK\b', text) and 'test' in text.lower():
            return "all tests passed"
        
        # FAILED pattern
        if 'FAILED' in text and 'test' in text.lower():
            return "tests failed"
    
    return None


def extract_progress_from_output(output_text: str) -> tuple[str, str, list, list]:
    """Extract progress summary, next step hints, blockers, and key decisions from output.
    
    Returns: (progress_summary, next_step, blockers, key_decisions)
    """
    lines = output_text.split('\n')
    
    # Look for progress markers
    progress_hints = []
    blockers = []
    last_activities = []
    key_decisions = []
    
    for line in lines:  # Scan entire output for decisions
        # Capture key decision markers (case-insensitive)
        if '[ralph] decision:' in line.lower():
            # Extract decision text after the marker
            marker_idx = line.lower().find('[ralph] decision:')
            decision_text = line[marker_idx + len('[ralph] decision:'):].strip()
            if decision_text:
                key_decisions.append(decision_text[:300])  # Limit length
    
    for line in lines[-200:]:  # Check last 200 lines for recent activity
        lower_line = line.lower()
        
        # Capture progress markers
        if '[ralph]' in lower_line and ('start' in lower_line or 'done' in lower_line):
            progress_hints.append(line.strip())
        
        # Capture error/blocker indicators
        if 'error' in lower_line or 'failed' in lower_line or 'exception' in lower_line:
            blockers.append(line.strip()[:200])
        
        # Capture recent tool activities
        if any(marker in lower_line for marker in ['running', 'editing', 'reading', 'writing', 'searching']):
            last_activities.append(line.strip()[:100])
    
    # Build progress summary
    if progress_hints:
        progress = progress_hints[-1]  # Most recent progress
    else:
        progress = "In progress (no explicit markers found)"
    
    # Build next step hint from last activities
    if last_activities:
        next_step = f"Was working on: {last_activities[-1]}"
    else:
        next_step = "Continue implementing the task"
    
    # Limit blockers and decisions
    blockers = blockers[-3:] if blockers else []
    key_decisions = key_decisions[-10:] if key_decisions else []  # Keep last 10 decisions
    
    return progress, next_step, blockers, key_decisions


def build_compacted_context(
    task: 'Task',
    repo_root: Path,
    output_text: str
) -> CompactedContext:
    """Build a compacted context for resumption after context pressure."""
    
    # Capture uncommitted changes
    uncommitted = capture_uncommitted_changes(repo_root)
    
    # Extract key files from the diff
    key_files = extract_key_files_from_diff(uncommitted)
    
    # Extract progress from output
    progress, next_step, blockers, key_decisions = extract_progress_from_output(output_text)
    
    # Extract detailed tool summaries
    tool_summaries = _extract_tool_summaries(output_text)
    
    return CompactedContext(
        task_name=task.name,
        task_notes=task.notes,
        task_accept=task.accept,
        progress_summary=progress,
        uncommitted_changes=uncommitted,
        key_files=key_files,
        blockers=blockers,
        next_step=next_step,
        key_decisions=key_decisions,
        tool_summaries=tool_summaries
    )


@dataclass
class RalphConfig:
    repo_root: Path
    ralph_dir: Path
    log_dir: Path
    prompt_plan: Path
    prompt_build: Path
    prompt_verify: Path
    prompt_investigate: Path
    prompt_decompose: Path
    specs_dir: Path
    output_fifo: Path
    plan_file: Path
    runtime_file: Path

    @classmethod
    def from_repo(cls, repo_root: Path, spec_name: str = None) -> 'RalphConfig':
        ralph_dir = repo_root / 'ralph'
        
        # Organize logs by repo/branch/spec
        # e.g., /tmp/ralph-logs/neo-mittens/main/ralph-refactor/
        repo_name = repo_root.name
        
        # Get current branch
        try:
            result = subprocess.run(
                ['git', 'branch', '--show-current'],
                cwd=repo_root, capture_output=True, text=True
            )
            branch = result.stdout.strip() or 'detached'
        except Exception:
            branch = 'unknown'
        
        # Auto-detect spec from plan.jsonl if not provided
        if not spec_name:
            plan_file = ralph_dir / 'plan.jsonl'
            if plan_file.exists():
                try:
                    for line in plan_file.read_text().splitlines():
                        if line.strip():
                            d = json.loads(line)
                            if d.get("t") == "spec" and d.get("spec"):
                                spec_name = d["spec"]
                                break
                except (json.JSONDecodeError, IOError):
                    pass
        
        if spec_name:
            # Strip .md extension if present
            spec_name = spec_name.replace('.md', '')
            log_dir = Path('/tmp/ralph-logs') / repo_name / branch / spec_name
        else:
            log_dir = Path('/tmp/ralph-logs') / repo_name / branch
        
        return cls(
            repo_root=repo_root,
            ralph_dir=ralph_dir,
            log_dir=log_dir,
            prompt_plan=ralph_dir / 'PROMPT_plan.md',
            prompt_build=ralph_dir / 'PROMPT_build.md',
            prompt_verify=ralph_dir / 'PROMPT_verify.md',
            prompt_investigate=ralph_dir / 'PROMPT_investigate.md',
            prompt_decompose=ralph_dir / 'PROMPT_decompose.md',
            specs_dir=ralph_dir / 'specs',
            output_fifo=log_dir / 'output.fifo',
            plan_file=ralph_dir / 'plan.jsonl',
            runtime_file=ralph_dir / '.runtime',
        )


# =============================================================================
# Runtime State (ephemeral, not committed)
# =============================================================================

def write_runtime_iteration(config: RalphConfig, iteration: int):
    """Write current iteration number to runtime file."""
    config.runtime_file.write_text(str(iteration))


def read_runtime_iteration(config: RalphConfig) -> Optional[int]:
    """Read current iteration number from runtime file, or None if not running."""
    if config.runtime_file.exists():
        try:
            return int(config.runtime_file.read_text().strip())
        except (ValueError, IOError):
            return None
    return None


def clear_runtime_state(config: RalphConfig):
    """Clear runtime state file (call when construct mode exits)."""
    if config.runtime_file.exists():
        config.runtime_file.unlink()


# =============================================================================
# State Management (JSONL-based)
# =============================================================================
# 
# plan.jsonl format - each line is an independent record:
#   {"t": "spec", "spec": "coverage.md"}
#   {"t": "task", "id": "t-xxxx", "desc": "...", "s": "p"}        # pending
#   {"t": "task", "id": "t-yyyy", "desc": "...", "s": "d", "done_at": "abc"}  # done
#   {"t": "issue", "id": "i-zzzz", "desc": "..."}
#
# Benefits: Git-friendly merges (line-based), clean diffs, no conflicts on parallel adds

def _generate_id(prefix: str = 't') -> str:
    """Generate a unique ID with timestamp and random suffix to reduce collisions.
    
    Format: {prefix}-{timestamp_base36}{random} (e.g., t-k5x9ab, i-k5x9cd)
    
    The timestamp component (2 chars) provides uniqueness across time,
    while the random suffix (4 chars) provides uniqueness within the same second.
    This reduces collision probability when multiple Ralph instances run in parallel.
    """
    import random
    import string
    import time
    
    chars = string.ascii_lowercase + string.digits
    # Use last 2 chars of base36 timestamp for some time-based uniqueness
    timestamp_part = int(time.time()) % (36 * 36)  # 0-1295, fits in 2 base36 chars
    ts_chars = ""
    for _ in range(2):
        ts_chars = chars[timestamp_part % 36] + ts_chars
        timestamp_part //= 36
    
    # Add 4 random chars
    random_part = ''.join(random.choice(chars) for _ in range(4))
    return f"{prefix}-{ts_chars}{random_part}"


@dataclass
class Task:
    id: str
    name: str  # Short task name (what to do)
    spec: str  # Spec file this task belongs to
    notes: Optional[str] = None  # Implementation notes/context (how to do it)
    accept: Optional[str] = None  # Acceptance criteria / test plan (how to verify)
    deps: Optional[list] = None  # List of task IDs this depends on
    status: str = "p"  # "p" = pending, "d" = done
    done_at: Optional[str] = None  # Commit hash when marked done
    needs_decompose: bool = False  # True if task was killed and needs breakdown
    kill_reason: Optional[str] = None  # "timeout" or "context" if killed
    kill_log: Optional[str] = None  # Path to log file from killed iteration
    priority: Optional[str] = None  # "high", "medium", or "low"
    reject_reason: Optional[str] = None  # Why task was rejected by VERIFY (if retrying)
    # Relationship tracking
    parent: Optional[str] = None  # Task ID this was decomposed from (DECOMPOSE stage)
    created_from: Optional[str] = None  # Issue ID this task was created from (INVESTIGATE stage)
    supersedes: Optional[str] = None  # Task ID this replaces (when rejection leads to new approach)
    decompose_depth: int = 0  # How many times this task's lineage has been decomposed (max 3)
    timeout_ms: Optional[int] = None  # Per-task timeout override (None = use stage default)
    
    def to_jsonl(self) -> str:
        d = {"t": "task", "id": self.id, "spec": self.spec, "name": self.name, "s": self.status}
        if self.notes:
            d["notes"] = self.notes
        if self.accept:
            d["accept"] = self.accept
        if self.deps:
            d["deps"] = self.deps
        if self.done_at:
            d["done_at"] = self.done_at
        if self.needs_decompose:
            d["decompose"] = True
        if self.kill_reason:
            d["kill"] = self.kill_reason
        if self.kill_log:
            d["kill_log"] = self.kill_log
        if self.priority:
            d["priority"] = self.priority
        if self.reject_reason:
            d["reject"] = self.reject_reason
        if self.parent:
            d["parent"] = self.parent
        if self.created_from:
            d["created_from"] = self.created_from
        if self.supersedes:
            d["supersedes"] = self.supersedes
        if self.decompose_depth > 0:
            d["decompose_depth"] = self.decompose_depth
        if self.timeout_ms is not None:
            d["timeout_ms"] = self.timeout_ms
        return json.dumps(d)
    
    @classmethod
    def from_jsonl(cls, d: dict) -> 'Task':
        # Support legacy 'desc' field as 'name'
        name = d.get("name") or d.get("desc", "")
        return cls(
            id=d["id"], 
            name=name,
            spec=d.get("spec", ""),  # Empty for legacy tasks
            notes=d.get("notes"),
            accept=d.get("accept"),
            deps=d.get("deps"),
            status=d.get("s", "p"),
            done_at=d.get("done_at"),
            needs_decompose=d.get("decompose", False),
            kill_reason=d.get("kill"),
            kill_log=d.get("kill_log"),
            priority=d.get("priority"),
            reject_reason=d.get("reject"),
            parent=d.get("parent"),
            created_from=d.get("created_from"),
            supersedes=d.get("supersedes"),
            decompose_depth=d.get("decompose_depth", 0),
            timeout_ms=d.get("timeout_ms")
        )


@dataclass 
class Issue:
    id: str
    desc: str
    spec: str  # Spec file this issue belongs to
    priority: Optional[str] = None  # Priority: high, medium, low - inherited by tasks created from this issue
    
    def to_jsonl(self) -> str:
        d = {"t": "issue", "id": self.id, "spec": self.spec, "desc": self.desc}
        if self.priority:
            d["priority"] = self.priority
        return json.dumps(d)
    
    @classmethod
    def from_jsonl(cls, d: dict) -> 'Issue':
        return cls(id=d["id"], desc=d["desc"], spec=d.get("spec", ""), priority=d.get("priority"))


@dataclass
class Tombstone:
    id: str  # Task ID that was accepted/rejected
    done_at: str  # Commit hash where task was marked done
    reason: str  # Why the task was rejected, or accept criteria for accepted
    tombstone_type: str = "reject"  # "accept" or "reject"
    name: str = ""  # Task name (preserved for display)
    timestamp: Optional[str] = None  # ISO timestamp when tombstone was created
    changed_files: Optional[list] = None  # List of files changed in the commit
    log_file: Optional[str] = None  # Path to log file (for rejected tasks)
    iteration: Optional[int] = None  # Which iteration number (for debugging)
    notes: Optional[str] = None  # Original task notes (preserved for context)
    
    def to_jsonl(self) -> str:
        d = {"t": self.tombstone_type, "id": self.id, "done_at": self.done_at, "reason": self.reason}
        if self.name:
            d["name"] = self.name
        if self.timestamp:
            d["timestamp"] = self.timestamp
        if self.changed_files:
            d["changed_files"] = self.changed_files
        if self.log_file:
            d["log_file"] = self.log_file
        if self.iteration is not None:
            d["iteration"] = self.iteration
        if self.notes:
            d["notes"] = self.notes
        return json.dumps(d)
    
    @classmethod
    def from_jsonl(cls, d: dict, tombstone_type: str = "reject") -> 'Tombstone':
        return cls(
            id=d["id"], 
            done_at=d["done_at"], 
            reason=d.get("reason", ""), 
            tombstone_type=tombstone_type, 
            name=d.get("name", ""),
            timestamp=d.get("timestamp"),
            changed_files=d.get("changed_files"),
            log_file=d.get("log_file"),
            iteration=d.get("iteration"),
            notes=d.get("notes")
        )


@dataclass
class RalphPlanConfig:
    """Configuration from plan.jsonl config record."""
    timeout_ms: int = 900000  # 15 min default
    max_iterations: int = 10
    context_warn: float = 0.70
    context_compact: float = 0.85
    context_kill: float = 0.95
    
    def to_jsonl(self) -> str:
        return json.dumps({
            "t": "config",
            "timeout_ms": self.timeout_ms,
            "max_iterations": self.max_iterations,
            "context_warn": self.context_warn,
            "context_compact": self.context_compact,
            "context_kill": self.context_kill
        })
    
    @classmethod
    def from_jsonl(cls, d: dict) -> 'RalphPlanConfig':
        return cls(
            timeout_ms=d.get("timeout_ms", 900000),
            max_iterations=d.get("max_iterations", 10),
            context_warn=d.get("context_warn", 0.70),
            context_compact=d.get("context_compact", 0.85),
            context_kill=d.get("context_kill", 0.95)
        )


@dataclass
class RalphState:
    spec: Optional[str] = None
    tasks: list = field(default_factory=list)   # List of Task (both pending and done)
    issues: list = field(default_factory=list)  # List of Issue
    tombstones: list = field(default_factory=list)  # List of Tombstone
    config: Optional[RalphPlanConfig] = None  # Optional config record from plan.jsonl
    # Runtime state (not persisted to plan.jsonl)
    current_task_id: Optional[str] = None  # Task ID currently assigned to BUILD stage
    
    @property
    def pending(self) -> list:
        return [t for t in self.tasks if t.status == "p"]
    
    @property
    def done(self) -> list:
        """Tasks awaiting verification (status='d')."""
        return [t for t in self.tasks if t.status == "d"]
    
    @property
    def accepted(self) -> list:
        """Tasks that have been verified and accepted (status='a')."""
        return [t for t in self.tasks if t.status == "a"]
    
    @property
    def done_ids(self) -> set:
        """Set of task IDs awaiting verification (status='d')."""
        return {t.id for t in self.done}
    
    @property
    def accepted_ids(self) -> set:
        """Set of accepted task IDs (status='a' or from tombstones)."""
        # Combine task status 'a' and tombstones for comprehensive accepted set
        from_tasks = {t.id for t in self.tasks if t.status == "a"}
        from_tombstones = {t.id for t in self.tombstones if t.tombstone_type == "accept"}
        return from_tasks | from_tombstones
    
    @property
    def completed_ids(self) -> set:
        """Set of all completed task IDs (done + accepted).
        
        This is used for dependency checking - a dependency is satisfied if
        the task is either done (awaiting verification) or accepted (verified).
        """
        return self.done_ids | self.accepted_ids
    
    def get_next_task(self) -> Optional[Task]:
        """Get next task respecting dependencies, sorted by priority (high > medium > low > None).
        
        Returns the first task from get_sorted_pending() to ensure consistency between
        what the BUILD prompt shows and what 'ralph task done' marks.
        """
        sorted_pending = self.get_sorted_pending()
        return sorted_pending[0] if sorted_pending else None
    
    def get_sorted_pending(self) -> list:
        """Return pending tasks sorted by priority (high > medium > low > None), then by topological order."""
        completed_ids = self.completed_ids  # Includes both done and accepted tasks
        priority_order = {"high": 0, "medium": 1, "low": 2, None: 3}
        result = []
        remaining = [(idx, task) for idx, task in enumerate(self.pending)]
        seen = set()
        
        changed = True
        while changed and remaining:
            changed = False
            ready = []
            still_waiting = []
            
            for idx, task in remaining:
                if not task.deps or all(dep in completed_ids or dep in seen for dep in task.deps):
                    ready.append((idx, task))
                else:
                    still_waiting.append((idx, task))
            
            if ready:
                ready.sort(key=lambda x: (priority_order.get(x[1].priority, 3), x[0]))
                for idx, task in ready:
                    result.append(task)
                    seen.add(task.id)
                remaining = still_waiting
                changed = True
        
        remaining.sort(key=lambda x: (priority_order.get(x[1].priority, 3), x[0]))
        result.extend([task for _, task in remaining])
        return result
    
    def to_dict(self) -> dict:
        """For JSON output (ralph query)."""
        def task_to_dict(t: Task) -> dict:
            d = {"id": t.id, "name": t.name}
            if t.notes:
                d["notes"] = t.notes
            if t.accept:
                d["accept"] = t.accept
            if t.deps:
                d["deps"] = t.deps
            if t.done_at:
                d["done_at"] = t.done_at
            if t.priority:
                d["priority"] = t.priority
            return d
        
        def tombstone_to_dict(tomb: Tombstone) -> dict:
            d = {
                "id": tomb.id,
                "name": tomb.name,
                "type": tomb.tombstone_type,
                "done_at": tomb.done_at,
                "reason": tomb.reason
            }
            if tomb.timestamp:
                d["timestamp"] = tomb.timestamp
            if tomb.changed_files:
                d["changed_files"] = tomb.changed_files
            if tomb.log_file:
                d["log_file"] = tomb.log_file
            if tomb.iteration is not None:
                d["iteration"] = tomb.iteration
            if tomb.notes:
                d["notes"] = tomb.notes
            return d
        
        return {
            "spec": self.spec,
            "tasks": {
                "pending": [task_to_dict(t) for t in self.get_sorted_pending()],
                "done": [task_to_dict(t) for t in self.done],
                "accepted": [task_to_dict(t) for t in self.accepted],
            },
            "issues": [{"id": i.id, "desc": i.desc} for i in self.issues],
            "tombstones": {
                "accepted": [tombstone_to_dict(t) for t in self.tombstones if t.tombstone_type == "accept"],
                "rejected": [tombstone_to_dict(t) for t in self.tombstones if t.tombstone_type == "reject"],
            },
        }
    
    def get_stage(self) -> str:
        """Compute current stage based on state.
        
        State machine per construct-mode.md spec (lines 630-640):
        | State                                | Stage       |
        |--------------------------------------|-------------|
        | Has issues                           | INVESTIGATE |
        | Has pending tasks                    | BUILD       |
        | Has done tasks, no pending           | VERIFY      |
        | Has task with kill_reason            | DECOMPOSE   |
        | Empty (no tasks, no issues)          | COMPLETE    |
        
        Note: DECOMPOSE takes priority - a killed task must be decomposed
        before continuing to BUILD more tasks.
        """
        if self.spec is None:
            return "PLAN"
        # INVESTIGATE takes priority - process all issues before building
        if self.issues:
            return "INVESTIGATE"
        # DECOMPOSE: any task (pending or done) with kill_reason needs breakdown
        # This covers both execution failures (timeout/context) during BUILD
        # and rejected tasks that failed due to being too large
        if any(t.kill_reason for t in self.tasks):
            return "DECOMPOSE"
        if self.pending:
            return "BUILD"
        if self.done:
            return "VERIFY"
        return "COMPLETE"
    
    def get_task_needing_decompose(self) -> Optional['Task']:
        """Get first task that needs decomposition (has kill_reason set)."""
        for t in self.tasks:
            if t.kill_reason:
                return t
        return None
    
    def get_next(self) -> dict:
        """Get next action to take."""
        stage = self.get_stage()
        if stage == "PLAN":
            return {"action": "PLAN", "item": None}
        elif stage == "DECOMPOSE":
            task = self.get_task_needing_decompose()
            return {"action": "DECOMPOSE", "task": task_to_query_dict(task, include_decompose_info=True) if task else None}
        elif stage == "BUILD":
            task = self.get_next_task()
            return {"action": "BUILD", "task": task_to_query_dict(task) if task else None}
        elif stage == "VERIFY":
            return {"action": "VERIFY", "item": f"Verify {len(self.done)} completed tasks against spec"}
        elif stage == "INVESTIGATE":
            return {"action": "INVESTIGATE", "items": [{"id": i.id, "desc": i.desc} for i in self.issues], "count": len(self.issues)}
        else:
            return {"action": "COMPLETE", "item": None}


def task_to_query_dict(t: Task, include_decompose_info: bool = False) -> dict:
    """Convert task to dict for query output.
    
    Args:
        t: Task to convert
        include_decompose_info: If True, include kill_reason and kill_log for decompose context
    """
    d = {"id": t.id, "name": t.name}
    if t.notes:
        d["notes"] = t.notes
    if t.accept:
        d["accept"] = t.accept
    if t.deps:
        d["deps"] = t.deps
    if t.done_at:
        d["done_at"] = t.done_at
    if include_decompose_info and t.kill_reason:
        d["kill_reason"] = t.kill_reason
        if t.kill_log:
            d["kill_log"] = t.kill_log
    return d


# =============================================================================
# Rejection Pattern Analysis
# =============================================================================
# 
# Analyzes tombstones (rejection records) to detect:
# 1. Tasks repeatedly rejected with the same error
# 2. Multiple tasks failing with the same root cause
# 3. Missing prerequisite tasks that block progress
#
# Creates issues automatically so INVESTIGATE can address them.

def analyze_rejection_patterns(state: 'RalphState', config: 'RalphConfig') -> list:
    """Analyze rejection patterns and create issues for recurring problems.
    
    Returns list of new issues created.
    """
    from collections import defaultdict
    
    # Count rejections per task
    rejections_by_task = defaultdict(list)
    for tomb in state.tombstones:
        rejections_by_task[tomb.id].append(tomb.reason)
    
    # Look for common error patterns across all rejections
    error_patterns = defaultdict(list)  # pattern -> list of (task_id, reason)
    
    # Common error pattern indicators
    PATTERN_KEYWORDS = [
        'argument count',
        'not found',
        'grep returns 0',
        'expected 1',
        'expected 0',
        'times out',
        'timeout',
        'still contains',
        'not implemented',
        'missing',
    ]
    
    for tomb in state.tombstones:
        reason_lower = tomb.reason.lower()
        for keyword in PATTERN_KEYWORDS:
            if keyword in reason_lower:
                error_patterns[keyword].append((tomb.id, tomb.reason))
                break
    
    new_issues = []
    existing_issue_descs = {i.desc.lower() for i in state.issues}
    
    # Check for tasks rejected 3+ times
    REJECTION_THRESHOLD = 3
    for task_id, reasons in rejections_by_task.items():
        if len(reasons) >= REJECTION_THRESHOLD:
            task = next((t for t in state.tasks if t.id == task_id), None)
            task_name = task.name if task else task_id
            
            # Check if we already have an issue for this
            issue_key = f"repeated rejection: {task_id}"
            if issue_key not in existing_issue_descs:
                # Summarize the rejection reasons
                unique_reasons = list(set(reasons))[:3]
                reason_summary = '; '.join(r[:100] for r in unique_reasons)
                
                issue_desc = (
                    f"REPEATED REJECTION ({len(reasons)}x): Task '{task_name}' ({task_id}) "
                    f"keeps failing with: {reason_summary}. "
                    f"Investigate root cause - may need prerequisite task or spec clarification."
                )
                
                issue = Issue(
                    id=_generate_id('i'),
                    desc=issue_desc,
                    spec=state.spec or "",
                    priority="high"
                )
                new_issues.append(issue)
    
    # Check for common error patterns affecting multiple tasks
    PATTERN_THRESHOLD = 2
    for pattern, occurrences in error_patterns.items():
        unique_tasks = set(task_id for task_id, _ in occurrences)
        if len(unique_tasks) >= PATTERN_THRESHOLD:
            # Check if we already have an issue for this pattern
            pattern_key = f"common failure pattern: {pattern}"
            if pattern_key not in existing_issue_descs:
                task_names = []
                for task_id in list(unique_tasks)[:3]:
                    task = next((t for t in state.tasks if t.id == task_id), None)
                    task_names.append(task.name[:30] if task else task_id)
                
                # Get a sample reason for context
                sample_reason = occurrences[0][1][:150]
                
                issue_desc = (
                    f"COMMON FAILURE PATTERN: {len(unique_tasks)} tasks fail with '{pattern}'. "
                    f"Affected: {', '.join(task_names)}. "
                    f"Sample: {sample_reason}. "
                    f"Likely missing prerequisite - create blocking task."
                )
                
                issue = Issue(
                    id=_generate_id('i'),
                    desc=issue_desc,
                    spec=state.spec or "",
                    priority="high"
                )
                new_issues.append(issue)
    
    return new_issues


def run_rejection_analysis(config: 'RalphConfig') -> int:
    """Run rejection pattern analysis and add issues to state.
    
    Returns number of new issues created.
    """
    state = load_state(config)
    
    if not state.tombstones:
        return 0
    
    new_issues = analyze_rejection_patterns(state, config)
    
    if new_issues:
        for issue in new_issues:
            state.issues.append(issue)
            print(f"{Colors.YELLOW}Auto-issue:{Colors.NC} {issue.desc[:80]}...")
        
        save_state(config, state, f"ralph: auto-created {len(new_issues)} issues from rejection patterns")
    
    return len(new_issues)


# =============================================================================
# Construct Mode State Machine
# =============================================================================
# 
# Per construct-mode.md spec, each iteration runs three stages sequentially:
#   INVESTIGATE -> BUILD -> VERIFY
# 
# With DECOMPOSE as an interrupt handler for failures (timeout/context).
# 
# State machine flow:
#   1. Each iteration starts with INVESTIGATE (if issues exist, else skip)
#   2. Then BUILD (execute tasks until none remain or failure)
#   3. Then VERIFY (check done tasks against spec)
#   4. If failure during any stage -> DECOMPOSE -> continue to next iteration
#   5. If VERIFY finds gaps -> new iteration
#   6. If VERIFY accepts all and no gaps -> COMPLETE

class Stage(Enum):
    """Stages within construct mode's iteration loop."""
    INVESTIGATE = auto()  # Turn issues into tasks
    BUILD = auto()        # Execute tasks
    VERIFY = auto()       # Verify done tasks against spec
    DECOMPOSE = auto()    # Handle failures by breaking down work
    COMPLETE = auto()     # Spec fully implemented


class StageOutcome(Enum):
    """Outcome of running a stage."""
    SUCCESS = auto()      # Stage completed normally
    FAILURE = auto()      # Stage failed (timeout/context/error)
    SKIP = auto()         # Stage skipped (no work to do)


@dataclass
class StageResult:
    """Result of running a single stage."""
    stage: Stage
    outcome: StageOutcome
    exit_code: int = 0
    duration_seconds: float = 0.0
    cost: float = 0.0
    tokens_used: int = 0
    kill_reason: Optional[str] = None  # "timeout", "context_limit", "compaction_failed"
    kill_log: Optional[str] = None     # Path to log file if killed
    task_id: Optional[str] = None      # Task that was being executed (for BUILD/DECOMPOSE)
    error: Optional[str] = None        # Error message if any


class ConstructStateMachine:
    """
    State machine for construct mode iterations.
    
    Each iteration runs: INVESTIGATE -> BUILD -> VERIFY
    DECOMPOSE is triggered on failures and runs before the next iteration.
    """
    
    def __init__(self, config: 'RalphConfig', metrics: 'Metrics',
                 stage_timeout_ms: int, context_limit: int,
                 run_stage_fn: Callable[['RalphConfig', Stage, 'RalphState', 'Metrics', int, int], StageResult]):
        """
        Initialize the state machine.
        
        Args:
            config: Ralph configuration
            metrics: Metrics tracker
            stage_timeout_ms: Timeout per stage in milliseconds
            context_limit: Context window size in tokens
            run_stage_fn: Function to actually run a stage (injected for testability)
        """
        self.config = config
        self.metrics = metrics
        self.stage_timeout_ms = stage_timeout_ms
        self.context_limit = context_limit
        self.run_stage = run_stage_fn
        
        # Track if we need to run DECOMPOSE before next iteration
        self._pending_decompose = False
        self._decompose_task_id: Optional[str] = None
        self._decompose_kill_reason: Optional[str] = None
        self._decompose_kill_log: Optional[str] = None
    
    def run_iteration(self, iteration: int) -> tuple[bool, bool]:
        """
        Run a single iteration of the construct loop.
        
        Per spec: INVESTIGATE -> BUILD -> VERIFY (sequentially)
        DECOMPOSE runs if there's a pending failure from previous stage.
        
        Args:
            iteration: Current iteration number
            
        Returns:
            Tuple of (should_continue, spec_complete)
            - should_continue: True if more iterations needed
            - spec_complete: True if spec is fully implemented
        """
        state = load_state(self.config)
        
        # If we have a pending decompose from a failure, run it first
        if self._pending_decompose:
            print(f"{Colors.YELLOW}Running DECOMPOSE for failed task...{Colors.NC}")
            result = self._run_stage_with_state(Stage.DECOMPOSE, state)
            self._pending_decompose = False
            self._decompose_task_id = None
            self._decompose_kill_reason = None
            self._decompose_kill_log = None
            
            if result.outcome == StageOutcome.FAILURE:
                # DECOMPOSE itself failed - this is bad, but continue
                print(f"{Colors.RED}DECOMPOSE failed: {result.error}{Colors.NC}")
            
            # After DECOMPOSE, start fresh iteration rather than continuing
            # This prevents running VERIFY immediately after DECOMPOSE
            return True, False
        
        # Also check for tasks with kill_reason in persisted state (from previous run)
        if any(t.kill_reason for t in state.tasks):
            print(f"{Colors.YELLOW}Running DECOMPOSE for previously killed task...{Colors.NC}")
            result = self._run_stage_with_state(Stage.DECOMPOSE, state)
            
            if result.outcome == StageOutcome.FAILURE:
                print(f"{Colors.RED}DECOMPOSE failed: {result.error}{Colors.NC}")
            
            # After DECOMPOSE, start fresh iteration
            return True, False
        
        # Check for terminal state
        if not state.spec:
            print(f"{Colors.YELLOW}No spec configured - run 'ralph plan <spec.md>' first{Colors.NC}")
            return False, False
        
        # Analyze rejection patterns and auto-create issues for recurring problems
        # This runs BEFORE INVESTIGATE so the AI can address them
        new_issues = run_rejection_analysis(self.config)
        if new_issues:
            print(f"{Colors.YELLOW}Created {new_issues} issues from rejection pattern analysis{Colors.NC}")
            state = load_state(self.config)  # Reload state with new issues
        
        # Phase 1: INVESTIGATE (if issues exist)
        if state.issues:
            print(f"\n{Colors.CYAN}‚ïê‚ïê‚ïê INVESTIGATE ({len(state.issues)} issues) ‚ïê‚ïê‚ïê{Colors.NC}")
            result = self._run_stage_with_state(Stage.INVESTIGATE, state)
            
            if result.outcome == StageOutcome.FAILURE:
                self._handle_failure(result)
                return True, False  # Continue to next iteration (with DECOMPOSE)
            
            # Reload state after investigate
            state = load_state(self.config)
        
        # Phase 2: BUILD (execute tasks until none remain)
        if state.pending:
            print(f"\n{Colors.CYAN}‚ïê‚ïê‚ïê BUILD ({len(state.pending)} tasks) ‚ïê‚ïê‚ïê{Colors.NC}")
            
            # BUILD processes tasks one at a time, but can fail mid-way
            # The BUILD prompt handles looping through tasks internally
            result = self._run_stage_with_state(Stage.BUILD, state)
            
            if result.outcome == StageOutcome.FAILURE:
                self._handle_failure(result)
                return True, False  # Continue to next iteration (with DECOMPOSE)
            
            # Reload state after build
            state = load_state(self.config)
        
        # Phase 3: VERIFY (if done tasks exist)
        if state.done:
            print(f"\n{Colors.CYAN}‚ïê‚ïê‚ïê VERIFY ({len(state.done)} done tasks) ‚ïê‚ïê‚ïê{Colors.NC}")
            result = self._run_stage_with_state(Stage.VERIFY, state)
            
            if result.outcome == StageOutcome.FAILURE:
                self._handle_failure(result)
                return True, False  # Continue to next iteration (with DECOMPOSE)
            
            # Reload state after verify
            state = load_state(self.config)
        
        # Check if we're complete
        if not state.pending and not state.done and not state.issues:
            return False, True  # Spec complete!
        
        # More work to do
        return True, False
    
    def _run_stage_with_state(self, stage: Stage, state: 'RalphState') -> StageResult:
        """Run a stage and return the result."""
        return self.run_stage(
            self.config, stage, state, self.metrics,
            self.stage_timeout_ms, self.context_limit
        )
    
    def _handle_failure(self, result: StageResult):
        """Handle a stage failure by queuing DECOMPOSE."""
        self._pending_decompose = True
        self._decompose_task_id = result.task_id
        self._decompose_kill_reason = result.kill_reason
        self._decompose_kill_log = result.kill_log
        
        # Mark the task with kill_reason in state
        if result.task_id:
            state = load_state(self.config)
            task = next((t for t in state.tasks if t.id == result.task_id), None)
            if task:
                task.kill_reason = result.kill_reason
                task.kill_log = result.kill_log
                save_state(self.config, state)
                print(f"{Colors.YELLOW}Task {task.id} marked for decomposition{Colors.NC}")


def load_state(config: RalphConfig) -> RalphState:
    """Load state from plan.jsonl by reading all lines."""
    state = RalphState()
    
    if not config.plan_file.exists():
        return state
    
    try:
        for line in config.plan_file.read_text().strip().split('\n'):
            if not line.strip():
                continue
            d = json.loads(line)
            t = d.get("t")
            if t == "spec":
                state.spec = d.get("spec")
            elif t == "task":
                state.tasks.append(Task.from_jsonl(d))
            elif t == "issue":
                state.issues.append(Issue.from_jsonl(d))
            elif t == "reject":
                state.tombstones.append(Tombstone.from_jsonl(d, "reject"))
            elif t == "accept":
                state.tombstones.append(Tombstone.from_jsonl(d, "accept"))
            elif t == "config":
                state.config = RalphPlanConfig.from_jsonl(d)
    except (json.JSONDecodeError, KeyError):
        pass
    
    # Post-process: mark tasks as accepted if they have accept tombstones
    # This ensures done tasks with accept tombstones don't show in VERIFY queue
    accepted_ids = {t.id for t in state.tombstones if t.tombstone_type == "accept"}
    for task in state.tasks:
        if task.id in accepted_ids and task.status == "d":
            task.status = "a"  # Mark as accepted, not just done
    
    return state


def save_state(config: RalphConfig, state: RalphState, commit_msg: Optional[str] = None):
    """Save state to plan.jsonl, optionally commit."""
    lines = []
    
    if state.config:
        lines.append(state.config.to_jsonl())
    
    if state.spec:
        lines.append(json.dumps({"t": "spec", "spec": state.spec}))
    
    for task in state.tasks:
        lines.append(task.to_jsonl())
    
    for issue in state.issues:
        lines.append(issue.to_jsonl())
    
    for tombstone in state.tombstones:
        lines.append(tombstone.to_jsonl())
    
    config.plan_file.write_text('\n'.join(lines) + '\n' if lines else '')
    
    if commit_msg:
        subprocess.run(['git', 'add', str(config.plan_file)], 
                      cwd=config.repo_root, capture_output=True)
        subprocess.run(['git', 'commit', '-m', commit_msg],
                      cwd=config.repo_root, capture_output=True)


def get_current_commit(config: RalphConfig) -> str:
    """Get current HEAD commit hash (short)."""
    result = subprocess.run(
        ['git', 'rev-parse', '--short', 'HEAD'],
        capture_output=True, text=True, cwd=config.repo_root
    )
    return result.stdout.strip() if result.returncode == 0 else "unknown"


def get_commit_files(config: RalphConfig, commit_hash: str) -> list:
    """Get list of files changed in a commit."""
    try:
        result = subprocess.run(
            ['git', 'diff-tree', '--no-commit-id', '--name-only', '-r', commit_hash],
            capture_output=True, text=True, cwd=config.repo_root, timeout=5
        )
        if result.returncode == 0:
            return [f.strip() for f in result.stdout.strip().split('\n') if f.strip()]
        return []
    except (subprocess.TimeoutExpired, Exception):
        return []


def get_commit_timestamp(config: RalphConfig, commit_hash: str) -> Optional[str]:
    """Get ISO timestamp of a commit."""
    try:
        result = subprocess.run(
            ['git', 'show', '-s', '--format=%cI', commit_hash],
            capture_output=True, text=True, cwd=config.repo_root, timeout=5
        )
        if result.returncode == 0:
            return result.stdout.strip()
        return None
    except (subprocess.TimeoutExpired, Exception):
        return None


def create_tombstone(
    config: RalphConfig,
    task: 'Task',
    tombstone_type: str,
    reason: str = "",
    log_file: Optional[str] = None,
    iteration: Optional[int] = None
) -> 'Tombstone':
    """Create a tombstone with full context information.
    
    Args:
        config: Ralph configuration
        task: Task being tombstoned
        tombstone_type: "accept" or "reject"
        reason: Acceptance criteria or rejection reason
        log_file: Path to log file (for rejected tasks)
        iteration: Iteration number when tombstone was created
    
    Returns:
        Tombstone with full metadata
    """
    from datetime import datetime
    
    commit_hash = task.done_at or get_current_commit(config)
    
    # Get timestamp - try from commit first, fallback to current time
    timestamp = get_commit_timestamp(config, commit_hash)
    if not timestamp:
        timestamp = datetime.utcnow().isoformat() + 'Z'
    
    # Get changed files from the commit
    changed_files = get_commit_files(config, commit_hash) if commit_hash != "unknown" else []
    
    return Tombstone(
        id=task.id,
        done_at=commit_hash,
        reason=reason,
        tombstone_type=tombstone_type,
        name=task.name,
        timestamp=timestamp,
        changed_files=changed_files,
        log_file=log_file,
        iteration=iteration,
        notes=task.notes
    )


def get_current_task_file(config: RalphConfig) -> Path:
    """Get path to the current task lock file."""
    return config.ralph_dir / ".current_task"


def save_current_task(config: RalphConfig, task_id: str) -> None:
    """Save the currently assigned task ID to a runtime lock file.
    
    This file is NOT tracked by git - it's runtime state that tracks
    which task BUILD is currently working on, so `ralph task done`
    knows which task to mark as complete.
    """
    lock_file = get_current_task_file(config)
    lock_file.write_text(task_id)


def load_current_task(config: RalphConfig) -> Optional[str]:
    """Load the currently assigned task ID from the runtime lock file.
    
    Returns None if no task is currently assigned.
    """
    lock_file = get_current_task_file(config)
    if lock_file.exists():
        task_id = lock_file.read_text().strip()
        return task_id if task_id else None
    return None


def clear_current_task(config: RalphConfig) -> None:
    """Clear the current task lock file."""
    lock_file = get_current_task_file(config)
    if lock_file.exists():
        lock_file.unlink()


def validate_state(state: RalphState, config: RalphConfig = None) -> dict:
    """Validate state for common issues like dangling dependencies.
    
    Args:
        state: Current RalphState
        config: RalphConfig for git history lookup (optional, but recommended)
    
    Returns dict with:
        valid: bool - True if no errors found
        errors: list - Critical issues that need fixing
        warnings: list - Non-critical issues
    
    Note: Dependency validation considers git history because plan.jsonl
    can be compacted (tombstones removed). A dep is valid if the task ID
    exists in current state, tombstones, OR git history.
    """
    errors = []
    warnings = []
    
    # Get all valid task IDs: current + tombstones + git history
    # This handles compaction where accepted/rejected tasks are cleaned up
    if config:
        all_valid_ids = get_all_valid_task_ids(config, state)
    else:
        # Fallback: just use current state + tombstones
        all_valid_ids = {t.id for t in state.tasks}
        all_valid_ids.update(t.id for t in state.tombstones)
    
    # Current task IDs (for cycle detection)
    current_task_ids = {t.id for t in state.tasks}
    
    # Check for dangling dependencies
    for task in state.pending:
        if task.deps:
            for dep_id in task.deps:
                if dep_id not in all_valid_ids:
                    errors.append(f"Task {task.id} has dangling dep: {dep_id} (not in current state, tombstones, or git history)")
    
    # Check for dangling parent references
    for task in state.tasks:
        if task.parent and task.parent not in all_valid_ids:
            warnings.append(f"Task {task.id} has dangling parent: {task.parent}")
    
    # Check for dangling created_from references
    issue_ids = {i.id for i in state.issues}
    for task in state.tasks:
        if task.created_from:
            # created_from can reference issues that are already cleared, so just warn
            if not task.created_from.startswith('i-'):
                warnings.append(f"Task {task.id} has invalid created_from: {task.created_from}")
    
    # Check for circular dependencies (simple cycle detection)
    # Only check among current tasks, not historical ones
    def has_cycle(task_id, visited, path):
        if task_id in path:
            return True
        if task_id in visited:
            return False
        visited.add(task_id)
        path.add(task_id)
        task = next((t for t in state.tasks if t.id == task_id), None)
        if task and task.deps:
            for dep_id in task.deps:
                if dep_id in current_task_ids and has_cycle(dep_id, visited, path):
                    return True
        path.remove(task_id)
        return False
    
    visited = set()
    for task in state.pending:
        if has_cycle(task.id, visited, set()):
            errors.append(f"Circular dependency detected involving task {task.id}")
    
    return {
        'valid': len(errors) == 0,
        'errors': errors,
        'warnings': warnings
    }


def validate_task_notes(notes: str) -> tuple[bool, Optional[str]]:
    """Validate that task notes are detailed with file paths and implementation guidance.
    
    Returns:
        Tuple of (is_valid, error_message)
        - is_valid: True if notes pass validation
        - error_message: Description of why validation failed, or None if valid
    
    Notes must:
    - Be specific (not vague like "implement X")
    - Include file paths or references
    - Describe the approach or what to modify
    - Be long enough to be useful (minimum 50 chars)
    
    Good examples:
    - "Modify src/aio/aio_combinators.c: Add valk_builtin_aio_within() that races handle with timeout"
    - "Create test/test_retry.valk: Test max-attempts, backoff patterns, and success after failure"
    - "Update src/parser.c line 450: Register aio/within in builtin table after aio/race"
    
    Bad examples:
    - "Implement the feature"
    - "Add tests"
    - "Fix the bug"
    - "Update code as needed"
    """
    if not notes:
        return False, "Task notes are required. Specify which files to modify and what approach to take."
    
    notes_stripped = notes.strip()
    
    # Check minimum length
    MIN_LENGTH = 50
    if len(notes_stripped) < MIN_LENGTH:
        return False, f"Task notes too short ({len(notes_stripped)} chars). Provide detailed implementation guidance with file paths (minimum {MIN_LENGTH} chars)."
    
    # Check for vague phrases
    VAGUE_PHRASES = [
        'implement the feature',
        'add the feature',
        'implement x',
        'add x',
        'fix the bug',
        'fix the issue',
        'fix the problem',
        'update code',
        'update as needed',
        'modify as needed',
        'change as needed',
        'add tests',
        'write tests',
        'implement',  # standalone
        'as needed',
        'tbd',
        'todo',
        'to be determined',
    ]
    
    notes_lower = notes_stripped.lower()
    for phrase in VAGUE_PHRASES:
        if phrase in notes_lower:
            return False, f"Task notes are too vague: '{phrase}'. Specify WHICH files to modify and WHAT approach to use."
    
    # Check for file path indicators
    FILE_PATH_INDICATORS = [
        '/',  # Path separator (src/foo.c, test/bar.valk)
        '.c', '.h', '.valk', '.py', '.js', '.ts',  # File extensions
        'src/', 'test/', 'include/', 'lib/',  # Common directories
        'line ', 'lines ',  # Line number references
        'function ', 'method ',  # Function references
        'file ',  # Explicit file reference
    ]
    
    has_file_reference = any(indicator in notes_lower for indicator in FILE_PATH_INDICATORS)
    
    if not has_file_reference:
        return False, "Task notes lack specific file paths. Include which files to modify (e.g., 'src/parser.c', 'test/test_foo.valk')."
    
    # Check for implementation guidance indicators
    IMPLEMENTATION_INDICATORS = [
        'add ', 'create ', 'modify ', 'update ', 'change ', 'remove ', 'delete ',
        'extract ', 'refactor ', 'move ', 'rename ', 'replace ',
        'register ', 'implement ', 'define ', 'declare ',
        'call ', 'invoke ', 'use ', 'pattern:',
        'approach:', 'strategy:',
        ':', '-',  # Colons and dashes often indicate structured guidance
    ]
    
    has_guidance = any(indicator in notes_lower for indicator in IMPLEMENTATION_INDICATORS)
    
    if not has_guidance:
        return False, "Task notes lack implementation guidance. Describe WHAT to do (add, modify, create, etc.) and HOW."
    
    # Check for specific location references (line numbers, function names, or class names)
    # This ensures notes contain concrete references for BUILD stage to find the right code
    import re
    
    LINE_NUMBER_PATTERNS = [
        r'line[s]?\s+\d+',           # "line 50" or "lines 100"
        r'line[s]?\s+~?\d+\s*-\s*\d+',  # "lines 100-150" or "lines ~100-150"
        r':\d+',                     # "file.py:50" (colon notation)
        r'\(\s*line[s]?\s+\d+',      # "(line 50" or "(lines 100"
    ]
    
    FUNCTION_CLASS_PATTERNS = [
        r'function\s+\w+',           # "function foo"
        r'method\s+\w+',             # "method bar"  
        r'class\s+\w+',              # "class Baz"
        r'def\s+\w+',                # "def foo"
        r'\w+\(\)',                  # "foo()" - function call notation
        r'\w+\.\w+\(\)',             # "obj.method()" - method call notation
    ]
    
    has_line_ref = any(re.search(p, notes_lower) for p in LINE_NUMBER_PATTERNS)
    has_func_ref = any(re.search(p, notes_lower) for p in FUNCTION_CLASS_PATTERNS)
    
    # Warn but don't reject if no specific location - some tasks legitimately create new files
    # But for modification tasks, we strongly prefer line numbers
    has_modify_verb = any(v in notes_lower for v in ['modify ', 'update ', 'change ', 'fix ', 'extract '])
    if has_modify_verb and not (has_line_ref or has_func_ref):
        return False, "Task notes mention modifying code but lack specific locations. Include line numbers (e.g., 'lines 100-150') or function/class names (e.g., 'function parse_config()')."
    
    # Check for context elements that help BUILD stage
    CONTEXT_INDICATORS = [
        'source:', 'from:', 'import', 'pattern:', 'similar to', 'follow',
        'spec ref', 'see ', 'reference:', 'based on', 'like ',
        'risk:', 'prerequisite', 'requires ', 'depends on', 'after ',
    ]
    
    has_context = any(indicator in notes_lower for indicator in CONTEXT_INDICATORS)
    
    # For longer notes (likely complex tasks), require some context
    if len(notes_stripped) > 150 and not has_context:
        # This is a soft warning - complex tasks should have context
        # But we don't reject, just note it's suboptimal
        pass
    
    return True, None


def validate_acceptance_criteria(accept: str) -> tuple[bool, Optional[str]]:
    """Validate that acceptance criteria is measurable and specific.
    
    Returns:
        Tuple of (is_valid, error_message)
        - is_valid: True if criteria passes validation
        - error_message: Description of why validation failed, or None if valid
    
    Acceptance criteria must be:
    - Specific (not vague phrases like "works correctly")
    - Measurable (has concrete pass/fail conditions)
    - Actionable (can be verified by running a command or checking output)
    
    Good examples:
    - "pytest tests/test_parser.py passes"
    - "`ralph query` returns JSON with `tasks` array"
    - "Build exits with code 0 and produces build/output.bin"
    - "grep -c 'ERROR' output.log returns 0"
    
    Bad examples:
    - "works correctly"
    - "tests pass" (which tests?)
    - "is implemented"
    - "errors are handled"
    """
    if not accept:
        return False, "Acceptance criteria is required. Specify how to verify the task is done."
    
    accept_lower = accept.lower().strip()
    
    VAGUE_PHRASES = [
        'works correctly',
        'works properly', 
        'works as expected',
        'works well',
        'is correct',
        'is proper',
        'is working',
        'is implemented',
        'is complete',
        'is done',
        'is finished',
        'is fixed',
        'is resolved',
        'is handled',
        'is supported',
        'functions correctly',
        'functions properly',
        'behaves correctly',
        'behaves properly',
        'operates correctly',
        'runs correctly',
        'executes correctly',
        'performs correctly',
        'performs well',
        'performs as expected',
        'no errors',
        'no issues',
        'no problems',
        'no bugs',
        'errors handled',
        'errors are handled',
        'handles errors',
        'error handling works',
        'properly handles',
        'correctly handles',
        'should work',
        'should pass',
        'should be correct',
        'should be working',
        'all good',
        'looks good',
        'seems to work',
        'appears to work',
    ]
    
    for phrase in VAGUE_PHRASES:
        if phrase in accept_lower:
            return False, f"Acceptance criteria is too vague: '{phrase}'. Be specific about what to verify (e.g., command to run, expected output, exit code)."
    
    VAGUE_WORD_BOUNDARY_PATTERNS = [
        (r'\bworks\b', "' works'"),  # "X works" without qualifier
    ]
    import re
    for pattern, label in VAGUE_WORD_BOUNDARY_PATTERNS:
        if re.search(pattern, accept_lower):
            context = accept_lower
            if ' works' in context:
                before_works = context.split(' works')[0].split()[-1] if context.split(' works')[0].split() else ''
                after_works = context.split(' works')[1].split()[0] if len(context.split(' works')) > 1 and context.split(' works')[1].split() else ''
                if after_works not in ('with', 'by', 'when', 'after', 'before', 'if', 'only'):
                    return False, f"Acceptance criteria contains vague '{before_works} works'. Specify HOW to verify it works (e.g., 'X returns Y', 'X produces output Z', 'running X shows Y')."
    
    STANDALONE_VAGUE = [
        'tests pass',
        'test passes',
        'all tests pass',
        'unit tests pass',
        'the tests pass',
    ]
    for phrase in STANDALONE_VAGUE:
        if accept_lower == phrase or accept_lower == phrase + '.':
            return False, f"'{phrase}' is too vague. Specify WHICH tests (e.g., 'pytest tests/test_foo.py passes' or 'make test-unit exits with code 0')."
    
    MIN_LENGTH = 15
    if len(accept.strip()) < MIN_LENGTH:
        return False, f"Acceptance criteria too short ({len(accept.strip())} chars). Be specific about verification steps (minimum {MIN_LENGTH} chars)."
    
    MEASURABLE_INDICATORS = [
        'pass', 'passes', 'passed',
        'fail', 'fails', 'failed',
        'return', 'returns', 'returned',
        'output', 'outputs',
        'print', 'prints',
        'exit', 'exits',
        'code', 'status',
        'contain', 'contains',
        'include', 'includes',
        'match', 'matches',
        'equal', 'equals',
        'produce', 'produces',
        'create', 'creates',
        'generate', 'generates',
        'show', 'shows',
        'display', 'displays',
        'count', 'counts',
        'exist', 'exists',
        '==', '!=', '>', '<', '>=', '<=',
        'grep', 'find', 'test', 'check',
        'assert', 'verify', 'confirm',
        'build', 'compile', 'run',
        'pytest', 'jest', 'mocha', 'cargo test', 'go test', 'npm test', 'make test',
        '`',  # backticks often indicate commands
        'should',  # "X should Y" patterns
    ]
    
    has_measurable = any(indicator in accept_lower for indicator in MEASURABLE_INDICATORS)
    if not has_measurable:
        return False, "Acceptance criteria lacks measurable verification. Include: a command to run, expected output/exit code, or specific condition to check."
    
    return True, None


def get_historical_task_ids(config: RalphConfig) -> set:
    """Get all task IDs that have ever existed in plan.jsonl from git history.
    
    This is used to validate dependencies - a dep is valid if the task ID
    exists in current state OR has ever existed (was accepted/compacted away).
    
    Uses git log to search for task IDs in the plan.jsonl history.
    """
    historical_ids = set()
    
    # Get task IDs from git history of plan.jsonl
    # Use git log -p to get the diffs, then extract task IDs
    try:
        result = subprocess.run(
            ['git', 'log', '-p', '--all', '--', 'ralph/plan.jsonl'],
            cwd=config.repo_root, capture_output=True, text=True, timeout=30
        )
        if result.returncode == 0:
            # Extract all task IDs from the history using regex
            import re
            # Match task IDs in format "t-" followed by alphanumeric chars
            for match in re.finditer(r'"id":\s*"(t-[a-z0-9]+)"', result.stdout):
                historical_ids.add(match.group(1))
    except (subprocess.TimeoutExpired, Exception):
        pass  # Fall back to current state only
    
    return historical_ids


def get_all_valid_task_ids(config: RalphConfig, state: RalphState) -> set:
    """Get all valid task IDs: current tasks + tombstones + git history.
    
    A task ID is valid as a dependency if:
    1. It exists in current state.tasks (pending, done, or accepted)
    2. It exists in tombstones (was accepted or rejected)
    3. It existed in git history (plan was compacted)
    """
    # Current task IDs
    valid_ids = {t.id for t in state.tasks}
    
    # Tombstone IDs (accepted and rejected)
    valid_ids.update(t.id for t in state.tombstones)
    
    # Historical IDs from git (handles compaction)
    valid_ids.update(get_historical_task_ids(config))
    
    return valid_ids


def sync_with_remote(config: RalphConfig, branch: str) -> str:
    """Sync local branch with remote, pulling any new changes.
    
    This allows multiple Ralph instances to collaborate on the same branch.
    Uses rebase to keep history clean.
    
    Returns:
        "updated" - Successfully pulled new changes
        "current" - Already up to date
        "conflict" - Merge conflict detected (needs manual resolution)
        "error" - Other error (logged but not fatal)
    """
    repo_root = config.repo_root
    
    # First, commit any uncommitted plan changes to avoid losing work
    if has_uncommitted_plan(config):
        subprocess.run(['git', 'add', str(config.plan_file)],
                      cwd=repo_root, capture_output=True)
        subprocess.run(['git', 'commit', '-m', 'ralph: save state before sync'],
                      cwd=repo_root, capture_output=True)
    
    # Fetch from remote
    fetch_result = subprocess.run(
        ['git', 'fetch', 'origin', branch],
        capture_output=True, text=True, cwd=repo_root
    )
    if fetch_result.returncode != 0:
        # Network error or branch doesn't exist on remote - not fatal
        return "error"
    
    # Check if we're behind
    status_result = subprocess.run(
        ['git', 'status', '-uno'],
        capture_output=True, text=True, cwd=repo_root
    )
    
    if 'Your branch is behind' not in status_result.stdout and 'have diverged' not in status_result.stdout:
        return "current"
    
    # We have upstream changes - try to rebase
    print(f"{Colors.CYAN}Remote has new changes - rebasing...{Colors.NC}")
    
    rebase_result = subprocess.run(
        ['git', 'rebase', f'origin/{branch}'],
        capture_output=True, text=True, cwd=repo_root
    )
    
    if rebase_result.returncode != 0:
        # Rebase failed - likely conflict
        if 'CONFLICT' in rebase_result.stdout or 'conflict' in rebase_result.stderr.lower():
            # Abort the rebase to restore state
            subprocess.run(['git', 'rebase', '--abort'],
                          capture_output=True, cwd=repo_root)
            return "conflict"
        else:
            # Other error - abort and continue
            subprocess.run(['git', 'rebase', '--abort'],
                          capture_output=True, cwd=repo_root)
            print(f"{Colors.YELLOW}Rebase failed: {rebase_result.stderr}{Colors.NC}")
            return "error"
    
    print(f"{Colors.GREEN}Successfully synced with remote{Colors.NC}")
    return "updated"


def push_with_retry(config: RalphConfig, branch: str, max_retries: int = 3) -> bool:
    """Push to remote, handling upstream changes by pulling and retrying.
    
    Returns True if push succeeded, False if unrecoverable conflict.
    """
    repo_root = config.repo_root
    
    for attempt in range(max_retries):
        push_result = subprocess.run(
            ['git', 'push', 'origin', branch],
            capture_output=True, text=True, cwd=repo_root
        )
        
        if push_result.returncode == 0:
            return True
        
        # Push rejected - likely need to pull first
        if 'rejected' in push_result.stderr or 'non-fast-forward' in push_result.stderr:
            print(f"{Colors.YELLOW}Push rejected - syncing with remote (attempt {attempt + 1}/{max_retries}){Colors.NC}")
            
            sync_result = sync_with_remote(config, branch)
            if sync_result == "conflict":
                print(f"{Colors.RED}Conflict during sync - cannot push{Colors.NC}")
                return False
            elif sync_result == "error":
                # Network or other error - don't retry
                return False
            # sync_result is "updated" or "current" - retry push
            continue
        else:
            # Other push error (network, auth, etc.)
            print(f"{Colors.RED}Push failed: {push_result.stderr}{Colors.NC}")
            return False
    
    print(f"{Colors.RED}Push failed after {max_retries} retries{Colors.NC}")
    return False


def check_unfinished_tasks(config: RalphConfig, new_spec: str) -> bool:
    """Check for unfinished tasks/issues and prompt user. Returns True if OK to proceed."""
    state = load_state(config)
    
    current_spec = state.spec or "unknown"
    pending_tasks = state.pending
    done_tasks = state.done
    issues = state.issues
    
    if not pending_tasks and not done_tasks and not issues:
        return True
    
    # Different messaging for same spec vs different spec
    same_spec = (current_spec == new_spec)
    
    if same_spec:
        print(f"{Colors.YELLOW}Found existing items for spec '{current_spec}':{Colors.NC}")
    else:
        print(f"{Colors.YELLOW}Found unfinished items from spec '{current_spec}':{Colors.NC}")
    
    for t in pending_tasks:
        print(f"  - [pending] {t.id}: {t.name}")
    for t in done_tasks:
        print(f"  - [done] {t.id}: {t.name}")
    for i in issues:
        desc_preview = i.desc[:60] + "..." if len(i.desc) > 60 else i.desc
        print(f"  - [issue] {i.id}: {desc_preview}")
    print()
    print("What would you like to do?")
    print("  [c] Clear existing tasks/issues and start fresh")
    if same_spec:
        print("  [k] Keep existing tasks/issues (plan will add to them)")
    print("  [a] Abort (keep current plan)")
    
    try:
        response = input(f"Choice [c/{'k/' if same_spec else ''}a]: ").strip().lower()
        if response == 'c':
            # Clear tasks and issues before proceeding
            state.tasks = []
            state.issues = []
            save_state(config, state)
            print(f"{Colors.GREEN}Cleared existing tasks and issues.{Colors.NC}")
            return True
        elif response == 'k' and same_spec:
            print(f"{Colors.GREEN}Keeping existing tasks/issues. Plan will add to them.{Colors.NC}")
            return True
        else:
            print(f"{Colors.YELLOW}Aborted. Keeping current plan.{Colors.NC}")
            return False
    except (KeyboardInterrupt, EOFError):
        print()
        print(f"{Colors.YELLOW}Aborted. Keeping current plan.{Colors.NC}")
        return False


def has_uncommitted_plan(config: RalphConfig) -> bool:
    """Check if plan.jsonl has uncommitted changes (staged or unstaged)."""
    if not config.plan_file.exists():
        return False
    
    # Check for both staged and unstaged changes
    result = subprocess.run(
        ['git', 'status', '--porcelain', str(config.plan_file)],
        capture_output=True, text=True, cwd=config.repo_root
    )
    # Porcelain output is empty if file is clean
    return bool(result.stdout.strip())


def check_opencode_available() -> tuple[bool, Optional[str]]:
    """Check if opencode is available and working.
    
    Returns:
        Tuple of (is_available, error_message)
    """
    try:
        result = subprocess.run(
            ['opencode', 'version'],
            capture_output=True, text=True, timeout=10
        )
        if result.returncode == 0:
            return True, None
        else:
            return False, f"opencode returned error: {result.stderr.strip()}"
    except FileNotFoundError:
        return False, "opencode not found in PATH. Install it with: npm install -g @anthropic/opencode"
    except subprocess.TimeoutExpired:
        return False, "opencode timed out during version check"
    except Exception as e:
        return False, f"Error checking opencode: {e}"


def find_repo_root() -> Optional[Path]:
    """Find git repository root."""
    dir = Path.cwd()
    while dir != dir.parent:
        if (dir / '.git').exists():
            return dir
        dir = dir.parent
    return None


def find_project_rules(repo_root: Path) -> Optional[str]:
    """Find and load project rules from AGENTS.md or CLAUDE.md.
    
    Searches for rules files in order of precedence (first found wins):
    1. AGENTS.md in repo root
    2. CLAUDE.md in repo root
    
    Returns the content or None if no rules file found.
    """
    candidates = [
        repo_root / 'AGENTS.md',
        repo_root / 'CLAUDE.md',
    ]
    
    for path in candidates:
        if path.exists():
            try:
                return path.read_text()
            except (OSError, IOError):
                pass
    
    return None


def build_prompt_with_rules(prompt_content: str, project_rules: Optional[str]) -> str:
    """Combine project rules with ralph prompt.
    
    If project rules exist, prepend them to the prompt with clear separation.
    This ensures the AI follows repo-specific conventions while executing ralph tasks.
    """
    if not project_rules:
        return prompt_content
    
    return f"""# Project Rules (from AGENTS.md)

The following rules are MANDATORY for this repository. Follow them strictly.

{project_rules}

---

# Ralph Task

{prompt_content}
"""


def get_current_branch() -> str:
    """Get current git branch name."""
    try:
        result = subprocess.run(
            ['git', 'branch', '--show-current'],
            capture_output=True, text=True, check=True
        )
        return result.stdout.strip()
    except subprocess.CalledProcessError:
        return 'unknown'


def count_running_opencode(repo_root: Path) -> int:
    """Count opencode processes spawned by ralph in this repo."""
    count = 0
    try:
        result = subprocess.run(['pgrep', '-x', 'opencode'], capture_output=True, text=True)
        for pid in result.stdout.strip().split('\n'):
            if not pid:
                continue
            try:
                # Check if it's in this repo
                cwd = Path(f'/proc/{pid}/cwd').resolve()
                if not str(cwd).startswith(str(repo_root)):
                    continue
                
                # Check if parent is ralph (python running ralph.py)
                ppid = Path(f'/proc/{pid}/stat').read_text().split()[3]
                parent_cmdline = Path(f'/proc/{ppid}/cmdline').read_bytes().decode('utf-8', errors='replace')
                if 'ralph' in parent_cmdline:
                    count += 1
            except (OSError, PermissionError, FileNotFoundError):
                pass
    except subprocess.CalledProcessError:
        pass
    return count


def parse_cost_line(line: str) -> Optional[tuple[float, int, int]]:
    """Parse a cost line from ralph-stream output.
    
    Returns (cost, tokens_in, tokens_out) or None if not a cost line.
    """
    match = re.search(r'Cost: \$([0-9.]+) \| Tokens: (\d+)in/(\d+)out', line)
    if match:
        return (float(match.group(1)), int(match.group(2)), int(match.group(3)))
    return None


# ============================================================================
# Prompt Merge Helpers
# ============================================================================

def prompt_merge_choice(filename: str) -> str:
    """Ask user how to handle an existing prompt file.
    
    Returns: 'merge', 'keep', or 'override'
    """
    print(f"\n{Colors.YELLOW}Found existing: {filename}{Colors.NC}")
    print("  [1] Auto-merge (use LLM to merge your customizations with new template)")
    print("  [2] Keep existing (don't modify)")
    print("  [3] Override with default (replace with new template)")
    
    while True:
        try:
            choice = input(f"{Colors.CYAN}Choice [1/2/3]: {Colors.NC}").strip()
            if choice == '1':
                return 'merge'
            elif choice == '2':
                return 'keep'
            elif choice == '3':
                return 'override'
            else:
                print(f"{Colors.RED}Invalid choice. Enter 1, 2, or 3.{Colors.NC}")
        except (EOFError, KeyboardInterrupt):
            print(f"\n{Colors.YELLOW}Keeping existing file.{Colors.NC}")
            return 'keep'


def llm_merge_prompts(existing_content: str, new_template: str, filename: str, repo_root: Path, profile_arg: Optional[str] = None) -> Optional[str]:
    """Use opencode to intelligently merge existing prompt customizations with new template.
    
    Returns merged content, or None if merge failed.
    """
    # Ensure profile is selected before using agent
    ensure_profile_selected(profile_arg)
    gcfg = get_global_config()
    model = gcfg.model_build
    
    merge_prompt = f'''You are merging two versions of a Ralph prompt file: {filename}

EXISTING (user's customized version):
```
{existing_content}
```

NEW TEMPLATE (latest default):
```
{new_template}
```

Your task:
1. Identify any customizations the user made to the existing version
2. Preserve those customizations while incorporating any new features/improvements from the template
3. If the existing version has the same content as the template, just return the template
4. Output ONLY the merged content, no explanations or markdown code blocks

Merged content:'''

    try:
        # Use ephemeral state directory to avoid polluting session list
        opencode_env = os.environ.copy()
        opencode_env['XDG_STATE_HOME'] = '/tmp/ralph-opencode-state'
        # Deny external directory access to fail fast instead of hanging on permission prompts
        opencode_env['OPENCODE_PERMISSION'] = json.dumps({
            "external_directory": "deny",
            "doom_loop": "deny"
        })
        
        result = subprocess.run(
            ['opencode', 'run', '--model', model, '--print', merge_prompt],
            capture_output=True,
            text=True,
            cwd=repo_root,
            timeout=120,
            env=opencode_env
        )
        
        if result.returncode == 0 and result.stdout.strip():
            merged = result.stdout.strip()
            # Remove any markdown code block wrappers if present
            if merged.startswith('```') and merged.endswith('```'):
                lines = merged.split('\n')
                merged = '\n'.join(lines[1:-1])
            return merged
        else:
            print(f"{Colors.RED}LLM merge failed: {result.stderr}{Colors.NC}")
            return None
    except subprocess.TimeoutExpired:
        print(f"{Colors.RED}LLM merge timed out{Colors.NC}")
        return None
    except FileNotFoundError:
        print(f"{Colors.RED}opencode not found - cannot perform LLM merge{Colors.NC}")
        return None
    except Exception as e:
        print(f"{Colors.RED}LLM merge error: {e}{Colors.NC}")
        return None


def handle_prompt_file(prompt_path: Path, new_content: str, repo_root: Path) -> None:
    """Handle creating or updating a prompt file with merge options."""
    if not prompt_path.exists():
        # Fresh file, just create it
        prompt_path.write_text(new_content)
        return
    
    existing_content = prompt_path.read_text()
    
    # If content is identical, skip
    if existing_content.strip() == new_content.strip():
        print(f"  {Colors.DIM}{prompt_path.name} - unchanged{Colors.NC}")
        return
    
    choice = prompt_merge_choice(prompt_path.name)
    
    if choice == 'keep':
        print(f"  {Colors.YELLOW}Keeping existing {prompt_path.name}{Colors.NC}")
        return
    elif choice == 'override':
        prompt_path.write_text(new_content)
        print(f"  {Colors.GREEN}Replaced {prompt_path.name} with default template{Colors.NC}")
        return
    elif choice == 'merge':
        print(f"  {Colors.CYAN}Merging {prompt_path.name} with LLM...{Colors.NC}")
        merged = llm_merge_prompts(existing_content, new_content, prompt_path.name, repo_root)
        if merged:
            prompt_path.write_text(merged)
            print(f"  {Colors.GREEN}Merged {prompt_path.name} successfully{Colors.NC}")
        else:
            print(f"  {Colors.YELLOW}Merge failed, keeping existing {prompt_path.name}{Colors.NC}")


# ============================================================================
# Commands
# ============================================================================

def cmd_init(config: RalphConfig):
    """Initialize ralph in current repo, or update prompts if already initialized."""
    is_update = config.ralph_dir.exists()
    
    if is_update:
        print(f"{Colors.BLUE}Updating Ralph in {config.repo_root}{Colors.NC}")
    else:
        print(f"{Colors.BLUE}Initializing Ralph in {config.repo_root}{Colors.NC}")
    
    config.ralph_dir.mkdir(parents=True, exist_ok=True)
    config.specs_dir.mkdir(parents=True, exist_ok=True)
    config.log_dir.mkdir(parents=True, exist_ok=True)

    # Define prompt templates
    # Note: {{SPEC_FILE}} is replaced at runtime with the target spec filename
    plan_prompt_template = '''\
## Target Spec: {{SPEC_FILE}}

1. Run `ralph query` to see current state
2. Read the spec file: `ralph/specs/{{SPEC_FILE}}`

## CRITICAL: Use Subagents for Research

Your context window is LIMITED. Do NOT read many files yourself.

**Launch subagents in parallel to research different aspects:**

```
Task: "Research how [aspect] is currently implemented. Find relevant files, understand the patterns used, and report back what exists and what's missing for [spec requirement]"
```

Launch multiple Task calls in a single message to parallelize research.

## Task: Gap Analysis for {{SPEC_FILE}}

Compare the spec against the CURRENT codebase and generate a task list:

1. Use subagents to study the spec and relevant source code thoroughly
2. For each requirement in the spec, check if it's already implemented
3. Create tasks ONLY for what's missing or broken
4. DO NOT implement anything - planning only

## Output

For each task identified, run:
```
ralph task add '{"name": "Short task name", "notes": "Implementation details", "accept": "How to verify", "deps": ["t-xxxx"]}'
```

Task fields:
- `name` (required): Short description of what to do (e.g., "Add unit tests for parser")
- `notes` (required): **DETAILED** implementation guidance - MUST include specific file paths and approach
- `accept` (required): **MEASURABLE** acceptance criteria - MUST specify concrete verification steps
- `deps` (optional): List of task IDs this task depends on

**CRITICAL: Notes MUST be detailed to minimize BUILD stage research.**

Good `notes` examples:
- "Modify src/aio/aio_combinators.c: Add valk_builtin_aio_within() that creates race between handle and sleep+timeout. Register in valk_lenv_put_builtins(). Pattern: race(handle, then(sleep(sys, ms), fail(timeout)))."
- "Create test/test_aio_within.valk: Test cases for timeout before completion, completion before timeout, and handle failure. Use aio/sleep for timing control."
- "Update src/parser.c line 450: Add 'aio/within' to builtin registration table after aio/race entry."

Bad `notes` examples (WILL BE REJECTED):
- "Add the feature" - no file paths, no approach
- "Implement aio/within" - vague, no details
- "Write tests" - which files? what to test?
- "Update code as needed" - no specific files

**CRITICAL: Acceptance criteria MUST be measurable and specific.**

Good `accept` examples:
- "pytest tests/test_parser.py passes"
- "`make build` exits with code 0"
- "file test/test_foo.valk exists and `make test` passes"
- "grep -c 'aio/within' src/builtins.c returns 1"
- "output contains 'Success' when running `./build/valk test.valk`"

Bad `accept` examples (WILL BE REJECTED):
- "works correctly" - too vague
- "tests pass" - which tests?
- "is implemented" - not measurable
- "feature works" - how do you verify?

**IMPORTANT**: Every task MUST have:
1. `notes` with SPECIFIC file paths and implementation approach (minimum 50 chars)
2. `accept` with MEASURABLE verification steps (minimum 15 chars)

Tasks without detailed `notes` will be REJECTED during validation.

The command returns the new task ID (e.g., "Task added: t-1a2b - ..."). Use this ID when other tasks depend on it.

Rules:
- Each task should be completable in ONE iteration
- Add tasks in dependency order - add prerequisite tasks first so you have their IDs
- Be specific - "Add X to Y" not "Improve Z"
- Tasks are for {{SPEC_FILE}} only
- `notes` MUST include specific file paths (e.g., src/foo.c, test/test_bar.valk)
- `accept` MUST be measurable (command to run, expected output, exit code)
- Use `deps` when a task requires another task to be done first

When done adding tasks, output:
```
[RALPH] PLAN_COMPLETE: Added N tasks for {{SPEC_FILE}}
```
'''

    build_prompt_template = '''\
# BUILD Stage

Implement the next pending task.

## Step 1: Get Task

Run `ralph query` to get current state. The `next.task` field shows:
- `name`: what to do
- `notes`: implementation hints (if provided)
- `accept`: how to verify it works (if provided)
- `reject`: why it was rejected (if this is a retry)

## Step 2: Check if Rejected Task

If `reject` field is present, this task was previously attempted and rejected by VERIFY:

1. **Read the rejection reason** - understand why it failed
2. **The code is already there** - don't start from scratch
3. **Fix the specific gap** - the rejection reason tells you what's wrong

Do NOT re-explore the whole codebase. Focus on fixing what's broken.

## Step 3: Understand Context

1. Read the spec file: `ralph/specs/<spec>`
2. Review `notes` for implementation hints
3. **Use subagents for research** - see below

## CRITICAL: Use Subagents for Codebase Research

Your context window is LIMITED. Do NOT read many files yourself - you will run out of context and be killed.

**For any research task, use the Task tool to spawn subagents:**

```
Task: "Find how X is implemented in the codebase. Search for Y, read relevant files, and report back:
1. Which files contain X
2. How it currently works
3. What would need to change for Z"
```

**When to use subagents:**
- Understanding how a feature currently works
- Finding all usages of a function/type
- Exploring unfamiliar parts of the codebase
- Any task requiring reading more than 2-3 files

**When NOT to use subagents:**
- You already know exactly which file to edit
- Making a small, targeted change
- Running tests or build commands

Each subagent gets a fresh context window. Use them liberally for exploration.

## Step 4: Implement

Build the feature/fix. Rules:
- Complete implementations only, no stubs
- No code comments unless explicitly requested

## Step 5: Check Acceptance Criteria

Before marking done, verify the task's acceptance criteria:
1. Check **only** the `accept` criteria for this task
2. Run any tests specified in the criteria
3. Do NOT re-read the full spec - that's VERIFY stage's job

If acceptance criteria pass, mark done. VERIFY stage will do the thorough spec check later.

## Step 6: Complete

```
ralph task done
```

This marks the task done and auto-commits.

## Discovering Issues - IMPORTANT

You MUST record any problems you notice, even if unrelated to the current task:
```
ralph issue add "description of issue"
```

**Always add an issue when you see:**
- Test warnings (TSAN, ASAN, valgrind warnings)
- Compiler warnings
- Code that "works but has problems" (memory leaks, thread leaks, etc.)
- TODOs or FIXMEs you encounter
- Potential bugs you notice while reading code
- Missing test coverage you observe

**Do NOT ignore problems** just because your current task passes. If you see something wrong, record it.

Issues are investigated later in the INVESTIGATE stage.

## Spec Ambiguities - CRITICAL

**Do NOT make design decisions yourself.** If the spec is ambiguous or conflicts with technical constraints:

1. **Log an issue** with the ambiguity:
   ```
   ralph issue add "Spec ambiguity: <what the spec says> vs <technical reality>. Options: (1) ... (2) ..."
   ```

2. **Skip the task** or implement a minimal stub that makes the conflict visible

3. **Do NOT "interpret" the spec** - your interpretation may be wrong

**Examples of spec ambiguities:**
- Spec requires X but the architecture doesn't support X
- Spec is vague about behavior in edge case Y
- Two parts of the spec contradict each other
- Spec assumes a capability that doesn't exist

**Wrong:** "The pragmatic interpretation is..." then implementing your guess
**Right:** `ralph issue add "Spec says X but Y prevents this. Need clarification."`

Design decisions belong to the user, not the agent.

## Progress Reporting

```
[RALPH] === START: <task name> ===
```

```
[RALPH] === DONE: <task name> ===
[RALPH] RESULT: <summary>
```

## EXIT after marking task done
'''

    verify_prompt_template = '''\
# VERIFY Stage

All tasks are done. Verify they meet their acceptance criteria.

## Step 1: Get State

Run `ralph query` to get:
- `spec`: the current spec name (e.g., "construct-mode.md")
- `tasks.done`: list of done tasks with their acceptance criteria

## Step 2: Verify Each Done Task

For EACH done task, spawn a subagent to verify:

```
Task: "Verify task '{task.name}' meets its acceptance criteria: {task.accept}

1. Search codebase for the implementation
2. Check if acceptance criteria is satisfied
3. Run any tests mentioned in criteria

Return JSON:
{
  \\"task_id\\": \\"{task.id}\\",
  \\"passed\\": true | false,
  \\"evidence\\": \\"<what you found>\\",
  \\"reason\\": \\"<why it failed>\\"  // only if passed=false
}"
```

**Run all verifications in parallel.**

## Step 3: Apply Results

### For each task:

**If passed** ‚Üí `ralph task accept <task-id>`

**If failed** ‚Üí Choose one:

1. **Implementation bug** (can be fixed):
   `ralph task reject <task-id> "<reason>"`

2. **Architectural blocker** (cannot be done):
   `ralph issue add "Task <task-id> blocked: <why>"`
   `ralph task delete <task-id>`
   
Signs of architectural blocker:
- "Cannot do X mid-execution"
- Same rejection reason recurring
- Requires changes outside this spec

## Step 4: Check for Gaps

Read the spec\'s **Acceptance Criteria section only** (not entire spec):
`ralph/specs/<spec-name>` - scroll to "## Acceptance Criteria"

For any unchecked criteria (`- [ ]`) not covered by existing tasks, research what's needed and create a well-defined task:
```
ralph task add \'{"name": "<specific action>", "notes": "<DETAILED: file paths + approach>", "accept": "<measurable verification>"}\\'
```

**IMPORTANT**: 
- `notes` MUST include SPECIFIC file paths and implementation approach (minimum 50 chars)
- `notes` should answer: Which files? What functions/lines? What pattern to use?
- `accept` MUST be measurable: command to run, expected exit code, or specific output to check
- Vague notes like "implement X" or acceptance like "works correctly" will be REJECTED

## Step 5: Final Decision

If all tasks accepted and no new tasks created:
```
[RALPH] SPEC_COMPLETE
```

Otherwise:
```
[RALPH] SPEC_INCOMPLETE: <summary>
```

## EXIT after completing
'''

    investigate_prompt_template = '''\
# INVESTIGATE Stage

Issues were discovered during build. Research and resolve ALL of them in parallel.

## Step 1: Get All Issues

Run `ralph query issues` to see all pending issues.

## Step 2: Parallel Investigation

Use the Task tool to investigate ALL issues in parallel. Launch one subagent per issue:

```
For each issue, launch a Task with prompt:
"Investigate this issue: <issue description>
Issue priority: <issue priority or 'medium' if not set>

1. Read relevant code to understand the problem
2. Determine root cause
3. Decide resolution:
   - If fix is non-trivial: describe the fix task needed
   - If fix is trivial: describe the simple fix
   - If out of scope: explain why

Return a JSON object:
{
  \\"issue_id\\": \\"<id>\\",
  \\"root_cause\\": \\"<what you found>\\",
  \\"resolution\\": \\"task\\" | \\"trivial\\" | \\"out_of_scope\\",
  \\"task\\": {  // only if resolution is \\"task\\"
    \\"name\\": \\"<fix description>\\",
    \\"notes\\": \\"<DETAILED: specific file paths, functions, and implementation approach - min 50 chars>\\",
    \\"accept\\": \\"<MEASURABLE: command + expected result, e.g. 'make test passes' or 'grep X file returns 1'>\\",
    \\"priority\\": \\"<inherit from issue priority above>\\"
  },
  \\"trivial_fix\\": \\"<description>\\"  // only if resolution is \\"trivial\\"
}
"
```

## Step 3: Collect Results and Apply

After all subagents complete:

1. Add all tasks in batch (include `created_from` to link back to issue, and `priority` from originating issue):
```
ralph task add \'{"name": "...", "notes": "...", "accept": "<measurable: command + expected result>", "created_from": "i-xxxx", "priority": "high|medium|low"}\'
ralph task add \'{"name": "...", "notes": "...", "accept": "<measurable: command + expected result>", "created_from": "i-yyyy", "priority": "high|medium|low"}\'
...
```

2. Clear all issues in one command:
```
ralph issue done-all
```

Or if only clearing specific issues:
```
ralph issue done-ids i-abc1 i-def2 i-ghi3
```

## Step 4: Report Summary

```
[RALPH] === INVESTIGATE COMPLETE ===
[RALPH] Processed: N issues
[RALPH] Tasks created: X
[RALPH] Trivial fixes: Y
[RALPH] Out of scope: Z
```

## Handling Auto-Generated Pattern Issues

Issues starting with "REPEATED REJECTION" or "COMMON FAILURE PATTERN" are auto-generated from rejection analysis.
These require special handling:

**For REPEATED REJECTION issues:**
1. The same task has failed 3+ times with similar errors
2. Read the spec and task to understand what's expected
3. Compare with rejection reasons to find the gap
4. Usually indicates: missing prerequisite, wrong approach, or spec ambiguity
5. Create a HIGH PRIORITY blocking task that addresses the root cause
6. Consider if the failing task's `deps` should include the new task

**For COMMON FAILURE PATTERN issues:**
1. Multiple different tasks fail with the same error type
2. This strongly indicates a missing prerequisite that all tasks need
3. Read the spec section about the failing functionality
4. The error message tells you what's missing (e.g., "argument count mismatch" = API changed)
5. Create a single HIGH PRIORITY task to fix the root cause
6. Mark existing failing tasks as depending on this new task using `ralph task add '{"deps": [...]}'`

**Example:**
If multiple tasks fail with "grep returns 0, expected 1" and they all involve `aio/then`, likely:
- The API wasn't changed to return handles yet
- A prerequisite C implementation task is missing
- Create: `ralph task add '{"name": "Refactor X to return handle", "priority": "high", "notes": "..."}'`

## IMPORTANT

- Launch ALL investigations in parallel using multiple Task tool calls in a single message
- Wait for all results before applying any changes
- Do NOT make code changes during investigation - only create tasks
- Use `ralph issue done-all` to clear all issues at once
- EXIT after all issues are resolved
'''

    decompose_prompt_template = '''\
# DECOMPOSE Stage

A task was killed because it was too large (exceeded context or timeout limits).
You must break it down into smaller subtasks.

## Step 1: Get the Failed Task

Run `ralph query` to see the task that needs decomposition.
The `next.task` field shows:
- `name`: The task that failed
- `kill_reason`: Why it was killed ("timeout" or "context_limit")
- `kill_log`: Path to the log from the failed iteration

## Step 2: Review the Failed Iteration Log (if available)

If `kill_log` is provided in the task, review it to understand what went wrong.

**CRITICAL**: The log file may be HUGE (it killed the previous iteration's context!). 
NEVER read the entire file. Always use head/tail:

```bash
# First check the size
wc -l <kill_log_path>

# Read ONLY the header (first 50 lines) - shows what task started
head -50 <kill_log_path>

# Read ONLY the tail (last 100 lines) - shows where it stopped  
tail -100 <kill_log_path>

# If you need to search for specific content
grep -n -E "error|Error|ERROR|failed|FAILED" <kill_log_path> | head -20
```

From this limited sample, determine:
- What work was started but not completed
- Where the iteration got stuck or ran out of context
- Which files were being modified
- Any partial progress that was made
- **What output flooded the context** (e.g., sanitizer output, verbose test logs)
  - This is important! Subtasks may need to suppress or redirect verbose output

If no `kill_log` is provided, skip this step and proceed to analyze the task based on its description.

## Step 3: Analyze the Task

Use subagents to understand what the task requires:

```
Task: "Analyze what's needed to implement: [task name]

Research the codebase and report:
1. Which files need to be modified
2. What are the distinct pieces of work
3. What order should they be done in
4. Any dependencies between pieces"
```

## Step 4: Create Subtasks

Break the original task into 2-5 smaller tasks that:
- Can each be completed in ONE iteration
- Have clear, specific scope
- Together accomplish the original task
- Account for any partial progress from the failed iteration

For each subtask, **include `parent` to link back to the original task**:
```
ralph task add \'{"name": "Specific subtask", "notes": "<DETAILED: file paths + approach, min 50 chars>", "accept": "<measurable: command + expected result>", "parent": "<original-task-id>"}\'
```

**IMPORTANT**: 
- `notes` MUST include specific file paths and implementation details (minimum 50 chars)
- `accept` MUST be measurable - specify command to run and expected result
- Example notes: "Modify src/foo.c lines 100-150: Extract bar() function to new file src/bar.c. Update includes."

Use `deps` to specify order if needed.

## Step 5: Remove the Original Task

After adding all subtasks, delete the original oversized task:
```
ralph task delete <task-id>
```

## Step 6: Report

```
[RALPH] === DECOMPOSE COMPLETE ===
[RALPH] Original: <original task name>
[RALPH] Kill reason: <timeout|context_limit>
[RALPH] Split into: N subtasks
```

Then EXIT to let the build loop process the new subtasks.

## Rules

- ALWAYS read the log file first to understand what happened
- Each subtask should be completable in ONE iteration (< 100k tokens)
- Be specific: "Add X to file Y" not "Implement feature Z"
- `accept` MUST be measurable (vague criteria like "works correctly" will be REJECTED)
- If a subtask is still too big, it will be killed and decomposed again
- DO NOT try to implement anything - just create the task breakdown
'''

    # Handle prompt files (with merge options if updating)
    if is_update:
        handle_prompt_file(config.prompt_plan, plan_prompt_template, config.repo_root)
        handle_prompt_file(config.prompt_build, build_prompt_template, config.repo_root)
        handle_prompt_file(config.prompt_verify, verify_prompt_template, config.repo_root)
        handle_prompt_file(config.prompt_investigate, investigate_prompt_template, config.repo_root)
        handle_prompt_file(config.prompt_decompose, decompose_prompt_template, config.repo_root)
    else:
        config.prompt_plan.write_text(plan_prompt_template)
        config.prompt_build.write_text(build_prompt_template)
        config.prompt_verify.write_text(verify_prompt_template)
        config.prompt_investigate.write_text(investigate_prompt_template)
        config.prompt_decompose.write_text(decompose_prompt_template)

    # Create example spec only on fresh init (preserve existing specs)
    if not is_update:
        (config.specs_dir / 'example.md').write_text('''\
# Example Specification

Delete this file and create your own specs.

## Overview

Describe what you want to build.

## Requirements

- Requirement 1
- Requirement 2

## Acceptance Criteria

- [ ] Criterion 1
- [ ] Criterion 2
''')

    # Initialize empty plan.jsonl on fresh init
    if not is_update and not config.plan_file.exists():
        save_state(config, RalphState())

    # Logs now go to /tmp/ralph-logs, no gitignore needed

    if is_update:
        print(f"{Colors.GREEN}Ralph updated!{Colors.NC}")
        print()
        print("Updated files:")
        print(f"  {config.ralph_dir}/")
        print("  ‚îú‚îÄ‚îÄ PROMPT_plan.md        (planning mode)")
        print("  ‚îú‚îÄ‚îÄ PROMPT_build.md       (build stage)")
        print("  ‚îú‚îÄ‚îÄ PROMPT_verify.md      (verify stage)")
        print("  ‚îî‚îÄ‚îÄ PROMPT_investigate.md (investigate stage)")
        print()
        print("Preserved:")
        print("  ‚îú‚îÄ‚îÄ plan.jsonl")
        print("  ‚îî‚îÄ‚îÄ specs/*")
    else:
        print(f"{Colors.GREEN}Ralph initialized!{Colors.NC}")
        print()
        print("Next steps:")
        print("  1. Write specs in ralph/specs/")
        print("  2. Run 'ralph plan <spec.md>' to generate tasks")
        print("  3. Run 'ralph' to start building")
        print()
        print("Files created:")
        print(f"  {config.ralph_dir}/")
        print("  ‚îú‚îÄ‚îÄ PROMPT_plan.md        (planning mode)")
        print("  ‚îú‚îÄ‚îÄ PROMPT_build.md       (build stage)")
        print("  ‚îú‚îÄ‚îÄ PROMPT_verify.md      (verify stage)")
        print("  ‚îú‚îÄ‚îÄ PROMPT_investigate.md (investigate stage)")
        print("  ‚îú‚îÄ‚îÄ plan.jsonl            (task/issue state)")
        print("  ‚îî‚îÄ‚îÄ specs/")
        print("      ‚îî‚îÄ‚îÄ example.md        (delete and add your own)")


def cmd_status(config: RalphConfig):
    """Show current status with full plan report."""
    if not config.ralph_dir.exists():
        print(f"{Colors.YELLOW}Ralph not initialized. Run 'ralph init' first.{Colors.NC}")
        return 1

    # Load state
    state = load_state(config)
    stage = state.get_stage()
    
    # Header
    print(f"{Colors.BLUE}{'='*60}{Colors.NC}")
    print(f"{Colors.BLUE}RALPH STATUS{Colors.NC}")
    print(f"{Colors.BLUE}{'='*60}{Colors.NC}")
    print()
    
    # Overview
    print(f"{Colors.CYAN}Overview{Colors.NC}")
    print(f"  Repo:   {config.repo_root}")
    print(f"  Branch: {get_current_branch()}")
    if state.spec:
        print(f"  Spec:   {Colors.CYAN}{state.spec}{Colors.NC}")
    else:
        print(f"  Spec:   {Colors.YELLOW}None - run 'ralph plan <spec.md>'{Colors.NC}")
    print(f"  Logs:   {Colors.DIM}{config.log_dir}{Colors.NC}")
    
    stage_colors = {
        'PLAN': Colors.YELLOW,
        'BUILD': Colors.GREEN,
        'VERIFY': Colors.CYAN,
        'INVESTIGATE': Colors.RED,
        'COMPLETE': Colors.GREEN,
    }
    print(f"  Stage:  {stage_colors.get(stage, '')}{stage}{Colors.NC}")
    
    # Running status
    running = count_running_opencode(config.repo_root)
    if running > 0:
        print(f"  Status: {Colors.GREEN}Running{Colors.NC} ({running} process(es))")
    else:
        print(f"  Status: {Colors.YELLOW}Stopped{Colors.NC}")
    
    # Validation check
    validation = validate_state(state, config)
    if not validation['valid']:
        print(f"  {Colors.RED}ERRORS: {len(validation['errors'])} validation issue(s){Colors.NC}")
    if validation['warnings']:
        print(f"  {Colors.YELLOW}Warnings: {len(validation['warnings'])}{Colors.NC}")
    print()
    
    # Tasks section
    pending = state.get_sorted_pending()
    done = state.done
    print(f"{Colors.CYAN}Tasks ({len(done)} done, {len(pending)} pending){Colors.NC}")
    print(f"{Colors.DIM}{'-'*60}{Colors.NC}")
    
    def print_task_details(task):
        """Print common task detail lines (accept, deps, relationships)."""
        if task.accept:
            print(f"    {Colors.DIM}accept: {task.accept[:70]}{'...' if len(task.accept) > 70 else ''}{Colors.NC}")
        if task.deps:
            print(f"    {Colors.DIM}deps: {', '.join(task.deps)}{Colors.NC}")
        # Relationship tracking
        relationships = []
        if task.parent:
            relationships.append(f"parent: {task.parent}")
        if task.created_from:
            relationships.append(f"from: {task.created_from}")
        if task.supersedes:
            relationships.append(f"supersedes: {task.supersedes}")
        if relationships:
            print(f"    {Colors.DIM}{', '.join(relationships)}{Colors.NC}")
    
    if done:
        for task in done:
            priority_str = f"[{task.priority}]" if task.priority else ""
            print(f"  {Colors.GREEN}‚úì{Colors.NC} {task.id} {priority_str} {task.name}")
            print_task_details(task)
    
    if pending:
        for task in pending:
            priority_str = f"[{task.priority}]" if task.priority else ""
            if task.reject_reason:
                print(f"  {Colors.RED}‚úó{Colors.NC} {task.id} {priority_str} {task.name} {Colors.RED}(retry){Colors.NC}")
                print(f"    {Colors.RED}reject: {task.reject_reason[:70]}{'...' if len(task.reject_reason) > 70 else ''}{Colors.NC}")
            elif task.kill_reason:
                print(f"  {Colors.YELLOW}!{Colors.NC} {task.id} {priority_str} {task.name} {Colors.YELLOW}(killed: {task.kill_reason}){Colors.NC}")
            else:
                print(f"  {Colors.YELLOW}‚óã{Colors.NC} {task.id} {priority_str} {task.name}")
            print_task_details(task)
    
    if not done and not pending:
        print(f"  {Colors.DIM}No tasks{Colors.NC}")
    print()
    
    # Issues section
    print(f"{Colors.CYAN}Issues ({len(state.issues)}){Colors.NC}")
    print(f"{Colors.DIM}{'-'*60}{Colors.NC}")
    if state.issues:
        for issue in state.issues:
            print(f"  {Colors.RED}‚Ä¢{Colors.NC} {issue.id}: {issue.desc}")
    else:
        print(f"  {Colors.DIM}No issues{Colors.NC}")
    print()
    
    # Tombstones section - rejected tasks
    rejected = [t for t in state.tombstones if t.tombstone_type == "reject"]
    if rejected:
        print(f"{Colors.CYAN}Rejected ({len(rejected)}){Colors.NC}")
        print(f"{Colors.DIM}{'-'*60}{Colors.NC}")
        for tombstone in rejected:
            name_str = f" {tombstone.name}" if tombstone.name else ""
            print(f"  {Colors.RED}‚úó{Colors.NC} {tombstone.id}{name_str}")
            
            # Show timestamp and commit
            time_info = []
            if tombstone.timestamp:
                # Show just the date and time, not full ISO format
                from datetime import datetime
                try:
                    dt = datetime.fromisoformat(tombstone.timestamp.replace('Z', '+00:00'))
                    time_info.append(dt.strftime('%Y-%m-%d %H:%M'))
                except:
                    time_info.append(tombstone.timestamp[:19])  # Fallback: first 19 chars
            if tombstone.done_at:
                time_info.append(f"commit {tombstone.done_at}")
            if time_info:
                print(f"    {Colors.DIM}{' | '.join(time_info)}{Colors.NC}")
            
            # Show full rejection reason (not truncated)
            if tombstone.reason:
                # Indent multi-line reasons
                reason_lines = tombstone.reason.split('\n')
                for i, line in enumerate(reason_lines):
                    prefix = "Reason: " if i == 0 else "        "
                    print(f"    {Colors.DIM}{prefix}{line}{Colors.NC}")
            
            # Show changed files
            if tombstone.changed_files:
                files_str = ', '.join(tombstone.changed_files[:5])
                if len(tombstone.changed_files) > 5:
                    files_str += f" (+{len(tombstone.changed_files) - 5} more)"
                print(f"    {Colors.DIM}Files: {files_str}{Colors.NC}")
            
            # Show log file link
            if tombstone.log_file:
                print(f"    {Colors.DIM}Log: {tombstone.log_file}{Colors.NC}")
            
            # Show iteration number
            if tombstone.iteration is not None:
                print(f"    {Colors.DIM}Iteration: {tombstone.iteration}{Colors.NC}")
            
            print()  # Blank line between tombstones
        print()
    
    # Tombstones section - accepted tasks
    accepted = [t for t in state.tombstones if t.tombstone_type == "accept"]
    if accepted:
        print(f"{Colors.CYAN}Accepted ({len(accepted)}){Colors.NC}")
        print(f"{Colors.DIM}{'-'*60}{Colors.NC}")
        for tombstone in accepted:
            name_str = f" {tombstone.name}" if tombstone.name else ""
            print(f"  {Colors.GREEN}‚úì{Colors.NC} {tombstone.id}{name_str}")
            
            # Show timestamp and commit
            time_info = []
            if tombstone.timestamp:
                from datetime import datetime
                try:
                    dt = datetime.fromisoformat(tombstone.timestamp.replace('Z', '+00:00'))
                    time_info.append(dt.strftime('%Y-%m-%d %H:%M'))
                except:
                    time_info.append(tombstone.timestamp[:19])
            if tombstone.done_at:
                time_info.append(f"commit {tombstone.done_at}")
            if time_info:
                print(f"    {Colors.DIM}{' | '.join(time_info)}{Colors.NC}")
            
            # Show full acceptance criteria (not truncated)
            if tombstone.reason:
                reason_lines = tombstone.reason.split('\n')
                for i, line in enumerate(reason_lines):
                    prefix = "Accept: " if i == 0 else "        "
                    print(f"    {Colors.DIM}{prefix}{line}{Colors.NC}")
            
            # Show changed files
            if tombstone.changed_files:
                files_str = ', '.join(tombstone.changed_files[:5])
                if len(tombstone.changed_files) > 5:
                    files_str += f" (+{len(tombstone.changed_files) - 5} more)"
                print(f"    {Colors.DIM}Files: {files_str}{Colors.NC}")
            
            print()  # Blank line between tombstones
        print()
    
    # Next action
    next_action = state.get_next()
    action = next_action['action']
    print(f"{Colors.CYAN}Next Action{Colors.NC}")
    print(f"{Colors.DIM}{'-'*60}{Colors.NC}")
    print(f"  {Colors.GREEN}{action}{Colors.NC}")
    if action in ('BUILD', 'DECOMPOSE') and next_action.get('task'):
        task = next_action['task']
        print(f"    Task: {task['id']} - {task['name']}")
        if task.get('accept'):
            print(f"    Accept: {task['accept'][:60]}{'...' if len(task['accept']) > 60 else ''}")
    elif action == 'INVESTIGATE' and next_action.get('items'):
        print(f"    {next_action['count']} issue(s) to investigate")
    elif action == 'VERIFY':
        print(f"    {len(done)} task(s) awaiting verification")
    elif next_action.get('item'):
        print(f"    {next_action['item']}")
    print()
    
    # Footer
    print(f"{Colors.DIM}Use 'ralph query' for JSON output, 'ralph watch' for live dashboard{Colors.NC}")


def cmd_validate(config: RalphConfig):
    """Validate plan.jsonl for common issues like dangling dependencies."""
    if not config.ralph_dir.exists():
        print(f"{Colors.YELLOW}Ralph not initialized. Run 'ralph init' first.{Colors.NC}")
        return 1
    
    state = load_state(config)
    validation = validate_state(state, config)
    
    print(f"{Colors.BLUE}{'='*60}{Colors.NC}")
    print(f"{Colors.BLUE}RALPH VALIDATION{Colors.NC}")
    print(f"{Colors.BLUE}{'='*60}{Colors.NC}")
    print()
    
    if validation['valid'] and not validation['warnings']:
        print(f"{Colors.GREEN}‚úì No issues found{Colors.NC}")
        print()
        accepted_tombstones = len([t for t in state.tombstones if t.tombstone_type == "accept"])
        rejected_tombstones = len([t for t in state.tombstones if t.tombstone_type == "reject"])
        legacy_accepted = len([t for t in state.tasks if t.status == 'a'])
        print(f"  Tasks: {len(state.pending)} pending, {len(state.done)} done")
        if legacy_accepted:
            print(f"  Legacy accepted (status=a): {legacy_accepted} {Colors.DIM}(consider running 'ralph compact'){Colors.NC}")
        print(f"  Tombstones: {accepted_tombstones} accepted, {rejected_tombstones} rejected")
        print(f"  Issues: {len(state.issues)}")
        return 0
    
    if validation['errors']:
        print(f"{Colors.RED}Errors ({len(validation['errors'])}){Colors.NC}")
        print(f"{Colors.DIM}{'-'*60}{Colors.NC}")
        for err in validation['errors']:
            print(f"  {Colors.RED}‚úó{Colors.NC} {err}")
        print()
    
    if validation['warnings']:
        print(f"{Colors.YELLOW}Warnings ({len(validation['warnings'])}){Colors.NC}")
        print(f"{Colors.DIM}{'-'*60}{Colors.NC}")
        for warn in validation['warnings']:
            print(f"  {Colors.YELLOW}!{Colors.NC} {warn}")
        print()
    
    if validation['errors']:
        print(f"{Colors.RED}Fix errors before running construct.{Colors.NC}")
        print(f"{Colors.DIM}Dangling deps can be fixed by:{Colors.NC}")
        print(f"{Colors.DIM}  1. Creating the missing task: ralph task add '{{\"id\": \"t-xxx\", ...}}'{Colors.NC}")
        print(f"{Colors.DIM}  2. Or removing the dep from the task in plan.jsonl{Colors.NC}")
        return 1
    
    return 0


def cmd_compact(config: RalphConfig):
    """Compact plan.jsonl by converting legacy accepted tasks to tombstones.
    
    This migrates tasks with status="a" to accept tombstones, then removes them.
    The tombstones preserve task IDs for dependency validation.
    """
    if not config.ralph_dir.exists():
        print(f"{Colors.YELLOW}Ralph not initialized. Run 'ralph init' first.{Colors.NC}")
        return 1
    
    state = load_state(config)
    
    # Find legacy accepted tasks (status = "a")
    legacy_accepted = [t for t in state.tasks if t.status == 'a']
    
    if not legacy_accepted:
        print(f"{Colors.GREEN}Nothing to compact - no legacy accepted tasks found{Colors.NC}")
        return 0
    
    print(f"{Colors.CYAN}Compacting plan.jsonl...{Colors.NC}")
    print(f"  Found {len(legacy_accepted)} legacy accepted tasks")
    
    # Convert each to a tombstone with full context
    for task in legacy_accepted:
        tombstone = create_tombstone(config, task, "accept", reason=task.accept or "")
        state.tombstones.append(tombstone)
        print(f"  {Colors.GREEN}‚úì{Colors.NC} {task.id} - {task.name}")
    
    # Remove legacy accepted from tasks
    legacy_ids = {t.id for t in legacy_accepted}
    state.tasks = [t for t in state.tasks if t.id not in legacy_ids]
    
    save_state(config, state, f"ralph: compact plan (migrate {len(legacy_accepted)} accepted tasks to tombstones)")
    
    print()
    print(f"{Colors.GREEN}Compacted {len(legacy_accepted)} tasks{Colors.NC}")
    return 0


def load_available_profiles() -> dict:
    """Load available profiles from config.toml.
    
    Returns dict of profile_name -> profile_config dict.
    """
    config_path = Path.home() / '.config' / 'ralph' / 'config.toml'
    
    if not config_path.exists():
        return {}
    
    try:
        try:
            import tomllib
        except ImportError:
            try:
                import tomli as tomllib
            except ImportError:
                return {}
        
        with open(config_path, 'rb') as f:
            data = tomllib.load(f)
        
        return data.get('profiles', {})
    except Exception:
        return {}


def describe_profile(name: str, profile: dict) -> tuple[str, str]:
    """Generate a human-readable description of a profile.
    
    Returns (description, model_info) tuple.
    """
    model_build = profile.get('model_build', profile.get('model', 'default'))
    
    # Extract just the model name without provider prefix
    model_short = model_build.split('/')[-1] if '/' in model_build else model_build
    
    # Generate description based on model
    if 'haiku' in model_build.lower():
        desc = "Haiku - cheapest option"
    elif 'opus' in model_build.lower():
        desc = "Opus - maximum capability"
    elif 'sonnet' in model_build.lower():
        desc = "Sonnet - good balance"
    else:
        desc = f"Custom ({model_short})"
    
    return desc, model_short


def select_profile_interactive() -> Optional[str]:
    """Interactive profile selector for cost optimization.
    
    Reads available profiles from ~/.config/ralph/config.toml and prompts
    user to select one before starting a construct run.
    
    Returns the selected profile name, or None if user wants to use default.
    """
    # Check if already set via environment
    env_profile = os.environ.get('RALPH_PROFILE', '')
    if env_profile:
        return None  # Already set, don't prompt
    
    # Check if stdin is a TTY (interactive)
    if not sys.stdin.isatty():
        return None  # Non-interactive, use default
    
    # Load profiles from config
    profiles = load_available_profiles()
    
    if not profiles:
        print(f"{Colors.DIM}No profiles found in ~/.config/ralph/config.toml{Colors.NC}")
        print(f"{Colors.DIM}Using default configuration{Colors.NC}")
        return None
    
    # Color rotation for profiles
    profile_colors = [Colors.GREEN, Colors.CYAN, Colors.YELLOW, Colors.BLUE, Colors.MAGENTA]
    
    print()
    print(f"{Colors.BLUE}{'‚îÄ'*60}{Colors.NC}")
    print(f"{Colors.BLUE}SELECT COST PROFILE{Colors.NC}")
    print(f"{Colors.BLUE}{'‚îÄ'*60}{Colors.NC}")
    print()
    print(f"{Colors.DIM}Choose a profile to optimize cost vs capability.{Colors.NC}")
    print(f"{Colors.DIM}Tip: Use --profile <name> or RALPH_PROFILE=<name> to skip this prompt.{Colors.NC}")
    print()
    
    # Display options
    options = list(profiles.keys())
    for i, name in enumerate(options):
        color = profile_colors[i % len(profile_colors)]
        desc, model_info = describe_profile(name, profiles[name])
        print(f"  {color}{i+1}. {name:12}{Colors.NC} - {desc}")
        print(f"     {Colors.DIM}Model: {model_info}{Colors.NC}")
    
    print()
    cfg = get_global_config()
    print(f"  {Colors.DIM}0. default{Colors.NC}      - Use [default] section (currently: {cfg.model})")
    print()
    
    # Get selection
    try:
        while True:
            response = input(f"Select profile [1-{len(options)}, 0=default]: ").strip()
            
            if response == '' or response == '0':
                print(f"{Colors.DIM}Using default configuration{Colors.NC}")
                return None
            
            # Check if they typed a profile name directly
            if response.lower() in profiles:
                selected = response.lower()
                desc, _ = describe_profile(selected, profiles[selected])
                print(f"{Colors.GREEN}Selected: {selected}{Colors.NC} - {desc}")
                return selected
            
            # Check numeric selection
            try:
                idx = int(response)
                if 1 <= idx <= len(options):
                    selected = options[idx - 1]
                    desc, _ = describe_profile(selected, profiles[selected])
                    print(f"{Colors.GREEN}Selected: {selected}{Colors.NC} - {desc}")
                    return selected
                else:
                    print(f"{Colors.RED}Invalid selection. Enter 1-{len(options)} or 0 for default.{Colors.NC}")
            except ValueError:
                print(f"{Colors.RED}Invalid input. Enter a number or profile name.{Colors.NC}")
                
    except KeyboardInterrupt:
        print(f"\n{Colors.YELLOW}Using default configuration{Colors.NC}")
        return None
    except EOFError:
        return None


def apply_profile(profile_name: str) -> None:
    """Apply a profile by setting RALPH_PROFILE and reloading config.
    
    Args:
        profile_name: Name of profile to apply (e.g., 'budget', 'balanced')
    """
    os.environ['RALPH_PROFILE'] = profile_name
    reload_global_config()


def ensure_profile_selected(profile_arg: Optional[str]) -> None:
    """Ensure a profile is selected before running an agent.
    
    Priority: --profile flag > RALPH_PROFILE env > interactive selection
    
    Args:
        profile_arg: Value of --profile flag, or None if not provided
    """
    if profile_arg:
        apply_profile(profile_arg)
        print(f"{Colors.GREEN}Using profile: {profile_arg}{Colors.NC}")
    elif not os.environ.get('RALPH_PROFILE'):
        selected_profile = select_profile_interactive()
        if selected_profile:
            apply_profile(selected_profile)
    
    # Validate models are configured
    gcfg = get_global_config()
    missing = []
    if not gcfg.model:
        missing.append('model')
    if not gcfg.model_build:
        missing.append('model_build')
    
    if missing:
        print(f"{Colors.RED}‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ{Colors.NC}")
        print(f"{Colors.RED}ERROR: Missing model config: {', '.join(missing)}{Colors.NC}")
        print(f"Set in ~/.config/ralph/config.toml:")
        print(f"  model = \"anthropic/claude-sonnet-4-20250514\"  # reasoning stages")
        print(f"  model_build = \"anthropic/claude-haiku-4-5-20251001\"  # BUILD stage")
        print(f"{Colors.RED}‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ{Colors.NC}")
        sys.exit(1)


def cmd_config():
    """Show current global configuration."""
    cfg = get_global_config()
    config_path = Path.home() / '.config' / 'ralph' / 'config.toml'
    
    print(f"{Colors.BLUE}{'='*60}{Colors.NC}")
    print(f"{Colors.BLUE}RALPH GLOBAL CONFIGURATION{Colors.NC}")
    print(f"{Colors.BLUE}{'='*60}{Colors.NC}")
    print()
    
    # Config file location
    print(f"{Colors.CYAN}Config File{Colors.NC}")
    if config_path.exists():
        print(f"  {Colors.GREEN}‚úì{Colors.NC} {config_path}")
    else:
        print(f"  {Colors.YELLOW}Not found:{Colors.NC} {config_path}")
        print(f"  {Colors.DIM}Using default values{Colors.NC}")
    print()
    
    # Active profile
    profile = cfg._profile_name
    profile_env = os.environ.get('RALPH_PROFILE', '')
    print(f"{Colors.CYAN}Active Profile{Colors.NC}")
    print(f"  Profile: {Colors.GREEN}{profile}{Colors.NC}")
    if profile_env:
        print(f"  {Colors.DIM}(set via RALPH_PROFILE={profile_env}){Colors.NC}")
    print()
    
    # Model settings
    print(f"{Colors.CYAN}Model Settings{Colors.NC}")
    print(f"  model: {Colors.GREEN}{cfg.model}{Colors.NC}")
    print()
    
    # Context limits
    print(f"{Colors.CYAN}Context Limits{Colors.NC}")
    print(f"  context_window:     {cfg.context_window:,} tokens")
    print(f"  context_warn_pct:   {cfg.context_warn_pct}%")
    print(f"  context_compact_pct: {cfg.context_compact_pct}%")
    print(f"  context_kill_pct:   {cfg.context_kill_pct}%")
    print()
    
    # Timeouts
    print(f"{Colors.CYAN}Timeouts{Colors.NC}")
    print(f"  stage_timeout_ms:     {cfg.stage_timeout_ms:,}ms ({cfg.stage_timeout_ms / 60000:.1f} min)")
    print(f"  iteration_timeout_ms: {cfg.iteration_timeout_ms:,}ms ({cfg.iteration_timeout_ms / 60000:.1f} min)")
    print()
    
    # Circuit breaker
    print(f"{Colors.CYAN}Circuit Breaker{Colors.NC}")
    print(f"  max_failures:       {cfg.max_failures}")
    print(f"  max_decompose_depth: {cfg.max_decompose_depth}")
    print()
    
    # Git settings
    print(f"{Colors.CYAN}Git Settings{Colors.NC}")
    print(f"  commit_prefix:        {cfg.commit_prefix}")
    print(f"  recent_commits_display: {cfg.recent_commits_display}")
    print()
    
    # UI settings
    print(f"{Colors.CYAN}UI Settings{Colors.NC}")
    print(f"  art_style:            {cfg.art_style}")
    print(f"  dashboard_buffer_lines: {cfg.dashboard_buffer_lines}")
    print()
    
    # Directories
    print(f"{Colors.CYAN}Directories{Colors.NC}")
    print(f"  ralph_dir: {cfg.ralph_dir}")
    print(f"  log_dir:   {cfg.log_dir}")
    print()
    
    # Example config
    print(f"{Colors.DIM}{'‚îÄ'*60}{Colors.NC}")
    print(f"{Colors.CYAN}Example config.toml:{Colors.NC}")
    print(f"""{Colors.DIM}
[default]
model = "anthropic/claude-sonnet-4"

[profiles.work]
model = "anthropic/claude-opus-4"

[profiles.home]
model = "openrouter/anthropic/claude-opus-4"

# Set RALPH_PROFILE=work or RALPH_PROFILE=home to switch
{Colors.NC}""")


@dataclass
class DashboardState:
    """State for rendering the dashboard."""
    config: RalphConfig
    branch: str
    cost: float = 0.0  # Parsed from stream
    tokens_in: int = 0
    tokens_out: int = 0
    context_tokens: int = 0  # Current context window size
    context_limit: int = DEFAULT_CONTEXT_WINDOW
    iteration: Optional[int] = None
    output_lines: list[str] = field(default_factory=list)
    is_running: bool = False
    running_count: int = 0
    footer_text: str = "Watching..."
    scroll_offset: int = 0  # For scrollable output
    auto_scroll: bool = True  # Auto-scroll to bottom on new output
    stage: str = ""  # Current stage: PLAN, BUILD, VERIFY, INVESTIGATE, COMPLETE
    kills_timeout: int = 0
    kills_context: int = 0
    last_kill_reason: str = ""
    last_kill_activity: str = ""
    skeleton_frame: Optional[int] = None  # Current skeleton animation frame (None = not showing)
    ralph_state: Optional['RalphState'] = None  # Cached ralph state (to avoid loading every frame)


# =============================================================================
# Textual TUI Application
# =============================================================================
# Uses Textual framework for smooth, optimized rendering with built-in:
# - Double-buffered rendering with character-level diffing
# - Smooth scrolling with mouse wheel support
# - Full ANSI color and emoji preservation
# - Reactive UI updates

def _create_textual_app():
    """Create and return the Textual app class. Lazy import to avoid startup cost."""
    from textual.app import App, ComposeResult
    from textual.containers import Container, Horizontal, Vertical, ScrollableContainer
    from textual.widgets import Static, Footer, Header, RichLog
    from textual.reactive import reactive
    from textual.binding import Binding
    from textual import work
    from textual.worker import Worker, get_current_worker
    from rich.text import Text
    from rich.console import Console
    from rich.markup import escape
    import asyncio

    class OutputLog(RichLog):
        """Scrollable output log that preserves ANSI colors."""
        
        BINDINGS = [
            Binding("g", "scroll_home", "Top", show=False),
            Binding("G", "scroll_end", "Bottom", show=False),
            Binding("d", "page_down", "Page Down", show=False),
            Binding("u", "page_up", "Page Up", show=False),
            Binding("ctrl+d", "page_down", "Page Down", show=False),
            Binding("ctrl+u", "page_up", "Page Up", show=False),
        ]
        
        def __init__(self, **kwargs):
            super().__init__(highlight=False, markup=False, wrap=False, auto_scroll=True, **kwargs)
            self._follow_mode = True
            self._pending_scroll = 0  # Accumulate scroll delta
            self._scroll_timer = None
        
        @property 
        def follow_mode(self) -> bool:
            return self._follow_mode
        
        @follow_mode.setter
        def follow_mode(self, value: bool):
            self._follow_mode = value
            self.auto_scroll = value
        
        def toggle_follow(self):
            self.follow_mode = not self.follow_mode
            if self.follow_mode:
                self.scroll_end(animate=False)
        
        def _flush_scroll(self):
            """Apply accumulated scroll and reset."""
            if self._pending_scroll != 0:
                self.scroll_relative(y=self._pending_scroll, animate=False)
                self.follow_mode = False
                self._pending_scroll = 0
            self._scroll_timer = None
        
        def on_key(self, event) -> None:
            """Handle j/k with coalescing for fast key repeat."""
            if event.key == 'j':
                self._pending_scroll += 1
                event.prevent_default()
                event.stop()
            elif event.key == 'k':
                self._pending_scroll -= 1
                event.prevent_default()
                event.stop()
            else:
                return  # Let other keys bubble up
            
            # Schedule flush on next frame if not already scheduled
            if self._scroll_timer is None:
                self._scroll_timer = self.set_timer(0.016, self._flush_scroll)  # ~60fps
        
        def action_page_down(self):
            self._flush_scroll()  # Apply any pending scroll first
            self.scroll_relative(y=self.size.height // 2, animate=False)
            self.follow_mode = False
        
        def action_page_up(self):
            self._flush_scroll()
            self.scroll_relative(y=-self.size.height // 2, animate=False)
            self.follow_mode = False
        
        def action_scroll_home(self):
            self._flush_scroll()
            self.scroll_home(animate=False)
            self.follow_mode = False
        
        def action_scroll_end(self):
            self._flush_scroll()
            self.scroll_end(animate=False)
            self.follow_mode = True
        
        def on_mouse_scroll_down(self, event) -> None:
            self.follow_mode = False
        
        def on_mouse_scroll_up(self, event) -> None:
            self.follow_mode = False

    class RalphArtWidget(Static):
        """Widget to display Ralph ASCII art with colors."""
        
        DEFAULT_CSS = """
        RalphArtWidget {
            width: auto;
            height: auto;
        }
        """
        
        def __init__(self, art_lines: list[str], **kwargs):
            # Art already has ANSI codes, convert to Rich Text
            super().__init__(**kwargs)
            self._art_lines = art_lines
        
        def render(self):
            return Text.from_ansi('\n'.join(self._art_lines))

    class StatusPanel(Static):
        """Status information panel."""
        
        DEFAULT_CSS = """
        StatusPanel {
            width: 100%;
            height: auto;
            padding: 0 1;
        }
        """
        
        branch = reactive("")
        status_text = reactive("")
        stage_text = reactive("")
        cost_text = reactive("")
        context_text = reactive("")
        progress_text = reactive("")
        spec_text = reactive("")
        task_text = reactive("")
        kill_text = reactive("")
        
        def render(self):
            lines = []
            if self.branch:
                lines.append(f"[green]Branch:[/] {escape(self.branch)}")
            if self.status_text:
                lines.append(self.status_text)
            if self.stage_text:
                lines.append(self.stage_text)
            if self.cost_text:
                lines.append(self.cost_text)
            if self.context_text:
                lines.append(self.context_text)
            lines.append("")
            if self.progress_text:
                lines.append(self.progress_text)
            lines.append("")
            if self.spec_text:
                lines.append(self.spec_text)
            if self.task_text:
                lines.append(f"[green]Task:[/]")
                lines.append(f"  {escape(self.task_text)}")
            if self.kill_text:
                lines.append("")
                lines.append(self.kill_text)
            return Text.from_markup('\n'.join(lines))

    class IssuesPanel(Static):
        """Issues display panel."""
        
        DEFAULT_CSS = """
        IssuesPanel {
            width: 100%;
            height: auto;
            padding: 0 1;
            display: none;
        }
        IssuesPanel.visible {
            display: block;
        }
        """
        
        def __init__(self, **kwargs):
            super().__init__(**kwargs)
            self._issues = []
            self._open_count = 0
            self._fixed_count = 0
        
        def update_issues(self, issues: list, open_count: int, fixed_count: int):
            self._issues = issues[:5]
            self._open_count = open_count
            self._fixed_count = fixed_count
            if self._issues:
                self.add_class("visible")
            else:
                self.remove_class("visible")
            self.refresh()
        
        def render(self):
            if not self._issues:
                return ""
            lines = [f"[yellow]Issues:[/] ({self._open_count} open, {self._fixed_count} fixed)"]
            for status, text in self._issues:
                # Strip **[STATUS]** markers
                text = re.sub(r'^\*\*\[[A-Z_]+\]\*\*\s*', '', text)
                if status == 'fixed':
                    lines.append(f"  [green]FIXED[/] {escape(text[:60])}")
                else:
                    lines.append(f"  [red]OPEN[/]  {escape(text[:60])}")
            return Text.from_markup('\n'.join(lines))

    class RalphDashboard(App):
        """Main Ralph Wiggum dashboard application."""
        
        TITLE = "Ralph Wiggum"
        
        CSS = """
        Screen {
            background: $surface;
        }
        
        #header-bar {
            background: $primary;
            color: $text;
            height: 3;
            padding: 0 1;
            content-align: center middle;
        }
        
        #header-bar Static {
            text-style: bold;
            width: 100%;
            content-align: center middle;
        }
        
        #main-content {
            height: 1fr;
        }
        
        #info-panel {
            height: auto;
            max-height: 50%;
            padding: 1 0;
        }
        
        #ralph-section {
            height: auto;
            width: 100%;
            padding: 0 1;
        }
        
        #ralph-art {
            width: auto;
            min-width: 20;
        }
        
        #separator {
            width: 1;
            height: 100%;
            margin: 0 1;
        }
        
        #status {
            width: 1fr;
        }
        
        #divider {
            height: 1;
            width: 100%;
            border-top: solid $primary-lighten-2;
        }
        
        #issues {
            height: auto;
            max-height: 8;
        }
        
        #output-section {
            height: 1fr;
            border-top: solid $primary-lighten-2;
        }
        
        #output-header {
            height: 1;
            padding: 0 1;
            background: $surface-darken-1;
        }
        
        #output-log {
            height: 1fr;
            padding: 0 1;
        }
        
        #footer-bar {
            height: 1;
            background: $surface-darken-1;
            padding: 0 1;
        }
        
        .follow-on {
            color: $success;
        }
        
        .follow-off {
            color: $warning;
        }
        """
        
        BINDINGS = [
            Binding("q", "quit", "Quit"),
            Binding("f", "toggle_follow", "Follow"),
            Binding("j", "focus_log_down", "Down", show=False),
            Binding("k", "focus_log_up", "Up", show=False),
        ]
        
        def __init__(self, config: 'RalphConfig', watch_mode: bool = False, 
                     iteration: Optional[int] = None, **kwargs):
            super().__init__(**kwargs)
            self._config = config
            self._watch_mode = watch_mode
            self._iteration = iteration
            self._cost = 0.0
            self._tokens_in = 0
            self._tokens_out = 0
            self._context_tokens = 0
            self._context_limit = DEFAULT_CONTEXT_WINDOW
            self._branch = ""
            self._is_running = False
            self._running_count = 0
            self._output_lines: deque = deque(maxlen=2000)
            self._fifo_fd = None
            self._process = None  # For run mode
            self._output_buffer = None  # For run mode
            self._stop_requested = False
            self._kills_timeout = 0
            self._kills_context = 0
            self._last_kill_reason = ""
            self._last_kill_activity = ""
        
        def compose(self) -> ComposeResult:
            # Header
            with Container(id="header-bar"):
                yield Static(self._get_title())
            
            # Main content area
            with Vertical(id="main-content"):
                # Info panel (Ralph + status)
                with Vertical(id="info-panel"):
                    with Horizontal(id="ralph-section"):
                        yield RalphArtWidget(RALPH_ART if RALPH_ART else [], id="ralph-art")
                        yield Static("‚îÇ", id="separator")
                        yield StatusPanel(id="status")
                    yield IssuesPanel(id="issues")
                
                # Output section
                with Vertical(id="output-section"):
                    yield Static("Output: [FOLLOW]", id="output-header")
                    yield OutputLog(id="output-log")
            
            # Footer
            yield Static(" q:quit  j/k:scroll  g/G:top/bottom  f:follow  d/u:page", id="footer-bar")
        
        def _get_title(self) -> str:
            ts = datetime.now().strftime('%H:%M:%S')
            kills_str = ""
            if self._kills_timeout > 0 or self._kills_context > 0:
                parts = []
                if self._kills_timeout > 0:
                    parts.append(f"T:{self._kills_timeout}")
                if self._kills_context > 0:
                    parts.append(f"C:{self._kills_context}")
                kills_str = f" | Kills: {' '.join(parts)}"
            if self._iteration is not None:
                return f"RALPH WIGGUM - Iteration {self._iteration} - {ts}{kills_str}"
            return f"RALPH WIGGUM - {ts}{kills_str}"
        
        def on_mount(self) -> None:
            """Start background tasks when app mounts."""
            self._branch = get_current_branch()
            
            # Start update loop
            self.set_interval(0.1, self._update_display)
            
            if self._watch_mode:
                # Start FIFO reader for watch mode
                self._start_fifo_reader()
            
            # Initial display update
            self._update_status_panel()
        
        def _start_fifo_reader(self):
            """Start reading from FIFO in background."""
            @work(thread=True, exclusive=True)
            async def read_fifo(self):
                while not self._stop_requested:
                    # Try to open FIFO if not open
                    if self._fifo_fd is None and self._config.output_fifo.exists():
                        try:
                            self._fifo_fd = os.open(str(self._config.output_fifo), os.O_RDWR | os.O_NONBLOCK)
                        except OSError:
                            pass
                    
                    # Read data
                    if self._fifo_fd is not None:
                        try:
                            ready, _, _ = select.select([self._fifo_fd], [], [], 0.05)
                            if ready:
                                data = os.read(self._fifo_fd, 8192)
                                if data:
                                    for line in data.decode('utf-8', errors='replace').splitlines():
                                        if line:
                                            self._output_lines.append(line)
                                            # Parse cost info from stream
                                            cost_info = parse_cost_line(line)
                                            if cost_info:
                                                self._cost = cost_info[0]
                                                self._tokens_in = cost_info[1]
                                                self._tokens_out = cost_info[2]
                                                self._context_tokens = cost_info[1]  # input tokens = context size
                                            # Post to main thread
                                            self.call_from_thread(self._append_output, line)
                        except OSError:
                            if self._fifo_fd is not None:
                                try:
                                    os.close(self._fifo_fd)
                                except OSError:
                                    pass
                            self._fifo_fd = None
                    else:
                        await asyncio.sleep(0.1)
            
            read_fifo(self)
        
        def _append_output(self, line: str):
            """Append a line to output log (called from main thread)."""
            log = self.query_one("#output-log", OutputLog)
            # Write with ANSI preserved - RichLog will render it
            log.write(Text.from_ansi(line))
        
        def _update_display(self):
            """Periodic display update."""
            # Update iteration from runtime file (written by construct/run)
            if self._watch_mode:
                self._iteration = read_runtime_iteration(self._config)
            
            # Update title with current time
            header = self.query_one("#header-bar Static", Static)
            header.update(self._get_title())
            
            # Update running status
            if self._watch_mode:
                self._running_count = count_running_opencode(self._config.repo_root)
                self._is_running = self._running_count > 0
            
            self._update_status_panel()
            self._update_output_header()
        
        def _update_status_panel(self):
            """Update the status panel."""
            status = self.query_one("#status", StatusPanel)
            state = load_state(self._config)
            
            status.branch = self._branch
            
            if self._is_running:
                if self._running_count > 0:
                    status.status_text = f"[green]Status:[/] Running ({self._running_count})"
                else:
                    status.status_text = "[green]Status:[/] Running"
            else:
                status.status_text = "[yellow]Status:[/] Stopped"
            
            # Show current stage with color coding
            stage = state.get_stage()
            stage_colors = {
                'PLAN': 'magenta',
                'BUILD': 'cyan',
                'VERIFY': 'yellow',
                'INVESTIGATE': 'red',
                'COMPLETE': 'green',
            }
            color = stage_colors.get(stage, 'white')
            status.stage_text = f"[green]Stage:[/] [{color}]{stage}[/]"
            
            if self._cost > 0:
                status.cost_text = f"[cyan]Cost:[/] ${self._cost:.4f}"
            else:
                status.cost_text = f"[cyan]Cost:[/] --"
            
            # Show context usage
            if self._context_tokens > 0:
                pct = self._context_tokens / self._context_limit * 100
                if pct >= 90:
                    color = "red"
                elif pct >= 70:
                    color = "yellow"
                else:
                    color = "cyan"
                status.context_text = f"[{color}]Context:[/] {self._context_tokens:,} / {self._context_limit:,} ({pct:.0f}%)"
            else:
                status.context_text = ""
            
            # Show last kill reason if any
            if self._last_kill_reason:
                status.kill_text = f"[red]Last Kill:[/] {self._last_kill_reason}"
                if self._last_kill_activity:
                    status.kill_text += f" @ {self._last_kill_activity}"
            else:
                status.kill_text = ""
            
            pending = len(state.pending)
            done = len(state.done)
            status.progress_text = f"[green]Progress:[/] {done} done, {pending} pending"
            
            if plan['current_spec']:
                status.spec_text = f"[green]Spec:[/] {plan['current_spec']}"
            else:
                status.spec_text = ""
            
            status.task_text = plan['next_task'] if plan['next_task'] else "(no pending tasks)"
            
            # Update issues
            issues_panel = self.query_one("#issues", IssuesPanel)
            issues_panel.update_issues(
                plan['issues']['items'],
                plan['issues']['open'],
                plan['issues']['fixed']
            )
        
        def _update_output_header(self):
            """Update output header with scroll/follow status."""
            log = self.query_one("#output-log", OutputLog)
            header = self.query_one("#output-header", Static)
            
            if log.follow_mode:
                header.update("Output: [green][FOLLOW][/]")
            else:
                header.update("Output: [yellow][SCROLL][/]")
        
        def action_toggle_follow(self):
            """Toggle follow mode."""
            log = self.query_one("#output-log", OutputLog)
            log.toggle_follow()
            self._update_output_header()
        
        def action_focus_log_down(self):
            """Scroll log down."""
            log = self.query_one("#output-log", OutputLog)
            log.action_scroll_down()
            self._update_output_header()
        
        def action_focus_log_up(self):
            """Scroll log up."""
            log = self.query_one("#output-log", OutputLog)
            log.action_scroll_up()
            self._update_output_header()
        
        def action_quit(self):
            """Quit the application."""
            self._stop_requested = True
            if self._fifo_fd is not None:
                try:
                    os.close(self._fifo_fd)
                except OSError:
                    pass
            self.exit()
        
        # Methods for run mode (not watch mode)
        def set_process(self, process, output_buffer: 'OutputBuffer'):
            """Set the process to monitor (for run mode)."""
            self._process = process
            self._output_buffer = output_buffer
            self._is_running = True
        
        def add_output_line(self, line: str):
            """Add a line to output (for run mode, called from output thread)."""
            self._output_lines.append(line)
            self.call_from_thread(self._append_output, line)
        
        def check_process_done(self) -> Optional[int]:
            """Check if process is done, return exit code or None."""
            if self._process is not None:
                ret = self._process.poll()
                if ret is not None:
                    self._is_running = False
                    return ret
            return None

    return RalphDashboard, OutputLog


class FallbackDashboard:
    """Shared ANSI fallback dashboard for watch and build modes."""
    
    def __init__(self, config: RalphConfig, iteration: Optional[int] = None):
        self.config = config
        self.iteration = iteration
        self.output_lines: deque = deque(maxlen=2000)
        self.scroll_offset = 0
        self.auto_scroll = True
        self.old_settings = None
        self.term_width = 80
        self.term_height = 24
        
        # Cached data
        self.cost = 0.0
        self.tokens_in = 0
        self.tokens_out = 0
        self.context_tokens = 0
        self.context_limit = DEFAULT_CONTEXT_WINDOW
        self.branch = ""
        self.is_running = False
        self.running_count = 0
        self.kills_timeout = 0
        self.kills_context = 0
        self.last_kill_reason = ""
        self.last_kill_activity = ""
        self.skeleton_frame: Optional[int] = None  # Current skeleton animation frame
        self.ralph_state: Optional[RalphState] = None  # Cached ralph state
    
    def get_input(self) -> Optional[str | tuple[str, int]]:
        """Non-blocking keyboard input with coalescing for scroll keys.
        
        Returns:
            - None if no input
            - str for single actions ('quit', 'page_down', etc.)
            - ('scroll', delta) for coalesced j/k scroll (delta can be negative)
        """
        scroll_delta = 0
        last_action = None
        
        try:
            # Drain all available input and coalesce scroll keys
            while True:
                ready, _, _ = select.select([sys.stdin], [], [], 0)
                if not ready:
                    break
                    
                ch = sys.stdin.read(1)
                if ch == 'q' or ch == 'Q':
                    return 'quit'  # Quit takes priority, return immediately
                elif ch == 'j':
                    scroll_delta += 1
                elif ch == 'k':
                    scroll_delta -= 1
                elif ch == 'g':
                    last_action = 'scroll_top'
                    scroll_delta = 0  # Reset scroll delta, jump takes priority
                elif ch == 'G':
                    last_action = 'scroll_bottom'
                    scroll_delta = 0
                elif ch == 'd':
                    last_action = 'page_down'
                elif ch == 'u':
                    last_action = 'page_up'
                elif ch == 'f' or ch == 'F':
                    last_action = 'toggle_follow'
                elif ch == '\x1b':  # Escape sequence
                    ready2, _, _ = select.select([sys.stdin], [], [], 0.01)
                    if ready2:
                        seq = sys.stdin.read(2)
                        if seq == '[A':
                            scroll_delta -= 1
                        elif seq == '[B':
                            scroll_delta += 1
                        elif seq == '[5':  # Page up
                            sys.stdin.read(1)  # consume ~
                            last_action = 'page_up'
                        elif seq == '[6':  # Page down
                            sys.stdin.read(1)  # consume ~
                            last_action = 'page_down'
        except:
            pass
        
        # Return coalesced scroll if any, otherwise last action
        if scroll_delta != 0:
            return ('scroll', scroll_delta)
        return last_action
    
    def handle_action(self, action) -> bool:
        """Handle a keyboard action. Returns True if should quit.
        
        Args:
            action: Either a string action or ('scroll', delta) tuple for coalesced scroll.
        """
        import shutil
        self.term_width, self.term_height = shutil.get_terminal_size((80, 24))
        viewport_height = max(1, self.term_height - 20)
        max_offset = max(0, len(self.output_lines) - viewport_height)
        
        # Handle coalesced scroll tuple
        if isinstance(action, tuple) and action[0] == 'scroll':
            delta = action[1]
            self.scroll_offset = max(0, min(self.scroll_offset + delta, max_offset))
            self.auto_scroll = (self.scroll_offset >= max_offset)
            return False
        
        if action == 'quit':
            return True
        elif action == 'scroll_top':
            self.scroll_offset = 0
            self.auto_scroll = False
        elif action == 'scroll_bottom':
            self.scroll_offset = max_offset
            self.auto_scroll = True
        elif action == 'page_down':
            self.scroll_offset = min(self.scroll_offset + viewport_height // 2, max_offset)
            self.auto_scroll = (self.scroll_offset >= max_offset)
        elif action == 'page_up':
            self.scroll_offset = max(self.scroll_offset - viewport_height // 2, 0)
            self.auto_scroll = False
        elif action == 'toggle_follow':
            self.auto_scroll = not self.auto_scroll
            if self.auto_scroll:
                self.scroll_offset = max_offset
        return False
    
    def render(self):
        """Render the dashboard."""
        import shutil
        self.term_width, self.term_height = shutil.get_terminal_size((80, 24))
        viewport_height = max(1, self.term_height - 20)
        
        # Auto-scroll if enabled
        if self.auto_scroll:
            self.scroll_offset = max(0, len(self.output_lines) - viewport_height)
        
        # Get visible output slice
        visible_output = list(self.output_lines)[self.scroll_offset:self.scroll_offset + viewport_height]
        
        # Build scroll indicator
        if len(self.output_lines) > viewport_height:
            scroll_info = f"[{self.scroll_offset + 1}-{min(self.scroll_offset + viewport_height, len(self.output_lines))}/{len(self.output_lines)}]"
            scroll_info += " FOLLOW" if self.auto_scroll else " SCROLL"
        else:
            scroll_info = "FOLLOW" if self.auto_scroll else ""
        
        state = DashboardState(
            config=self.config,
            branch=self.branch,
            cost=self.cost,
            tokens_in=self.tokens_in,
            tokens_out=self.tokens_out,
            context_tokens=self.context_tokens,
            context_limit=self.context_limit,
            iteration=self.iteration,
            output_lines=visible_output,
            is_running=self.is_running,
            running_count=self.running_count,
            footer_text=f"q:quit j/k:scroll g/G:top/bot f:follow | {scroll_info}",
            kills_timeout=self.kills_timeout,
            kills_context=self.kills_context,
            last_kill_reason=self.last_kill_reason,
            last_kill_activity=self.last_kill_activity,
            skeleton_frame=self.skeleton_frame,
            ralph_state=self.ralph_state
        )
        
        # Move cursor to top and render
        sys.stdout.write('\033[H')
        lines = render_dashboard(state, self.term_width, self.term_height)
        sys.stdout.write('\n'.join(lines))
        sys.stdout.flush()
    
    def enter(self):
        """Enter dashboard mode - set up terminal."""
        import termios
        self.old_settings = termios.tcgetattr(sys.stdin)
        new_settings = termios.tcgetattr(sys.stdin)
        new_settings[3] = new_settings[3] & ~termios.ECHO
        new_settings[3] = new_settings[3] & ~termios.ICANON
        termios.tcsetattr(sys.stdin, termios.TCSANOW, new_settings)
        
        sys.stdout.write('\033[?1049h')  # Alternate screen
        sys.stdout.write('\033[?25l')    # Hide cursor
        sys.stdout.flush()
    
    def exit(self):
        """Exit dashboard mode - restore terminal."""
        import termios
        if self.old_settings:
            termios.tcsetattr(sys.stdin, termios.TCSADRAIN, self.old_settings)
        sys.stdout.write('\033[?25h')  # Show cursor
        sys.stdout.write('\033[?1049l')  # Exit alternate screen
        sys.stdout.flush()
    
    def add_line(self, line: str):
        """Add an output line."""
        # Handle heartbeat messages - update skeleton animation frame
        if line.startswith('\x01HEARTBEAT:'):
            try:
                self.skeleton_frame = int(line.split(':')[1])
            except (IndexError, ValueError):
                self.skeleton_frame = 0
            return
        # Filter out hidden metrics lines
        if line.startswith('\x00'):
            return
        # Clear skeleton when real content arrives
        self.skeleton_frame = None
        self.output_lines.append(line)
        # Parse cost info
        cost_info = parse_cost_line(line)
        if cost_info:
            self.cost = cost_info[0]
            self.tokens_in = cost_info[1]
            self.tokens_out = cost_info[2]
            self.context_tokens = cost_info[1]  # input tokens = context size
    
    def run_loop(self, poll_data, on_quit=None, update_state=None):
        """Unified main loop for dashboard rendering.
        
        Args:
            poll_data: Callable that returns list of new lines (or None to continue).
                       Return empty list if no new data. Raise StopIteration to exit.
            on_quit: Optional callable when user presses quit. Return value is loop return value.
            update_state: Optional callable to update dashboard state each iteration.
        
        Returns:
            Return value from on_quit, or None if loop exits normally.
        """
        ANIMATION_FPS = 30
        FRAME_DURATION = 1.0 / ANIMATION_FPS
        SKELETON_DELAY = 0.5
        STATE_REFRESH_INTERVAL = 1.0  # Refresh ralph_state every 1s, not every frame
        
        last_activity_time = time.time()
        animation_start_time = 0.0
        last_output_count = len(self.output_lines)
        last_state_refresh = 0.0
        
        self.enter()
        
        try:
            while True:
                now = time.time()
                
                # Poll for new data
                try:
                    new_lines = poll_data()
                except StopIteration:
                    break
                
                # Process new lines
                if new_lines:
                    for line in new_lines:
                        self.add_line(line)
                    last_activity_time = now
                
                # Handle skeleton animation
                if len(self.output_lines) != last_output_count:
                    # New content arrived, clear skeleton
                    self.skeleton_frame = None
                    last_output_count = len(self.output_lines)
                    last_activity_time = now
                elif now - last_activity_time > SKELETON_DELAY and self.is_running:
                    # No new content, show skeleton
                    if self.skeleton_frame is None:
                        animation_start_time = now
                    elapsed = now - animation_start_time
                    self.skeleton_frame = int(elapsed * ANIMATION_FPS) % len(SKELETON_FRAMES)
                
                # Refresh ralph_state periodically (not every frame - expensive I/O)
                if now - last_state_refresh >= STATE_REFRESH_INTERVAL:
                    self.ralph_state = load_state(self.config)
                    last_state_refresh = now
                
                # Update external state (metrics, etc.)
                if update_state:
                    update_state(self)
                
                # Handle keyboard input
                action = self.get_input()
                if action:
                    if action == 'quit':
                        if on_quit:
                            return on_quit()
                        break
                    self.handle_action(action)
                
                self.render()
                
                # Sleep less when animating
                if self.skeleton_frame is not None:
                    time.sleep(FRAME_DURATION)
                else:
                    time.sleep(0.05)
        
        except KeyboardInterrupt:
            if on_quit:
                return on_quit()
            raise
        finally:
            self.exit()
        
        return None


def render_dashboard(state: DashboardState, term_width: int, term_height: int) -> list[str]:
    """Render the dashboard and return lines."""
    CLEAR_LINE = '\033[K'
    
    def truncate(text, max_width, prefix_len=0):
        """Truncate text to fit terminal, accounting for ANSI codes."""
        visible_max = max_width - prefix_len - 3
        if len(text) > visible_max:
            return text[:visible_max] + "..."
        return text
    
    lines = []
    def add(text=''):
        lines.append(f"{text}{CLEAR_LINE}")
    
    header_bar = "‚ïê" * (term_width - 1)
    section_bar = "‚îÄ" * (term_width - 1)
    footer_bar = "‚îÄ" * (term_width - 1)
    
    # Header
    add(f"{Colors.BLUE}{header_bar}{Colors.NC}")
    
    # Build kills string for header
    kills_str = ""
    if state.kills_timeout > 0 or state.kills_context > 0:
        parts = []
        if state.kills_timeout > 0:
            parts.append(f"T:{state.kills_timeout}")
        if state.kills_context > 0:
            parts.append(f"C:{state.kills_context}")
        kills_str = f" | {Colors.RED}Kills: {' '.join(parts)}{Colors.NC}"
    
    if state.iteration is not None:
        title = f"  RALPH WIGGUM - Iteration {state.iteration} - {datetime.now().strftime('%H:%M:%S')}{kills_str}"
    else:
        title = f"  RALPH WIGGUM - {datetime.now().strftime('%H:%M:%S')}{kills_str}"
    add(f"{Colors.BLUE}{title}{Colors.NC}")
    add(f"{Colors.BLUE}{header_bar}{Colors.NC}")
    add()
    
    # Use cached ralph state if available, otherwise load (expensive)
    ralph_state = state.ralph_state if state.ralph_state else load_state(state.config)
    
    # Build status lines to display next to Ralph
    status_lines = []
    status_lines.append(f"üåø {Colors.GREEN}Branch:{Colors.NC} {state.branch}")
    
    if state.is_running:
        if state.running_count > 0:
            status_lines.append(f"üü¢ {Colors.GREEN}Status:{Colors.NC} Running ({state.running_count})")
        else:
            status_lines.append(f"üü¢ {Colors.GREEN}Status:{Colors.NC} Running")
    else:
        status_lines.append(f"üü° {Colors.YELLOW}Status:{Colors.NC} Stopped")
    
    # Show current stage with color coding
    stage = ralph_state.get_stage()
    stage_colors = {
        'PLAN': Colors.MAGENTA,
        'BUILD': Colors.CYAN,
        'VERIFY': Colors.YELLOW,
        'INVESTIGATE': Colors.RED,
        'COMPLETE': Colors.GREEN,
    }
    stage_color = stage_colors.get(stage, Colors.WHITE)
    status_lines.append(f"üîß {Colors.GREEN}Stage:{Colors.NC} {stage_color}{stage}{Colors.NC}")
    
    if state.cost > 0:
        status_lines.append(f"üí∞ {Colors.CYAN}Cost:{Colors.NC} ${state.cost:.4f}")
    else:
        status_lines.append(f"üí∞ {Colors.CYAN}Cost:{Colors.NC} --")
    
    # Show context usage (always show, even if 0, for debugging)
    pct = (state.context_tokens / state.context_limit * 100) if state.context_limit > 0 else 0
    if pct >= 90:
        ctx_color = Colors.RED
    elif pct >= 70:
        ctx_color = Colors.YELLOW
    else:
        ctx_color = Colors.CYAN
    status_lines.append(f"üß† {ctx_color}Context:{Colors.NC} {state.context_tokens:,} / {state.context_limit:,} ({pct:.0f}%)")
    
    # Show last kill reason if any
    if state.last_kill_reason:
        kill_msg = f"‚ö†Ô∏è  {Colors.RED}Kill:{Colors.NC} {state.last_kill_reason}"
        if state.last_kill_activity:
            kill_msg += f" @ {state.last_kill_activity[:30]}"
        status_lines.append(kill_msg)
    
    pending = len(ralph_state.pending)
    done = len(ralph_state.done)
    status_lines.append(f"")
    status_lines.append(f"üìä {Colors.GREEN}Progress:{Colors.NC} {done} done, {pending} pending")
    status_lines.append(f"")
    if ralph_state.spec:
        status_lines.append(f"üìã {Colors.GREEN}Spec:{Colors.NC} {ralph_state.spec}")
    status_lines.append(f"üéØ {Colors.GREEN}Task:{Colors.NC}")
    next_task_obj = ralph_state.get_next_task()
    next_task = next_task_obj.name if next_task_obj else None
    if next_task:
        status_lines.append(f"   {truncate(next_task, term_width - RALPH_WIDTH - 6, 3)}")
    else:
        status_lines.append(f"   (no pending tasks)")
    
    # Print Ralph art alongside status info with vertical separator
    num_art_lines = max(len(RALPH_ART), len(status_lines))
    for i in range(num_art_lines):
        ralph_line = RALPH_ART[i] if i < len(RALPH_ART) else " " * RALPH_WIDTH
        status_line = status_lines[i] if i < len(status_lines) else ""
        add(f"{ralph_line} {Colors.DIM}‚îÇ{Colors.NC} {status_line}")
    
    # T-join separator (‚î¥) connecting vertical bar to horizontal
    # The ‚îÇ is at position RALPH_WIDTH + 1 (after ralph art + space)
    left_width = RALPH_WIDTH + 1  # Ralph art width + space before ‚îÇ
    right_width = term_width - left_width - 1  # rest after ‚î¥
    if right_width < 0:
        right_width = 0
    t_join_separator = "‚îÄ" * left_width + "‚î¥" + "‚îÄ" * right_width
    add(f"{Colors.DIM}{t_join_separator}{Colors.NC}")
    
    # Discovered Issues
    if ralph_state.issues:
        add(f"{Colors.YELLOW}Discovered Issues:{Colors.NC} ({len(ralph_state.issues)} open)")
        for issue in ralph_state.issues[:5]:
            truncated_text = truncate(issue.desc, term_width, 9)
            add(f"  {Colors.RED}OPEN{Colors.NC}   {truncated_text}")
        if len(ralph_state.issues) > 5:
            add(f"  {Colors.YELLOW}... and {len(ralph_state.issues) - 5} more{Colors.NC}")
        add(f"{Colors.DIM}{section_bar}{Colors.NC}")
    
    # Latest output - fill rest of screen
    lines_used = len(lines)
    available_lines = term_height - lines_used - 3  # Reserve for Output: header + footer (2 lines)
    add(f"{Colors.GREEN}Output:{Colors.NC}")
    if available_lines >= 1:
        display_lines = state.output_lines[-available_lines:] if state.output_lines else []
        for line in display_lines:
            add(f"  {truncate(line, term_width, 2)}")
        # Show skeleton animation if active (waiting for response)
        if state.skeleton_frame is not None:
            frame = SKELETON_FRAMES[state.skeleton_frame % len(SKELETON_FRAMES)]
            add(f"  {frame}")
            # One less empty line since we added skeleton
            for _ in range(available_lines - len(display_lines) - 1):
                add()
        else:
            for _ in range(available_lines - len(display_lines)):
                add()
    
    add(f"{Colors.BLUE}{footer_bar}{Colors.NC}")
    add(state.footer_text)
    
    # Ensure we have exactly term_height lines to prevent jitter
    while len(lines) < term_height:
        add()
    
    return lines[:term_height]


def cmd_watch(config: RalphConfig):
    """Live dashboard showing current status with streamed output."""
    if not _check_textual():
        # Use the original ANSI-based dashboard (still good, just not as optimized)
        _cmd_watch_fallback(config)
        return
    
    # Use Textual TUI
    RalphDashboard, _ = _create_textual_app()
    app = RalphDashboard(config, watch_mode=True)
    app.run()
    print("Stopped watching.")


def _cmd_watch_fallback(config: RalphConfig):
    """Fallback watch mode without Textual - uses shared FallbackDashboard."""
    dashboard = FallbackDashboard(config)
    dashboard.branch = get_current_branch()
    dashboard.running_count = count_running_opencode(config.repo_root)
    dashboard.is_running = dashboard.running_count > 0
    
    # State for FIFO reading
    fifo_state = {'fd': None, 'buffer': ''}
    last_expensive_update = [0.0]
    EXPENSIVE_UPDATE_INTERVAL = 1.0
    
    def poll_fifo():
        """Poll FIFO for new lines."""
        lines = []
        
        # Try to open FIFO if not open
        if fifo_state['fd'] is None and config.output_fifo.exists():
            try:
                fifo_state['fd'] = os.open(str(config.output_fifo), os.O_RDWR | os.O_NONBLOCK)
            except OSError:
                pass
        
        # Read any available data from FIFO
        if fifo_state['fd'] is not None:
            try:
                while True:
                    ready, _, _ = select.select([fifo_state['fd']], [], [], 0)
                    if not ready:
                        break
                    data = os.read(fifo_state['fd'], 4096)
                    if not data:
                        break
                    # Buffer data and only process complete lines
                    fifo_state['buffer'] += data.decode('utf-8', errors='replace')
                    while '\n' in fifo_state['buffer']:
                        line, fifo_state['buffer'] = fifo_state['buffer'].split('\n', 1)
                        if line:
                            lines.append(line)
            except OSError:
                if fifo_state['fd'] is not None:
                    try:
                        os.close(fifo_state['fd'])
                    except OSError:
                        pass
                fifo_state['fd'] = None
        
        return lines
    
    def update_state(db):
        """Update expensive state periodically."""
        now = time.time()
        if now - last_expensive_update[0] >= EXPENSIVE_UPDATE_INTERVAL:
            db.running_count = count_running_opencode(config.repo_root)
            db.is_running = db.running_count > 0
            db.iteration = read_runtime_iteration(config)
            if int(now) % 5 == 0:
                db.branch = get_current_branch()
            last_expensive_update[0] = now
    
    try:
        dashboard.run_loop(poll_fifo, update_state=update_state)
    finally:
        if fifo_state['fd'] is not None:
            try:
                os.close(fifo_state['fd'])
            except OSError:
                pass
        print("Stopped watching.")


def cmd_stream():
    """Filter opencode stream-json output to show human-readable progress with syntax highlighting.
    
    Usage: opencode --format json | ralph stream
    
    Note: This command doesn't require being in a git repo since it just processes stdin.
    
    Features a pulsing "skeleton" indicator that shows while waiting for events,
    similar to loading placeholders in modern apps.
    """
    import select as sel
    
    # ANSI color codes
    class C:
        RESET = '\033[0m'
        BOLD = '\033[1m'
        DIM = '\033[2m'
        RED = '\033[31m'
        GREEN = '\033[32m'
        YELLOW = '\033[33m'
        BLUE = '\033[34m'
        MAGENTA = '\033[35m'
        CYAN = '\033[36m'
        WHITE = '\033[37m'
        BRIGHT_BLACK = '\033[90m'
        BRIGHT_GREEN = '\033[92m'
        BRIGHT_YELLOW = '\033[93m'
        BRIGHT_BLUE = '\033[94m'
        BRIGHT_MAGENTA = '\033[95m'
        BRIGHT_CYAN = '\033[96m'
        # Cursor control
        SAVE = '\033[s'
        RESTORE = '\033[u'
        CLEAR_LINE = '\033[2K'
        UP = '\033[1A'
    
    fd = sys.stdin.fileno()
    frame_idx = 0
    in_step = False  # Track if we're inside a step (between step_start and step_finish)
    last_event_time = time.time()
    skeleton_delay = 0.5  # Wait this long before showing skeleton
    
    def format_tool_output(tool, args, title, output):
        """Format and print tool use output."""
        if tool == "bash":
            cmd = args.get("command", "")
            desc = args.get("description", "") or title
            print(f"\n‚ö° {C.BRIGHT_YELLOW}Bash:{C.RESET} {C.DIM}{cmd[:80]}{C.RESET}")
            if desc:
                print(f"  {C.YELLOW}{desc}{C.RESET}")
        elif tool == "read":
            path = args.get("filePath", "")
            print(f"\nüìñ {C.BRIGHT_CYAN}Read:{C.RESET} {C.CYAN}{path}{C.RESET}")
        elif tool == "edit":
            path = args.get("filePath", "")
            print(f"\n‚úèÔ∏è  {C.BRIGHT_GREEN}Edit:{C.RESET} {C.GREEN}{path}{C.RESET}")
        elif tool == "write":
            path = args.get("filePath", "")
            print(f"\nüìù {C.BRIGHT_GREEN}Write:{C.RESET} {C.GREEN}{path}{C.RESET}")
        elif tool == "grep":
            pattern = args.get("pattern", "")
            print(f"\nüîç {C.BRIGHT_MAGENTA}Grep:{C.RESET} {C.MAGENTA}{pattern}{C.RESET}")
        elif tool == "glob":
            pattern = args.get("pattern", "")
            print(f"\nüìÅ {C.BRIGHT_MAGENTA}Glob:{C.RESET} {C.MAGENTA}{pattern}{C.RESET}")
        elif tool == "task":
            desc = args.get("description", "") or title
            print(f"\nü§ñ {C.BRIGHT_BLUE}Task:{C.RESET} {C.BLUE}{desc}{C.RESET}")
        elif tool == "todowrite":
            todos = args.get("todos", [])
            print(f"\nüîß {C.WHITE}todowrite:{C.RESET} {C.DIM}{len(todos)} todos{C.RESET}")
        elif tool == "ddg-search" or tool == "webfetch":
            query = args.get("query", "") or args.get("url", "") or title
            print(f"\nü¶Ü {C.BRIGHT_CYAN}Web:{C.RESET} {C.CYAN}{query}{C.RESET}")
        elif tool.startswith("ralph") or tool.startswith("mcp_ralph"):
            desc = args.get("description", "") or title or tool
            print(f"\nüëÆ {C.BRIGHT_YELLOW}Ralph:{C.RESET} {C.YELLOW}{desc}{C.RESET}")
        else:
            label = f"{tool}: {title}" if title else tool
            print(f"\nüîß {C.WHITE}{label}{C.RESET}")
        
        # Show brief output - dimmed
        if output:
            lines = str(output).strip().split('\n')
            if len(lines) <= 3:
                for l in lines:
                    print(f"  {C.DIM}{l[:100]}{C.RESET}")
            else:
                print(f"  {C.DIM}({len(lines)} lines){C.RESET}")
        sys.stdout.flush()
    
    try:
        while True:
            # Non-blocking read with 100ms timeout for animation
            ready, _, _ = sel.select([fd], [], [], 0.1)
            
            if ready:
                line = sys.stdin.readline()
                if not line:  # EOF
                    break
                
                line = line.strip()
                if not line:
                    continue
                
                try:
                    event = json.loads(line)
                except json.JSONDecodeError:
                    # Non-JSON output - likely an error message from opencode
                    print(f"{C.RED}{line}{C.RESET}", file=sys.stderr)
                    sys.stderr.flush()
                    continue
                
                last_event_time = time.time()
                event_type = event.get("type", "")
                part = event.get("part", {})
                
                if event_type == "step_start":
                    in_step = True
                
                elif event_type == "text":
                    text = part.get("text", "")
                    if text:
                        print(f"\n{C.WHITE}{text}{C.RESET}")
                        sys.stdout.flush()
                
                elif event_type == "tool_use":
                    tool = part.get("tool", "?")
                    state = part.get("state", {})
                    args = state.get("input", {})
                    title = state.get("title", "")
                    output = state.get("output", "")
                    format_tool_output(tool, args, title, output)
                
                elif event_type == "step_finish":
                    in_step = False
                    cost = part.get("cost", 0)
                    tokens = part.get("tokens", {})
                    input_tokens = tokens.get("input", 0)
                    output_tokens = tokens.get("output", 0)
                    cache = tokens.get("cache", {})
                    cache_read = cache.get("read", 0)
                    context_size = input_tokens + cache_read
                    print(f"\n{C.BRIGHT_BLACK}¬∑ ¬∑ ¬∑{C.RESET}")
                    print(f"\x00Cost: ${cost:.4f} | Tokens: {context_size}in/{output_tokens}out")
                    sys.stdout.flush()
            
            else:
                # No data available - emit heartbeat if we're waiting in a step
                # Parent process can use this to show animation
                if in_step and (time.time() - last_event_time) > skeleton_delay:
                    # Emit heartbeat with frame number for parent to animate
                    print(f"\x01HEARTBEAT:{frame_idx}")
                    sys.stdout.flush()
                    frame_idx += 1
    
    except KeyboardInterrupt:
        pass


@dataclass 
class OutputBuffer:
    """Thread-safe buffer for output lines."""
    lines: deque = field(default_factory=lambda: deque(maxlen=100))
    lock: threading.Lock = field(default_factory=threading.Lock)
    total_output: list = field(default_factory=list)  # For completion promise check
    last_activity: str = ""  # Last tool/action observed
    iteration_tokens: int = 0  # Latest context window size (not cumulative)
    
    def add(self, line: str):
        with self.lock:
            self.lines.append(line)
            self.total_output.append(line)
    
    def set_last_activity(self, activity: str):
        with self.lock:
            self.last_activity = activity
    
    def get_last_activity(self) -> str:
        with self.lock:
            return self.last_activity
    
    def set_context_tokens(self, tokens: int):
        """Set current context window size (replaces, doesn't accumulate)."""
        with self.lock:
            self.iteration_tokens = tokens
    
    def get_iteration_tokens(self) -> int:
        with self.lock:
            return self.iteration_tokens
    
    def get_lines(self) -> list[str]:
        with self.lock:
            return list(self.lines)
    
    def get_all(self) -> str:
        with self.lock:
            return '\n'.join(self.total_output)


def run_with_live_ui(process, config: RalphConfig, iteration: int,
                     metrics: Metrics, branch: str, output_buffer: OutputBuffer) -> int:
    """Run process with live dashboard UI, return exit code."""
    
    if not _check_textual():
        # Fallback: just wait for process without fancy UI
        return _run_with_simple_ui(process, config, iteration, metrics, branch, output_buffer)
    
    # Use Textual TUI with process monitoring
    RalphDashboard, _ = _create_textual_app()
    
    # Create a custom app that monitors the process
    app = RalphDashboard(config, watch_mode=False, iteration=iteration)
    app._cost = metrics.total_cost
    app._tokens_in = metrics.total_tokens_in
    app._tokens_out = metrics.total_tokens_out
    app._branch = branch
    app._is_running = True
    app._output_buffer = output_buffer  # For context tracking
    
    # We need to run the app and stream output simultaneously
    # The output thread is already running, we just need to hook it up
    exit_code = [None]
    
    def check_process():
        """Check if process is done and update app."""
        ret = process.poll()
        if ret is not None:
            exit_code[0] = ret
            app._is_running = False
            # Give a moment for final output then exit
            app.set_timer(0.5, lambda: app.exit())
        
        # Update context tokens from output buffer
        if app._output_buffer:
            app._context_tokens = app._output_buffer.get_iteration_tokens()
        
        # Feed new output lines to the app
        for line in output_buffer.get_lines()[-50:]:  # Get recent lines
            # Skip if already added (crude dedup by checking last few)
            pass
    
    # Start the app with a process monitor
    original_on_mount = app.on_mount
    
    def patched_on_mount():
        original_on_mount()
        # Set up process monitoring
        app.set_interval(0.1, check_process)
        # Set up output feeding
        def feed_output():
            lines = output_buffer.get_lines()
            log = app.query_one("#output-log")
            # Only add new lines
            current_count = getattr(app, '_fed_lines', 0)
            from rich.text import Text
            for line in lines[current_count:]:
                log.write(Text.from_ansi(line))
            app._fed_lines = len(lines)
        app.set_interval(0.1, feed_output)
    
    app.on_mount = patched_on_mount
    
    try:
        app.run()
    except KeyboardInterrupt:
        process.terminate()
        process.wait()
        raise
    
    # If we exited before process finished, wait for it
    if exit_code[0] is None:
        process.terminate()
        process.wait()
        return process.returncode
    
    return exit_code[0]


def _run_with_simple_ui(process, config: RalphConfig, iteration: int,
                        metrics: Metrics, branch: str, output_buffer: OutputBuffer) -> int:
    """Simple fallback UI without Textual - uses shared FallbackDashboard."""
    dashboard = FallbackDashboard(config, iteration=iteration)
    dashboard.branch = branch
    dashboard.is_running = True
    
    last_line_count = [0]
    
    def poll_buffer():
        """Poll output buffer for new lines. Raises StopIteration when process exits."""
        if process.poll() is not None:
            raise StopIteration
        all_lines = output_buffer.get_lines()
        new_lines = all_lines[last_line_count[0]:]
        last_line_count[0] = len(all_lines)
        return new_lines
    
    def update_state(db):
        """Sync metrics to dashboard."""
        db.cost = metrics.total_cost
        db.tokens_in = metrics.total_tokens_in
        db.tokens_out = metrics.total_tokens_out
        db.kills_timeout = metrics.kills_timeout
        db.kills_context = metrics.kills_context
        ctx = output_buffer.get_iteration_tokens()
        if ctx > 0:
            db.context_tokens = ctx
        db.last_kill_reason = metrics.last_kill_reason
        db.last_kill_activity = metrics.last_kill_activity
    
    def on_quit():
        """Handle quit action."""
        process.terminate()
        process.wait()
        return process.returncode
    
    try:
        result = dashboard.run_loop(poll_buffer, on_quit=on_quit, update_state=update_state)
        if result is not None:
            return result
        return process.returncode
    except KeyboardInterrupt:
        process.terminate()
        process.wait()
        raise


def stream_output(pipe, output_buffer: OutputBuffer, metrics: Metrics, 
                  print_to_stdout: bool = False, fifo_path: Optional[Path] = None,
                  stop_event: Optional[threading.Event] = None):
    """Read from pipe, update buffer and metrics. Runs in a thread.
    
    Args:
        stop_event: Optional event to signal the thread should stop reading.
    """
    fifo_fd = None
    
    # Use select for non-blocking reads with timeout if stop_event provided
    if stop_event is not None:
        import select as sel
        fd = pipe.fileno()
        while not stop_event.is_set():
            # Wait up to 0.5s for data
            ready, _, _ = sel.select([fd], [], [], 0.5)
            if not ready:
                continue
            line = pipe.readline()
            if not line:  # EOF
                break
            decoded = line.decode('utf-8', errors='replace').rstrip('\n')
            _process_stream_line(decoded, output_buffer, metrics, print_to_stdout, fifo_path)
    else:
        # Original blocking mode
        for line in iter(pipe.readline, b''):
            decoded = line.decode('utf-8', errors='replace').rstrip('\n')
            _process_stream_line(decoded, output_buffer, metrics, print_to_stdout, fifo_path)
    
    if fifo_fd is not None:
        try:
            os.close(fifo_fd)
        except OSError:
            pass


def _process_stream_line(decoded: str, output_buffer: OutputBuffer, metrics: Metrics,
                         print_to_stdout: bool, fifo_path: Optional[Path]):
    """Process a single line from the stream."""
    # Parse cost info (before filtering - metrics lines start with \x00)
    cost_info = parse_cost_line(decoded)
    if cost_info:
        metrics.total_cost = cost_info[0]
        metrics.total_tokens_in = cost_info[1]
        metrics.total_tokens_out = cost_info[2]
        # Track context window size (latest value, not cumulative)
        # The tokens reported are the current context size, not a delta
        output_buffer.set_context_tokens(cost_info[1])
    
    # Track last activity from tool calls (look for tool indicators)
    # Match emoji followed by tool name and description
    activity_match = re.search(r'(?:üìñ|‚úèÔ∏è|‚ö°|üíª|üîç|üìÅ|ü§ñ|ü¶Ü|üëÆ|üîß|üìù)\s*(?:\x1b\[[0-9;]*m)*(\w+:\s*.{0,60})', decoded)
    if activity_match:
        # Clean ANSI codes from the match
        activity = re.sub(r'\x1b\[[0-9;]*m', '', activity_match.group(1))
        output_buffer.set_last_activity(activity.strip()[:80])
    
    # Filter out hidden metrics lines (prefixed with \x00) from display
    if decoded.startswith('\x00'):
        return
    
    # Filter out heartbeat messages - they're only for dashboard animation
    if decoded.startswith('\x01HEARTBEAT:'):
        # Write heartbeat to FIFO so watchers can animate
        if fifo_path is not None:
            fifo_fd = getattr(_process_stream_line, '_fifo_fd', None)
            if fifo_fd is None:
                try:
                    fifo_fd = os.open(str(fifo_path), os.O_RDWR | os.O_NONBLOCK)
                    _process_stream_line._fifo_fd = fifo_fd
                except OSError:
                    pass
            if fifo_fd is not None:
                try:
                    os.write(fifo_fd, (decoded + '\n').encode('utf-8'))
                except OSError:
                    try:
                        os.close(fifo_fd)
                    except OSError:
                        pass
                    _process_stream_line._fifo_fd = None
        return
    
    output_buffer.add(decoded)
    
    if print_to_stdout:
        print(decoded)
        sys.stdout.flush()
    
    # Write to FIFO for watchers
    # Use O_RDWR so we don't block/fail when no reader is connected
    if fifo_path is not None:
        fifo_fd = getattr(_process_stream_line, '_fifo_fd', None)
        if fifo_fd is None:
            try:
                fifo_fd = os.open(str(fifo_path), os.O_RDWR | os.O_NONBLOCK)
                _process_stream_line._fifo_fd = fifo_fd
            except OSError:
                pass  # FIFO doesn't exist
        
        if fifo_fd is not None:
            try:
                os.write(fifo_fd, (decoded + '\n').encode('utf-8'))
            except OSError:
                # Broken pipe - close and retry next time
                try:
                    os.close(fifo_fd)
                except OSError:
                    pass
                _process_stream_line._fifo_fd = None


def get_prompt_for_stage(config: RalphConfig, mode: str, stage) -> Path:
    """Get the appropriate prompt file based on mode and stage.
    
    Args:
        config: Ralph configuration
        mode: 'plan' or 'construct'
        stage: Stage enum or string (for backwards compatibility)
    """
    if mode == 'plan':
        return config.prompt_plan
    
    # Convert Stage enum to string if needed
    stage_str = stage.name if isinstance(stage, Stage) else stage
    
    # Build mode - select based on stage
    if stage_str == 'VERIFY':
        return config.prompt_verify
    elif stage_str == 'INVESTIGATE':
        return config.prompt_investigate
    elif stage_str == 'DECOMPOSE':
        return config.prompt_decompose
    else:
        # BUILD, PLAN, COMPLETE all use build prompt
        return config.prompt_build


def run_single_stage(config: RalphConfig, stage: Stage, state: RalphState, 
                     metrics: Metrics, stage_timeout_ms: int, context_limit: int,
                     interactive: bool = False, project_rules: Optional[str] = None,
                     spec_file: Optional[str] = None) -> StageResult:
    """
    Run a single stage of the construct loop.
    
    This is the core function that invokes the AI model via opencode.
    Extracted from cmd_run for use by the state machine.
    
    Args:
        config: Ralph configuration
        stage: Stage to run
        state: Current Ralph state
        metrics: Metrics tracker
        stage_timeout_ms: Timeout for this stage in milliseconds
        context_limit: Context window size in tokens
        interactive: Whether to use interactive UI
        project_rules: Project rules content (from AGENTS.md/CLAUDE.md)
        spec_file: Spec file name for template substitution
        
    Returns:
        StageResult with outcome and details
    """
    start_time = time.time()
    stage_str = stage.name
    
    # Get prompt for this stage
    prompt_file = get_prompt_for_stage(config, 'construct', stage)
    if not prompt_file.exists():
        return StageResult(
            stage=stage,
            outcome=StageOutcome.FAILURE,
            error=f"Prompt file not found: {prompt_file}"
        )
    
    prompt_content = prompt_file.read_text()
    
    # Substitute spec file placeholder
    if spec_file:
        prompt_content = prompt_content.replace('{{SPEC_FILE}}', spec_file)
    
    # Incorporate project rules
    if project_rules:
        prompt_content = build_prompt_with_rules(prompt_content, project_rules)
    
    # Get current task info for tracking
    current_task_id = None
    current_task_name = None
    current_task = state.get_next_task()
    if current_task:
        current_task_id = current_task.id
        current_task_name = current_task.name
    
    # For BUILD stage, save the assigned task ID so `ralph task done` knows which task to mark
    # This prevents the "wrong task marked done" bug when task ordering changes mid-iteration
    if stage == Stage.BUILD and current_task_id:
        save_current_task(config, current_task_id)
    
    output_buffer = OutputBuffer()
    
    # Use per-task timeout if available, otherwise fall back to stage timeout
    if current_task and current_task.timeout_ms is not None:
        iteration_timeout = current_task.timeout_ms / 1000.0
    else:
        iteration_timeout = stage_timeout_ms / 1000.0
    
    # Calculate context limits
    plan_config = state.config
    if plan_config:
        hard_limit_pct = plan_config.context_kill * 100
        compact_limit_pct = plan_config.context_compact * 100
        soft_limit_pct = plan_config.context_warn * 100
    else:
        gcfg = get_global_config()
        hard_limit_pct = gcfg.context_kill_pct
        compact_limit_pct = gcfg.context_compact_pct
        soft_limit_pct = gcfg.context_warn_pct
    
    hard_limit = int(context_limit * hard_limit_pct / 100)
    compact_limit = int(context_limit * compact_limit_pct / 100)
    soft_limit = int(context_limit * soft_limit_pct / 100)
    
    # Set up environment for opencode
    opencode_env = os.environ.copy()
    opencode_env['XDG_STATE_HOME'] = '/tmp/ralph-opencode-state'
    
    permission_config = {
        "external_directory": "deny",
        "doom_loop": "deny"
    }
    if stage == Stage.DECOMPOSE:
        permission_config["read"] = {"*": "allow"}
        permission_config["external_directory"] = {"*": "deny"}
    opencode_env['OPENCODE_PERMISSION'] = json.dumps(permission_config)
    
    gcfg = get_global_config()
    # BUILD uses fast model, but upgrades to main model if task is complex
    # All other stages always use main model
    if stage == Stage.BUILD:
        model = gcfg.model_build
        current_task = state.get_next_task()
        # Upgrade to main model if task is struggling
        if current_task:
            if current_task.reject_reason:
                # Previously rejected - needs more capability
                model = gcfg.model
            elif current_task.priority == 'high':
                # High priority tasks get main model
                model = gcfg.model
            elif current_task.decompose_depth > 0:
                # Already been decomposed - subtasks are tricky
                model = gcfg.model
    else:
        model = gcfg.model
    
    cmd = ['opencode', 'run', '--model', model,
           '--format', 'json', prompt_content]
    
    # Start opencode process
    opencode_proc = subprocess.Popen(
        cmd,
        stdin=subprocess.DEVNULL,
        stdout=subprocess.PIPE,
        stderr=subprocess.STDOUT,
        cwd=config.repo_root,
        env=opencode_env
    )
    
    # Pipe through ralph stream for parsing
    # Use -u for unbuffered output so we see progress in real-time
    ralph_stream_proc = subprocess.Popen(
        [sys.executable, '-u', __file__, 'stream'],
        stdin=opencode_proc.stdout,
        stdout=subprocess.PIPE,
        stderr=subprocess.STDOUT,
    )
    
    if opencode_proc.stdout:
        opencode_proc.stdout.close()
    
    # Track kill state
    kill_state = {"killed": False, "reason": "none", "info": None, "compact_requested": False}
    soft_warned = [False]
    compact_attempted = [False]
    reader_stop = threading.Event()
    
    # Start reader thread
    reader_thread = threading.Thread(
        target=stream_output,
        args=(ralph_stream_proc.stdout, output_buffer, metrics, not interactive, config.output_fifo, reader_stop)
    )
    reader_thread.daemon = True
    reader_thread.start()
    
    # Monitor function
    def monitor_limits():
        deadline = time.time() + iteration_timeout
        check_interval = 2.0
        
        while ralph_stream_proc.poll() is None and opencode_proc.poll() is None:
            if kill_state["killed"]:
                break
            
            elapsed = int(time.time() - start_time)
            current_tokens = output_buffer.get_iteration_tokens()
            
            # Check timeout
            if time.time() >= deadline:
                kill_state["killed"] = True
                kill_state["reason"] = "timeout"
                kill_state["info"] = IterationKillInfo(
                    reason="timeout",
                    task_name=current_task_name,
                    timeout_seconds=iteration_timeout,
                    elapsed_seconds=elapsed,
                    last_activity=output_buffer.get_last_activity()
                )
                try:
                    opencode_proc.terminate()
                    ralph_stream_proc.terminate()
                except:
                    pass
                break
            
            # Check context hard limit (95%)
            if current_tokens >= hard_limit:
                kill_state["killed"] = True
                kill_state["reason"] = "context_limit"
                kill_state["info"] = IterationKillInfo(
                    reason="context_limit",
                    task_name=current_task_name,
                    tokens_used=current_tokens,
                    context_limit=context_limit,
                    elapsed_seconds=elapsed,
                    last_activity=output_buffer.get_last_activity()
                )
                try:
                    opencode_proc.terminate()
                    ralph_stream_proc.terminate()
                except:
                    pass
                break
            
            # Check compact limit (85%) - only in non-interactive
            if not interactive and current_tokens >= compact_limit and not compact_attempted[0]:
                compact_attempted[0] = True
                pct = current_tokens / context_limit * 100
                print(f"\n{Colors.YELLOW}[RALPH] Context at {pct:.0f}% - requesting compaction...{Colors.NC}")
                kill_state["compact_requested"] = True
                kill_state["info"] = IterationKillInfo(
                    reason="compaction_requested",
                    task_name=current_task_name,
                    tokens_used=current_tokens,
                    context_limit=context_limit,
                    elapsed_seconds=elapsed,
                    last_activity=output_buffer.get_last_activity()
                )
                try:
                    opencode_proc.terminate()
                    ralph_stream_proc.terminate()
                except:
                    pass
                break
            
            # Soft warning at 70%
            if current_tokens >= soft_limit and not soft_warned[0]:
                pct = current_tokens / context_limit * 100
                print(f"\n{Colors.YELLOW}[RALPH] Context pressure: {pct:.0f}% ({current_tokens:,}/{context_limit:,} tokens){Colors.NC}")
                soft_warned[0] = True
            
            time.sleep(check_interval)
    
    # Start monitor thread
    monitor_thread = threading.Thread(target=monitor_limits, daemon=True)
    monitor_thread.start()
    
    # Wait for process
    if interactive:
        exit_code = run_with_live_ui(ralph_stream_proc, config, 0, metrics, 
                                      get_current_branch(), output_buffer)
    else:
        while ralph_stream_proc.poll() is None:
            if kill_state["killed"] or kill_state["compact_requested"]:
                break
            time.sleep(0.1)
        exit_code = ralph_stream_proc.returncode if ralph_stream_proc.returncode is not None else -1
    
    monitor_thread.join(timeout=1.0)
    
    # Always signal reader thread to stop and wait for it to finish
    # This ensures output is flushed before we continue (fixes display freeze on timeout)
    reader_stop.set()
    reader_thread.join(timeout=2.0)
    
    # Handle compaction - attempt to resume with compacted context
    if kill_state["compact_requested"] and not kill_state["killed"]:
        print(f"{Colors.YELLOW}‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ{Colors.NC}")
        print(f"{Colors.YELLOW}COMPACTION: Building compacted context...{Colors.NC}")
        
        # Clean up current processes
        reader_stop.set()
        try:
            ralph_stream_proc.kill()
            opencode_proc.kill()
        except:
            pass
        reader_thread.join(timeout=2.0)
        if opencode_proc.poll() is None:
            opencode_proc.wait()
        
        # Build compacted context
        if current_task:
            compacted = build_compacted_context(
                current_task,
                config.repo_root,
                output_buffer.get_all()
            )
            compacted_prompt = compacted.to_prompt()
            
            # Combine with original prompt
            full_prompt = compacted_prompt + "\n\n" + prompt_content
            
            print(f"{Colors.GREEN}[RALPH] Context compacted. Resuming execution...{Colors.NC}")
            print(f"{Colors.YELLOW}‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ{Colors.NC}")
            
            # Create new output buffer for resumed execution
            output_buffer = OutputBuffer()
            
            # Start new opencode process with compacted context
            model = get_global_config().model
            cmd = ['opencode', 'run', '--model', model, 
                   '--format', 'json', full_prompt]
            
            opencode_proc = subprocess.Popen(
                cmd,
                stdin=subprocess.DEVNULL,
                stdout=subprocess.PIPE,
                stderr=subprocess.STDOUT,
                cwd=config.repo_root,
                env=opencode_env
            )
            
            ralph_stream_proc = subprocess.Popen(
                [sys.executable, '-u', __file__, 'stream'],
                stdin=opencode_proc.stdout,
                stdout=subprocess.PIPE,
                stderr=subprocess.STDOUT,
            )
            
            if opencode_proc.stdout:
                opencode_proc.stdout.close()
            
            # Reset kill state for resumed execution
            kill_state = {"killed": False, "reason": "none", "info": None, "compact_requested": False}
            reader_stop = threading.Event()
            
            # Start new reader thread
            reader_thread = threading.Thread(
                target=stream_output,
                args=(ralph_stream_proc.stdout, output_buffer, metrics, not interactive, config.output_fifo, reader_stop)
            )
            reader_thread.daemon = True
            reader_thread.start()
            
            # Start new monitor thread - check for resume success and hard limit
            resumed_start_time = time.time()
            resume_check_done = [False]
            
            def monitor_resumed():
                """Monitor thread for resumed execution after compaction."""
                resumed_deadline = resumed_start_time + (stage_timeout_ms / 1000.0)
                check_interval = 2.0
                
                while ralph_stream_proc.poll() is None and opencode_proc.poll() is None:
                    if kill_state["killed"]:
                        break
                    
                    resumed_elapsed = int(time.time() - resumed_start_time)
                    current_tokens = output_buffer.get_iteration_tokens()
                    
                    # Check timeout
                    if time.time() >= resumed_deadline:
                        kill_state["killed"] = True
                        kill_state["reason"] = "timeout"
                        kill_state["info"] = IterationKillInfo(
                            reason="timeout",
                            task_name=current_task_name,
                            timeout_seconds=int(stage_timeout_ms / 1000),
                            elapsed_seconds=resumed_elapsed,
                            last_activity=output_buffer.get_last_activity()
                        )
                        try:
                            opencode_proc.terminate()
                            ralph_stream_proc.terminate()
                        except:
                            pass
                        break
                    
                    # Check if compaction failed (still > 80% after resume)
                    if current_tokens > 0 and not resume_check_done[0]:
                        resume_check_done[0] = True
                        pct = current_tokens / context_limit * 100
                        if current_tokens > int(context_limit * 0.80):
                            print(f"\n{Colors.RED}[RALPH] Compaction failed - still at {pct:.0f}% after resume{Colors.NC}")
                            kill_state["killed"] = True
                            kill_state["reason"] = "compaction_failed"
                            kill_state["info"] = IterationKillInfo(
                                reason="compaction_failed",
                                task_name=current_task_name,
                                tokens_used=current_tokens,
                                context_limit=context_limit,
                                elapsed_seconds=resumed_elapsed,
                                last_activity=output_buffer.get_last_activity()
                            )
                            try:
                                opencode_proc.terminate()
                                ralph_stream_proc.terminate()
                            except:
                                pass
                            break
                        else:
                            print(f"\n{Colors.GREEN}[RALPH] Context compacted: resumed at {pct:.0f}%{Colors.NC}")
                    
                    # Check hard limit (95%)
                    if current_tokens >= hard_limit:
                        kill_state["killed"] = True
                        kill_state["reason"] = "context_limit"
                        kill_state["info"] = IterationKillInfo(
                            reason="context_limit",
                            task_name=current_task_name,
                            tokens_used=current_tokens,
                            context_limit=context_limit,
                            elapsed_seconds=resumed_elapsed,
                            last_activity=output_buffer.get_last_activity()
                        )
                        try:
                            opencode_proc.terminate()
                            ralph_stream_proc.terminate()
                        except:
                            pass
                        break
                    
                    time.sleep(check_interval)
            
            resumed_monitor_thread = threading.Thread(target=monitor_resumed, daemon=True)
            resumed_monitor_thread.start()
            
            # Wait for resumed process
            while ralph_stream_proc.poll() is None:
                if kill_state["killed"]:
                    break
                time.sleep(0.1)
            exit_code = ralph_stream_proc.returncode if ralph_stream_proc.returncode is not None else -1
            
            resumed_monitor_thread.join(timeout=1.0)
            
            # Update start_time for duration calculation
            start_time = resumed_start_time
        else:
            # No current task - treat as failure
            print(f"{Colors.RED}[RALPH] No current task for compaction - treating as failure{Colors.NC}")
            kill_state["killed"] = True
            kill_state["reason"] = "compaction_failed"
    
    duration = time.time() - start_time
    
    # Log output
    config.log_dir.mkdir(parents=True, exist_ok=True)
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    log_file = config.log_dir / f"ralph-{timestamp}-{stage_str.lower()}.log"
    log_file_written = None
    try:
        with log_file.open('w') as f:
            f.write(f"# Ralph construct stage: {stage_str}\n")
            f.write(f"# Date: {datetime.now().isoformat()}\n")
            f.write(f"# Exit code: {exit_code}\n")
            f.write(f"# Duration: {duration:.1f}s\n")
            f.write(f"# Task: {current_task_name or 'N/A'}\n")
            if kill_state["killed"]:
                f.write(f"# Kill reason: {kill_state['reason']}\n")
            f.write("\n")
            f.write(output_buffer.get_all())
        log_file_written = str(log_file)
    except Exception:
        pass
    
    # Build result
    if kill_state["killed"]:
        return StageResult(
            stage=stage,
            outcome=StageOutcome.FAILURE,
            exit_code=exit_code,
            duration_seconds=duration,
            cost=metrics.iteration_cost if hasattr(metrics, 'iteration_cost') else 0,
            tokens_used=output_buffer.get_iteration_tokens(),
            kill_reason=kill_state["reason"],
            kill_log=log_file_written,
            task_id=current_task_id
        )
    
    return StageResult(
        stage=stage,
        outcome=StageOutcome.SUCCESS,
        exit_code=exit_code,
        duration_seconds=duration,
        cost=metrics.iteration_cost if hasattr(metrics, 'iteration_cost') else 0,
        tokens_used=output_buffer.get_iteration_tokens(),
        task_id=current_task_id
    )


def print_plan_report(state: RalphState, mode: str):
    """Print a detailed plan report for developer review."""
    print(f"{Colors.BLUE}‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ{Colors.NC}")
    
    if mode == 'plan':
        print(f"{Colors.CYAN}PLAN REVIEW{Colors.NC} - {state.spec or 'no spec'}")
        print()
    
    # Build task ID to name map for dependency display
    task_names = {t.id: t.name for t in state.tasks}
    # Also include accepted task names from tombstones
    for tomb in state.tombstones:
        if tomb.tombstone_type == "accept" and tomb.name:
            task_names[tomb.id] = tomb.name
    completed_ids = state.completed_ids  # Done + accepted
    
    # Show pending tasks in topological order with full details
    if state.pending:
        sorted_pending = state.get_sorted_pending()
        print(f"{Colors.YELLOW}PENDING TASKS ({len(sorted_pending)}){Colors.NC}")
        print()
        for i, t in enumerate(sorted_pending, 1):
            # Check if task is blocked
            blocked = t.deps and not all(dep in completed_ids for dep in t.deps)
            if blocked:
                print(f"  {Colors.DIM}{i}. {t.name}{Colors.NC} [{t.id}] {Colors.RED}(blocked){Colors.NC}")
            else:
                print(f"  {Colors.WHITE}{i}. {t.name}{Colors.NC} [{t.id}]")
            
            if t.deps:
                dep_strs = []
                for dep in t.deps:
                    dep_name = task_names.get(dep, dep)[:30]
                    if dep in completed_ids:
                        dep_strs.append(f"{Colors.GREEN}‚úì {dep_name}{Colors.NC}")
                    else:
                        dep_strs.append(f"{Colors.RED}‚óã {dep_name}{Colors.NC}")
                print(f"     {Colors.CYAN}Deps:{Colors.NC} {', '.join(dep_strs)}")
            
            if t.notes:
                # Wrap notes nicely
                for line in t.notes.split('\n'):
                    print(f"     {Colors.DIM}{line}{Colors.NC}")
            if t.accept:
                print(f"     {Colors.GREEN}Verify:{Colors.NC} {t.accept}")
            print()
    
    # Show done tasks (completed but not yet accepted)
    if state.done:
        print(f"{Colors.GREEN}DONE ({len(state.done)}){Colors.NC} - awaiting verification")
        print()
        for i, t in enumerate(state.done, 1):
            print(f"  {Colors.DIM}{i}. {t.name}{Colors.NC} [{t.id}]")
            if t.accept:
                print(f"     {Colors.GREEN}Verify:{Colors.NC} {t.accept}")
            if t.done_at:
                print(f"     {Colors.DIM}Completed at: {t.done_at}{Colors.NC}")
            print()
    
    # Show issues
    if state.issues:
        print(f"{Colors.RED}ISSUES ({len(state.issues)}){Colors.NC}")
        print()
        for i in state.issues:
            print(f"  - {i.desc} [{i.id}]")
        print()
    
    # Summary
    total = len(state.pending) + len(state.done)
    if total > 0:
        print(f"{Colors.DIM}Total: {len(state.pending)} pending, {len(state.done)} done{Colors.NC}")


def cmd_construct(config: RalphConfig, max_iterations: int, max_cost: float,
                  max_failures: int, completion_promise: str, no_ui: bool = False,
                  spec_file: Optional[str] = None, stage_timeout_ms: int = DEFAULT_STAGE_TIMEOUT_MS,
                  context_limit: int = DEFAULT_CONTEXT_WINDOW):
    """
    Run construct mode using the proper state machine.
    
    Per construct-mode.md spec, each iteration runs:
      INVESTIGATE -> BUILD -> VERIFY (sequentially)
    
    With DECOMPOSE as an interrupt handler for failures.
    """
    if not config.ralph_dir.exists():
        print(f"{Colors.RED}Ralph not initialized. Run 'ralph init' first.{Colors.NC}")
        return 1
    
    # Pre-flight check: validate state for dangling deps
    state = load_state(config)
    validation = validate_state(state, config)
    if not validation['valid']:
        print(f"{Colors.RED}‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ{Colors.NC}")
        print(f"{Colors.RED}VALIDATION ERRORS - Cannot start construct{Colors.NC}")
        for err in validation['errors']:
            print(f"  {Colors.RED}‚úó{Colors.NC} {err}")
        print(f"{Colors.RED}‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ{Colors.NC}")
        print(f"{Colors.DIM}Run 'ralph validate' for details on how to fix.{Colors.NC}")
        return 1
    
    # Pre-flight check: verify opencode is available
    opencode_ok, opencode_error = check_opencode_available()
    if not opencode_ok:
        print(f"{Colors.RED}‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ{Colors.NC}")
        print(f"{Colors.RED}OPENCODE NOT AVAILABLE{Colors.NC}")
        print(f"{opencode_error}")
        print(f"{Colors.RED}‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ{Colors.NC}")
        return 1
    
    # Initialize metrics
    metrics = Metrics(started_at=datetime.now().isoformat())
    config.log_dir.mkdir(parents=True, exist_ok=True)
    
    branch = get_current_branch()
    consecutive_failures = 0
    
    # Detect interactive terminal
    interactive = sys.stdout.isatty() and not no_ui
    
    # Create FIFO for watch command
    if config.output_fifo.exists():
        if not stat.S_ISFIFO(config.output_fifo.stat().st_mode):
            config.output_fifo.unlink()
            os.mkfifo(str(config.output_fifo))
    else:
        os.mkfifo(str(config.output_fifo))
    
    # Check for project rules
    project_rules = find_project_rules(config.repo_root)
    rules_source = None
    if project_rules:
        for candidate in ['AGENTS.md', 'CLAUDE.md']:
            if (config.repo_root / candidate).exists():
                rules_source = candidate
                break
    
    # Load state to get spec
    state = load_state(config)
    if not state.spec:
        print(f"{Colors.YELLOW}No spec configured - run 'ralph plan <spec.md>' first{Colors.NC}")
        return 1
    
    # Calculate context limits
    plan_config = state.config
    if plan_config:
        soft_limit_pct = plan_config.context_warn * 100
        compact_limit_pct = plan_config.context_compact * 100
        hard_limit_pct = plan_config.context_kill * 100
    else:
        gcfg = get_global_config()
        soft_limit_pct = gcfg.context_warn_pct
        compact_limit_pct = gcfg.context_compact_pct
        hard_limit_pct = gcfg.context_kill_pct
    
    soft_limit = int(context_limit * soft_limit_pct / 100)
    compact_limit = int(context_limit * compact_limit_pct / 100)
    hard_limit = int(context_limit * hard_limit_pct / 100)
    
    # Print header
    print(f"{Colors.BLUE}‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ{Colors.NC}")
    print(f"Mode:   {Colors.GREEN}construct{Colors.NC} (state machine)")
    print(f"Spec:   {Colors.CYAN}{state.spec}{Colors.NC}")
    print(f"Branch: {branch}")
    if rules_source:
        print(f"Rules:  {Colors.GREEN}{rules_source}{Colors.NC}")
    else:
        print(f"Rules:  {Colors.YELLOW}None{Colors.NC}")
    if max_iterations > 0:
        print(f"Max iterations: {max_iterations}")
    if max_cost > 0:
        print(f"Max cost:       ${max_cost}")
    print(f"Max failures:   {max_failures} (circuit breaker)")
    print(f"Timeout:        {stage_timeout_ms}ms per stage")
    print(f"Context:        {context_limit:,} tokens (warn: {soft_limit:,}, compact: {compact_limit:,}, kill: {hard_limit:,})")
    if completion_promise:
        print(f"Completion:     \"{completion_promise}\"")
    print(f"{Colors.BLUE}‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ{Colors.NC}")
    
    # Create stage runner function
    def stage_runner(cfg, stage, st, met, timeout_ms, ctx_limit):
        return run_single_stage(
            cfg, stage, st, met, timeout_ms, ctx_limit,
            interactive=interactive,
            project_rules=project_rules,
            spec_file=state.spec
        )
    
    # Create state machine
    state_machine = ConstructStateMachine(
        config=config,
        metrics=metrics,
        stage_timeout_ms=stage_timeout_ms,
        context_limit=context_limit,
        run_stage_fn=stage_runner
    )
    
    # Prevent system sleep while ralph is running
    # macOS: caffeinate, Linux: systemd-inhibit
    sleep_inhibit_proc = None
    try:
        if sys.platform == "darwin":
            sleep_inhibit_proc = subprocess.Popen(
                ["caffeinate", "-dims"],  # -d: display, -i: idle, -m: disk, -s: system
                stdout=subprocess.DEVNULL,
                stderr=subprocess.DEVNULL,
            )
            print(f"{Colors.DIM}Sleep prevention: enabled (caffeinate){Colors.NC}")
        elif sys.platform == "linux":
            # systemd-inhibit runs the current process under inhibit lock
            # We spawn it with 'cat' as a long-running process to hold the lock
            sleep_inhibit_proc = subprocess.Popen(
                ["systemd-inhibit", "--what=idle:sleep:handle-lid-switch",
                 "--who=ralph", "--why=Ralph construct mode running",
                 "cat"],
                stdin=subprocess.PIPE,
                stdout=subprocess.DEVNULL,
                stderr=subprocess.DEVNULL,
            )
            print(f"{Colors.DIM}Sleep prevention: enabled (systemd-inhibit){Colors.NC}")
    except (FileNotFoundError, subprocess.SubprocessError):
        pass  # sleep inhibitor not available, continue without it
    
    iteration = 0
    try:
        while True:
            # Check iteration limit
            if max_iterations > 0 and iteration >= max_iterations:
                print(f"{Colors.BLUE}‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ{Colors.NC}")
                print(f"Reached max iterations: {max_iterations}")
                print(f"{Colors.CYAN}Total cost: ${metrics.total_cost:.4f}{Colors.NC}")
                print(f"{Colors.BLUE}‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ{Colors.NC}")
                break
            
            # Check cost limit
            if max_cost > 0 and metrics.total_cost >= max_cost:
                print(f"{Colors.YELLOW}‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ{Colors.NC}")
                print(f"{Colors.YELLOW}COST LIMIT REACHED{Colors.NC}")
                print(f"Spent: ${metrics.total_cost:.4f} / ${max_cost}")
                print(f"{Colors.YELLOW}‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ{Colors.NC}")
                break
            
            # Check circuit breaker
            if consecutive_failures >= max_failures:
                print(f"{Colors.RED}‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ{Colors.NC}")
                print(f"{Colors.RED}CIRCUIT BREAKER TRIPPED{Colors.NC}")
                print(f"{consecutive_failures} consecutive failures detected")
                print(f"{Colors.RED}‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ{Colors.NC}")
                break
            
            iteration += 1
            metrics.total_iterations += 1
            write_runtime_iteration(config, iteration)
            
            # Sync with remote before each iteration to pick up changes from other Ralph instances
            sync_result = sync_with_remote(config, branch)
            if sync_result == "conflict":
                print(f"{Colors.RED}‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ{Colors.NC}")
                print(f"{Colors.RED}GIT CONFLICT DETECTED{Colors.NC}")
                print(f"Another Ralph instance made conflicting changes.")
                print(f"Stopping to avoid data loss. Please resolve manually.")
                print(f"{Colors.RED}‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ{Colors.NC}")
                break
            elif sync_result == "updated":
                print(f"{Colors.CYAN}Synced with remote - reloading state{Colors.NC}")
                state = load_state(config)
            
            if not interactive:
                if max_cost > 0:
                    cost_display = f" | Cost: ${metrics.total_cost:.4f}/${max_cost}"
                else:
                    cost_display = f" | Cost: ${metrics.total_cost:.4f}"
                
                print()
                print(f"{Colors.GREEN}‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó{Colors.NC}")
                print(f"{Colors.GREEN}‚ïë  ITERATION {iteration} - {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}{cost_display}{Colors.NC}")
                print(f"{Colors.GREEN}‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù{Colors.NC}")
                print()
            
            # Run one iteration of the state machine
            should_continue, spec_complete = state_machine.run_iteration(iteration)
            
            if spec_complete:
                print(f"{Colors.GREEN}‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ{Colors.NC}")
                print(f"{Colors.GREEN}SPEC COMPLETE: {state.spec}{Colors.NC}")
                print(f"Total cost: ${metrics.total_cost:.4f}")
                print(f"Iterations: {iteration}")
                print(f"{Colors.GREEN}‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ{Colors.NC}")
                break
            
            if not should_continue:
                print(f"{Colors.YELLOW}‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ{Colors.NC}")
                print(f"{Colors.YELLOW}No more work to do{Colors.NC}")
                print(f"Total cost: ${metrics.total_cost:.4f}")
                print(f"{Colors.YELLOW}‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ{Colors.NC}")
                break
            
            # Commit any plan changes after each iteration
            if has_uncommitted_plan(config):
                subprocess.run(['git', 'add', str(config.plan_file)],
                              cwd=config.repo_root, capture_output=True)
                subprocess.run(['git', 'commit', '-m', f'ralph: iteration {iteration}'],
                              cwd=config.repo_root, capture_output=True)
            
            # Push changes with retry (handles upstream changes from other Ralph instances)
            if not push_with_retry(config, branch):
                print(f"{Colors.RED}‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ{Colors.NC}")
                print(f"{Colors.RED}PUSH FAILED - STOPPING{Colors.NC}")
                print(f"Could not push changes to remote. Another Ralph instance may have")
                print(f"conflicting changes. Please resolve manually and restart.")
                print(f"{Colors.RED}‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ{Colors.NC}")
                break
    
    except KeyboardInterrupt:
        print(f"\n{Colors.YELLOW}Interrupted by user{Colors.NC}")
    finally:
        # Terminate sleep inhibitor
        if sleep_inhibit_proc is not None:
            try:
                sleep_inhibit_proc.terminate()
                sleep_inhibit_proc.wait(timeout=2)
            except (subprocess.TimeoutExpired, OSError):
                sleep_inhibit_proc.kill()
        
        clear_runtime_state(config)
        
        # Show final state
        final_state = load_state(config)
        if final_state.tasks or final_state.issues:
            print_plan_report(final_state, 'construct')
        print(f"{Colors.BLUE}‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ{Colors.NC}")
    
    return 0


def cmd_run(config: RalphConfig, mode: str, max_iterations: int, max_cost: float,
            max_failures: int, completion_promise: str, no_ui: bool = False,
            spec_file: Optional[str] = None, stage_timeout_ms: int = DEFAULT_STAGE_TIMEOUT_MS,
            context_limit: int = DEFAULT_CONTEXT_WINDOW):
    """Run the main loop."""
    # Convert timeout from milliseconds to seconds for internal use
    iteration_timeout = stage_timeout_ms / 1000.0
    
    if not config.ralph_dir.exists():
        print(f"{Colors.RED}Ralph not initialized. Run 'ralph init' first.{Colors.NC}")
        return 1

    # For plan mode, spec_file is required
    if mode == 'plan' and not spec_file:
        print(f"{Colors.RED}Plan mode requires a spec file: ralph plan <spec.md>{Colors.NC}")
        return 1

    # Pre-flight check: verify opencode is available
    opencode_ok, opencode_error = check_opencode_available()
    if not opencode_ok:
        print(f"{Colors.RED}‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ{Colors.NC}")
        print(f"{Colors.RED}OPENCODE NOT AVAILABLE{Colors.NC}")
        print(f"{opencode_error}")
        print(f"{Colors.RED}‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ{Colors.NC}")
        return 1

    # Initialize metrics
    metrics = Metrics(started_at=datetime.now().isoformat())
    config.log_dir.mkdir(parents=True, exist_ok=True)
    
    branch = get_current_branch()
    consecutive_failures = 0
    
    # Detect interactive terminal (can be overridden with --no-ui)
    interactive = sys.stdout.isatty() and not no_ui
    
    # Create FIFO for watch command
    if config.output_fifo.exists():
        if not stat.S_ISFIFO(config.output_fifo.stat().st_mode):
            config.output_fifo.unlink()  # Remove regular file
            os.mkfifo(str(config.output_fifo))
    else:
        os.mkfifo(str(config.output_fifo))

    # Check for project rules upfront
    project_rules = find_project_rules(config.repo_root)
    rules_source = None
    if project_rules:
        for candidate in ['AGENTS.md', 'CLAUDE.md']:
            if (config.repo_root / candidate).exists():
                rules_source = candidate
                break

    # Load plan config to get context thresholds
    plan_state = load_state(config)
    plan_config = plan_state.config
    
    # Calculate context limits, using plan config if available
    if plan_config:
        soft_limit_pct = plan_config.context_warn * 100
        compact_limit_pct = plan_config.context_compact * 100
        hard_limit_pct = plan_config.context_kill * 100
    else:
        gcfg = get_global_config()
        soft_limit_pct = gcfg.context_warn_pct
        compact_limit_pct = gcfg.context_compact_pct
        hard_limit_pct = gcfg.context_kill_pct
    
    soft_limit = int(context_limit * soft_limit_pct / 100)
    compact_limit = int(context_limit * compact_limit_pct / 100)
    hard_limit = int(context_limit * hard_limit_pct / 100)

    print(f"{Colors.BLUE}‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ{Colors.NC}")
    print(f"Mode:   {Colors.GREEN}{mode}{Colors.NC}")
    if spec_file:
        print(f"Spec:   {Colors.CYAN}{spec_file}{Colors.NC}")
    print(f"Branch: {branch}")
    if rules_source:
        print(f"Rules:  {Colors.GREEN}{rules_source}{Colors.NC}")
    else:
        print(f"Rules:  {Colors.YELLOW}None{Colors.NC}")
    if max_iterations > 0:
        print(f"Max iterations: {max_iterations}")
    if max_cost > 0:
        print(f"Max cost:       ${max_cost}")
    print(f"Max failures:   {max_failures} (circuit breaker)")
    print(f"Timeout:        {stage_timeout_ms}ms per iteration")
    print(f"Context:        {context_limit:,} tokens (warn: {soft_limit:,}, compact: {compact_limit:,}, kill: {hard_limit:,})")
    if completion_promise:
        print(f"Completion:     \"{completion_promise}\"")
    print(f"{Colors.BLUE}‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ{Colors.NC}")



    iteration = 0
    try:
        while True:
            # Check iteration limit
            if max_iterations > 0 and iteration >= max_iterations:
                print(f"{Colors.BLUE}‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ{Colors.NC}")
                print(f"Reached max iterations: {max_iterations}")
                print(f"{Colors.CYAN}Total cost: ${metrics.total_cost:.4f}{Colors.NC}")
                print(f"{Colors.BLUE}‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ{Colors.NC}")
                break

            # Check cost limit
            if max_cost > 0 and metrics.total_cost >= max_cost:
                print(f"{Colors.YELLOW}‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ{Colors.NC}")
                print(f"{Colors.YELLOW}COST LIMIT REACHED{Colors.NC}")
                print(f"Spent: ${metrics.total_cost:.4f} / ${max_cost}")
                print(f"{Colors.YELLOW}‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ{Colors.NC}")
                break

            # Check circuit breaker
            if consecutive_failures >= max_failures:
                print(f"{Colors.RED}‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ{Colors.NC}")
                print(f"{Colors.RED}CIRCUIT BREAKER TRIPPED{Colors.NC}")
                print(f"{consecutive_failures} consecutive failures detected")
                print(f"{Colors.RED}‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ{Colors.NC}")
                break

            iteration += 1
            metrics.total_iterations += 1
            write_runtime_iteration(config, iteration)
            start_time = time.time()

            if not interactive:
                # Cost display for non-interactive mode
                if max_cost > 0:
                    cost_display = f" | Cost: ${metrics.total_cost:.4f}/${max_cost}"
                else:
                    cost_display = f" | Cost: ${metrics.total_cost:.4f}"

                print()
                print(f"{Colors.GREEN}‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó{Colors.NC}")
                print(f"{Colors.GREEN}‚ïë  ITERATION {iteration} - {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}{cost_display}{Colors.NC}")
                print(f"{Colors.GREEN}‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù{Colors.NC}")
                print()

            # Determine prompt based on current stage
            state = load_state(config)
            stage = state.get_stage()
            
            # Check for terminal states in build mode
            if mode != 'plan':
                if stage == 'COMPLETE':
                    print(f"{Colors.GREEN}‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ{Colors.NC}")
                    print(f"{Colors.GREEN}COMPLETE{Colors.NC} - No tasks to execute")
                    if state.spec:
                        print(f"Spec: {state.spec}")
                    print(f"Run 'ralph plan <spec.md>' to add new tasks")
                    print(f"{Colors.GREEN}‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ{Colors.NC}")
                    break
                elif stage == 'PLAN':
                    print(f"{Colors.YELLOW}‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ{Colors.NC}")
                    print(f"{Colors.YELLOW}NO PLAN{Colors.NC} - No spec configured")
                    print(f"Run 'ralph plan <spec.md>' to create a plan first")
                    print(f"{Colors.YELLOW}‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ{Colors.NC}")
                    break
            
            # Ensure plan.jsonl is committed before BUILD stage begins
            # This catches changes made by INVESTIGATE stage (task additions)
            if stage == 'BUILD' and has_uncommitted_plan(config):
                subprocess.run(['git', 'add', str(config.plan_file)], 
                              cwd=config.repo_root, capture_output=True)
                subprocess.run(['git', 'commit', '-m', 'ralph: update plan (from investigate)'],
                              cwd=config.repo_root, capture_output=True)
                print(f"{Colors.GREEN}Committed plan.jsonl before BUILD stage{Colors.NC}")
            
            prompt_file = get_prompt_for_stage(config, mode, stage)
            
            if not prompt_file.exists():
                print(f"{Colors.RED}Prompt file not found: {prompt_file}{Colors.NC}")
                return 1
            
            prompt_content = prompt_file.read_text()
            
            # Substitute spec file placeholder for plan mode
            if spec_file:
                prompt_content = prompt_content.replace('{{SPEC_FILE}}', spec_file)
            
            # Incorporate project rules (already loaded above, reuse for efficiency)
            prompt_content = build_prompt_with_rules(prompt_content, project_rules)
            
            # Get current task info for kill tracking and log naming
            # Use get_next_task() to match the task that will actually be executed
            current_task_id = None
            current_task_name = None
            current_task = state.get_next_task()
            if current_task:
                current_task_id = current_task.id
                current_task_name = current_task.name
            
            # For BUILD stage, save the assigned task ID so `ralph task done` knows which task to mark
            # This prevents the "wrong task marked done" bug when task ordering changes mid-iteration
            if stage == 'BUILD' and current_task_id:
                save_current_task(config, current_task_id)
            
            output_buffer = OutputBuffer()

            gcfg = get_global_config()
            # BUILD uses fast model, but upgrades to main model if task is complex
            # All other stages always use main model
            if stage == 'BUILD':
                model = gcfg.model_build
                # Upgrade to main model if task is struggling
                if current_task:
                    if current_task.reject_reason:
                        # Previously rejected - needs more capability
                        model = gcfg.model
                    elif current_task.priority == 'high':
                        # High priority tasks get main model
                        model = gcfg.model
                    elif current_task.decompose_depth > 0:
                        # Already been decomposed - subtasks are tricky
                        model = gcfg.model
            else:
                model = gcfg.model
            
            cmd = ['opencode', 'run', '--model', model, 
                   '--format', 'json', prompt_content]
            
            # Use ephemeral state directory to avoid polluting session list
            opencode_env = os.environ.copy()
            opencode_env['XDG_STATE_HOME'] = '/tmp/ralph-opencode-state'
            # Permission config:
            # - Deny external_directory by default to fail fast instead of hanging on prompts
            # - But allow reading /tmp/ralph-logs/* for DECOMPOSE stage to review failed iteration
            permission_config = {
                "external_directory": "deny",
                "doom_loop": "deny"
            }
            if stage == 'DECOMPOSE':
                # Allow reading ralph logs so decompose can analyze the killed iteration
                # Logs are in /tmp/ralph-logs/
                permission_config["read"] = {
                    "*": "allow"
                }
                permission_config["external_directory"] = {
                    "*": "deny"
                }
            opencode_env['OPENCODE_PERMISSION'] = json.dumps(permission_config)
            
            # opencode | ralph stream, capture stdout
            # Use DEVNULL for stdin to prevent any prompts from blocking
            opencode_proc = subprocess.Popen(
                cmd,
                stdin=subprocess.DEVNULL,
                stdout=subprocess.PIPE,
                stderr=subprocess.STDOUT,
                cwd=config.repo_root,
                env=opencode_env
            )
            
            ralph_stream_proc = subprocess.Popen(
                [sys.executable, __file__, 'stream'],
                stdin=opencode_proc.stdout,
                stdout=subprocess.PIPE,
                stderr=subprocess.STDOUT,
            )
            
            # Allow opencode to receive SIGPIPE if ralph stream exits
            if opencode_proc.stdout:
                opencode_proc.stdout.close()
            
            # Track if we killed this iteration (shared state for monitor thread)
            kill_state = {"killed": False, "reason": "none", "info": None, "compact_requested": False}
            soft_warned = [False]  # Use list for mutability in closure
            compact_attempted = [False]  # Track if we've attempted compaction at 85%
            compaction_in_progress = [False]  # Track if we're running with compacted context
            reader_stop = threading.Event()
            
            # Start reader thread with stop event for clean shutdown
            reader_thread = threading.Thread(
                target=stream_output,
                args=(ralph_stream_proc.stdout, output_buffer, metrics, not interactive, config.output_fifo, reader_stop)
            )
            reader_thread.daemon = True
            reader_thread.start()
            
            def monitor_limits():
                """Monitor thread that checks timeout and context limits."""
                deadline = time.time() + iteration_timeout
                check_interval = 2.0
                
                while ralph_stream_proc.poll() is None and opencode_proc.poll() is None:
                    if kill_state["killed"]:
                        break
                        
                    elapsed = int(time.time() - start_time)
                    current_tokens = output_buffer.get_iteration_tokens()
                    
                    # Check timeout
                    if time.time() >= deadline:
                        kill_state["killed"] = True
                        kill_state["reason"] = "timeout"
                        kill_state["info"] = IterationKillInfo(
                            reason="timeout",
                            task_name=current_task_name,
                            timeout_seconds=iteration_timeout,
                            elapsed_seconds=elapsed,
                            last_activity=output_buffer.get_last_activity()
                        )
                        # Kill the processes
                        try:
                            opencode_proc.terminate()
                            ralph_stream_proc.terminate()
                        except:
                            pass
                        break
                    
                    # Check context hard limit (95%)
                    if current_tokens >= hard_limit:
                        kill_state["killed"] = True
                        kill_state["reason"] = "context_limit"
                        kill_state["info"] = IterationKillInfo(
                            reason="context_limit",
                            task_name=current_task_name,
                            tokens_used=current_tokens,
                            context_limit=context_limit,
                            elapsed_seconds=elapsed,
                            last_activity=output_buffer.get_last_activity()
                        )
                        # Kill the processes
                        try:
                            opencode_proc.terminate()
                            ralph_stream_proc.terminate()
                        except:
                            pass
                        break
                    
                    # Check compact limit (85%) - attempt compaction by terminating and resuming
                    if not interactive and current_tokens >= compact_limit and not compact_attempted[0]:
                        compact_attempted[0] = True
                        pct = current_tokens / context_limit * 100
                        print(f"\n{Colors.YELLOW}[RALPH] Context at {pct:.0f}% - requesting compaction...{Colors.NC}")
                        
                        # Request compaction - main loop will handle resumption
                        kill_state["compact_requested"] = True
                        kill_state["info"] = IterationKillInfo(
                            reason="compaction_requested",
                            task_name=current_task_name,
                            tokens_used=current_tokens,
                            context_limit=context_limit,
                            elapsed_seconds=elapsed,
                            last_activity=output_buffer.get_last_activity()
                        )
                        # Terminate the processes gracefully
                        try:
                            opencode_proc.terminate()
                            ralph_stream_proc.terminate()
                        except:
                            pass
                        break
                    
                    # Soft warning at 70% (both interactive and non-interactive modes)
                    if current_tokens >= soft_limit and not soft_warned[0]:
                        pct = current_tokens / context_limit * 100
                        print(f"\n{Colors.YELLOW}[RALPH] Context pressure: {pct:.0f}% - consider wrapping up ({current_tokens:,}/{context_limit:,} tokens){Colors.NC}")
                        soft_warned[0] = True
                    
                    time.sleep(check_interval)
            
            # Start monitor thread
            monitor_thread = threading.Thread(target=monitor_limits, daemon=True)
            monitor_thread.start()
            
            if interactive:
                exit_code = run_with_live_ui(ralph_stream_proc, config, iteration, 
                                              metrics, branch, output_buffer)
            else:
                # Poll instead of blocking wait, so monitor thread can kill us
                while ralph_stream_proc.poll() is None:
                    if kill_state["killed"] or kill_state["compact_requested"]:
                        break
                    time.sleep(0.1)
                exit_code = ralph_stream_proc.returncode if ralph_stream_proc.returncode is not None else -1
            
            # Wait for monitor to finish
            monitor_thread.join(timeout=1.0)
            
            # Handle compaction request - attempt to resume with compacted context
            if kill_state["compact_requested"] and not kill_state["killed"]:
                print(f"{Colors.YELLOW}‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ{Colors.NC}")
                print(f"{Colors.YELLOW}COMPACTION: Building compacted context...{Colors.NC}")
                
                # Clean up current processes
                reader_stop.set()
                try:
                    ralph_stream_proc.kill()
                    opencode_proc.kill()
                except:
                    pass
                reader_thread.join(timeout=2.0)
                if opencode_proc.poll() is None:
                    opencode_proc.wait()
                
                # Build compacted context
                current_task = state.get_next_task()
                if current_task:
                    compacted = build_compacted_context(
                        current_task,
                        config.repo_root,
                        output_buffer.get_all()
                    )
                    compacted_prompt = compacted.to_prompt()
                    
                    # Combine with original prompt
                    full_prompt = compacted_prompt + "\n\n" + prompt_content
                    
                    print(f"{Colors.GREEN}[RALPH] Context compacted. Resuming execution...{Colors.NC}")
                    print(f"{Colors.YELLOW}‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ{Colors.NC}")
                    
                    # Create new output buffer for resumed execution
                    output_buffer = OutputBuffer()
                    compaction_in_progress[0] = True
                    
                    # Start new opencode process with compacted context
                    model = get_global_config().model
                    cmd = ['opencode', 'run', '--model', model, 
                           '--format', 'json', full_prompt]
                    
                    opencode_proc = subprocess.Popen(
                        cmd,
                        stdin=subprocess.DEVNULL,
                        stdout=subprocess.PIPE,
                        stderr=subprocess.STDOUT,
                        cwd=config.repo_root,
                        env=opencode_env
                    )
                    
                    ralph_stream_proc = subprocess.Popen(
                        [sys.executable, __file__, 'stream'],
                        stdin=opencode_proc.stdout,
                        stdout=subprocess.PIPE,
                        stderr=subprocess.STDOUT,
                    )
                    
                    if opencode_proc.stdout:
                        opencode_proc.stdout.close()
                    
                    # Reset kill state for resumed execution (but keep compact_attempted=True)
                    kill_state = {"killed": False, "reason": "none", "info": None, "compact_requested": False}
                    reader_stop = threading.Event()
                    
                    # Start new reader thread
                    reader_thread = threading.Thread(
                        target=stream_output,
                        args=(ralph_stream_proc.stdout, output_buffer, metrics, not interactive, config.output_fifo, reader_stop)
                    )
                    reader_thread.daemon = True
                    reader_thread.start()
                    
                    # Start new monitor thread - only check 70% resume threshold and hard limit
                    resumed_start_time = time.time()
                    resume_check_done = [False]
                    
                    def monitor_resumed():
                        """Monitor thread for resumed execution after compaction."""
                        resumed_deadline = resumed_start_time + iteration_timeout
                        check_interval = 2.0
                        resume_threshold = int(context_limit * 0.70)  # Check if < 70% after compaction
                        
                        while ralph_stream_proc.poll() is None and opencode_proc.poll() is None:
                            if kill_state["killed"]:
                                break
                            
                            resumed_elapsed = int(time.time() - resumed_start_time)
                            current_tokens = output_buffer.get_iteration_tokens()
                            
                            # Check timeout
                            if time.time() >= resumed_deadline:
                                kill_state["killed"] = True
                                kill_state["reason"] = "timeout"
                                kill_state["info"] = IterationKillInfo(
                                    reason="timeout",
                                    task_name=current_task_name,
                                    timeout_seconds=iteration_timeout,
                                    elapsed_seconds=resumed_elapsed,
                                    last_activity=output_buffer.get_last_activity()
                                )
                                try:
                                    opencode_proc.terminate()
                                    ralph_stream_proc.terminate()
                                except:
                                    pass
                                break
                            
                            # Check if context is too high after compaction (compaction failed)
                            # We give it some time to start, then check if still > 80%
                            if current_tokens > 0 and not resume_check_done[0]:
                                resume_check_done[0] = True
                                pct = current_tokens / context_limit * 100
                                if current_tokens > int(context_limit * 0.80):
                                    print(f"\n{Colors.RED}[RALPH] Compaction failed - still at {pct:.0f}% after resume{Colors.NC}")
                                    kill_state["killed"] = True
                                    kill_state["reason"] = "compaction_failed"
                                    kill_state["info"] = IterationKillInfo(
                                        reason="compaction_failed",
                                        task_name=current_task_name,
                                        tokens_used=current_tokens,
                                        context_limit=context_limit,
                                        elapsed_seconds=resumed_elapsed,
                                        last_activity=output_buffer.get_last_activity()
                                    )
                                    try:
                                        opencode_proc.terminate()
                                        ralph_stream_proc.terminate()
                                    except:
                                        pass
                                    break
                                else:
                                    print(f"\n{Colors.GREEN}[RALPH] Context compacted: resumed at {pct:.0f}%{Colors.NC}")
                            
                            # Check hard limit (95%)
                            if current_tokens >= hard_limit:
                                kill_state["killed"] = True
                                kill_state["reason"] = "context_limit"
                                kill_state["info"] = IterationKillInfo(
                                    reason="context_limit",
                                    task_name=current_task_name,
                                    tokens_used=current_tokens,
                                    context_limit=context_limit,
                                    elapsed_seconds=resumed_elapsed,
                                    last_activity=output_buffer.get_last_activity()
                                )
                                try:
                                    opencode_proc.terminate()
                                    ralph_stream_proc.terminate()
                                except:
                                    pass
                                break
                            
                            time.sleep(check_interval)
                    
                    resumed_monitor_thread = threading.Thread(target=monitor_resumed, daemon=True)
                    resumed_monitor_thread.start()
                    
                    # Wait for resumed process
                    while ralph_stream_proc.poll() is None:
                        if kill_state["killed"]:
                            break
                        time.sleep(0.1)
                    exit_code = ralph_stream_proc.returncode if ralph_stream_proc.returncode is not None else -1
                    
                    resumed_monitor_thread.join(timeout=1.0)
                    
                    # Update start_time for duration calculation
                    start_time = resumed_start_time
                else:
                    # No current task - treat as failure
                    print(f"{Colors.RED}[RALPH] No current task for compaction - treating as failure{Colors.NC}")
                    kill_state["killed"] = True
                    kill_state["reason"] = "compaction_failed"
            
            # Check if we were killed by the monitor
            if kill_state["killed"]:
                print(f"\n{Colors.RED}‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ{Colors.NC}")
                if kill_state["reason"] == "timeout":
                    print(f"{Colors.RED}TIMEOUT: Iteration killed after {stage_timeout_ms}ms{Colors.NC}")
                elif kill_state["info"] and kill_state["info"].tokens_used > 0:
                    pct = kill_state["info"].tokens_used / context_limit * 100
                    reason_text = "COMPACTION FAILED" if kill_state["reason"] == "compaction_failed" else "CONTEXT LIMIT"
                    print(f"{Colors.RED}{reason_text}: Iteration killed at {kill_state['info'].tokens_used:,} tokens ({pct:.0f}%){Colors.NC}")
                else:
                    print(f"{Colors.RED}KILLED: {kill_state['reason']}{Colors.NC}")
                print(f"Last activity: {output_buffer.get_last_activity() or 'unknown'}")
                
                print(f"{Colors.RED}‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ{Colors.NC}")
                # Signal reader thread to stop and ensure processes are dead
                reader_stop.set()
                try:
                    ralph_stream_proc.kill()
                    opencode_proc.kill()
                except:
                    pass
                exit_code = -1
            
            # Signal reader to stop (in case of normal exit too)
            reader_stop.set()
            reader_thread.join(timeout=2.0)
            if opencode_proc.poll() is None:
                opencode_proc.wait()

            duration = int(time.time() - start_time)

            # Check for immediate failure (e.g., bad model name, missing API key)
            if exit_code != 0 and duration < 5 and not output_buffer.get_all().strip():
                print(f"{Colors.RED}‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ{Colors.NC}")
                print(f"{Colors.RED}OPENCODE FAILED TO START{Colors.NC}")
                print(f"Exit code: {exit_code}")
                print(f"Check model name, API keys, and opencode configuration.")
                print(f"Run with --no-ui to see error output.")
                print(f"{Colors.RED}‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ{Colors.NC}")

            # Track success/failure
            # Context/timeout kills are NOT failures - they're expected behavior that triggers retry
            if exit_code == 0:
                consecutive_failures = 0
                metrics.successes += 1
            elif kill_state["killed"]:
                # Killed by monitor (timeout or context limit) - don't count as failure
                # The next iteration will get guidance to break down the problem
                kill_info = kill_state["info"]
                metrics.last_kill_reason = kill_state["reason"]
                metrics.last_kill_activity = kill_info.last_activity if kill_info else "unknown"
                if kill_state["reason"] == "timeout":
                    metrics.kills_timeout += 1
                elif kill_state["reason"] in ("context_limit", "compaction_failed"):
                    metrics.kills_context += 1
            else:
                consecutive_failures += 1
                metrics.failures += 1

            # Log iteration output to /tmp/ralph-logs/
            # Filename format: ralph-<timestamp>-<stage>.log per spec
            config.log_dir.mkdir(parents=True, exist_ok=True)
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            log_file = config.log_dir / f"ralph-{timestamp}-{stage.lower()}.log"
            try:
                with log_file.open('w') as f:
                    f.write(f"# Ralph {mode} iteration {iteration} - {stage}\n")
                    f.write(f"# Date: {datetime.now().isoformat()}\n")
                    f.write(f"# Exit code: {exit_code}\n")
                    f.write(f"# Duration: {duration}s\n")
                    f.write(f"# Spec: {spec_file or 'N/A'}\n")
                    f.write(f"# Stage: {stage}\n")
                    f.write(f"# Task: {current_task_name or 'N/A'}\n")
                    f.write(f"# Repo: {config.repo_root}\n")
                    if kill_state["killed"]:
                        f.write(f"# Kill reason: {kill_state['reason']}\n")
                    f.write("\n")
                    f.write(output_buffer.get_all())
                log_file_written = str(log_file)
            except Exception as e:
                log_file_written = None

            # Mark task for decomposition AFTER writing log so we can reference it
            # Per construct-mode.md spec: task with kill_reason triggers DECOMPOSE stage
            if kill_state["killed"] and current_task_id and stage == 'BUILD':
                current_state = load_state(config)
                # Find task by ID (more reliable than name matching)
                task = next((t for t in current_state.tasks if t.id == current_task_id), None)
                if task:
                    task.kill_reason = kill_state["reason"]
                    task.kill_log = log_file_written
                    save_state(config, current_state)
                    print(f"{Colors.YELLOW}Task marked for decomposition: {task.id}{Colors.NC}")
                    if log_file_written:
                        print(f"{Colors.YELLOW}Kill log: {log_file_written}{Colors.NC}")
                    print(f"{Colors.YELLOW}Next iteration will run DECOMPOSE stage{Colors.NC}")

            if not interactive:
                print()
                print(f"{Colors.BLUE}‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê{Colors.NC}")
                print(f"{Colors.BLUE}‚îÇ  Iteration {iteration}: {duration}s (total: ${metrics.total_cost:.4f}){Colors.NC}")
                print(f"{Colors.BLUE}‚îÇ  Exit: {exit_code} | Failures: {consecutive_failures}/{max_failures}{Colors.NC}")
                print(f"{Colors.BLUE}‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò{Colors.NC}")

            # Check completion promise
            if completion_promise:
                if completion_promise in output_buffer.get_all():
                    print(f"{Colors.GREEN}‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ{Colors.NC}")
                    print(f"{Colors.GREEN}COMPLETION PROMISE DETECTED{Colors.NC}")
                    print(f"Found: {completion_promise}")
                    print(f"{Colors.GREEN}‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ{Colors.NC}")
                    break

            # Check for spec complete signals - but verify against actual state
            output_text = output_buffer.get_all()
            if '[RALPH] SPEC_COMPLETE' in output_text or '[RALPH] SPEC_VERIFIED' in output_text:
                # Reload state to verify - don't trust AI output alone
                current_state = load_state(config)
                if current_state.issues:
                    # AI said complete but there are issues - continue to INVESTIGATE
                    print(f"{Colors.YELLOW}‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ{Colors.NC}")
                    print(f"{Colors.YELLOW}SPEC_COMPLETE signal ignored - {len(current_state.issues)} issues pending{Colors.NC}")
                    print(f"{Colors.YELLOW}Continuing to INVESTIGATE stage...{Colors.NC}")
                    print(f"{Colors.YELLOW}‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ{Colors.NC}")
                    # Don't break - let loop continue
                elif current_state.pending or current_state.done:
                    # AI said complete but there are still tasks
                    print(f"{Colors.YELLOW}‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ{Colors.NC}")
                    print(f"{Colors.YELLOW}SPEC_COMPLETE signal ignored - tasks still pending/done{Colors.NC}")
                    print(f"{Colors.YELLOW}‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ{Colors.NC}")
                    # Don't break - let loop continue
                else:
                    # Actually complete
                    spec_match = re.search(r'\[RALPH\] SPEC_(?:COMPLETE|VERIFIED):?\s*(\S+)?', output_text)
                    spec_name = spec_match.group(1) if spec_match and spec_match.group(1) else spec_file or 'unknown'
                    print(f"{Colors.GREEN}‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ{Colors.NC}")
                    print(f"{Colors.GREEN}SPEC COMPLETE: {spec_name}{Colors.NC}")
                    print(f"Total cost: ${metrics.total_cost:.4f}")
                    print(f"Iterations: {metrics.total_iterations}")
                    print(f"{Colors.GREEN}‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ{Colors.NC}")
                    break
            
            # Check for plan complete signal - commit the plan
            if '[RALPH] PLAN_COMPLETE' in output_text and mode == 'plan':
                # Auto-prioritize tasks before committing
                # cmd_task outputs JSON, so we capture stdout to show a cleaner message
                f = io.StringIO()
                with redirect_stdout(f):
                    prioritize_result = cmd_task(config, 'prioritize')
                prioritize_output = f.getvalue().strip()
                if prioritize_result is None or prioritize_result == 0:
                    try:
                        pdata = json.loads(prioritize_output)
                        print(f"{Colors.GREEN}Auto-prioritized {pdata.get('prioritized', 0)} tasks (high: {pdata.get('high', 0)}, medium: {pdata.get('medium', 0)}, low: {pdata.get('low', 0)}){Colors.NC}")
                    except json.JSONDecodeError:
                        print(f"{Colors.GREEN}Auto-prioritized tasks{Colors.NC}")
                
                # Commit the plan.jsonl with all added tasks
                if has_uncommitted_plan(config):
                    task_count_match = re.search(r'\[RALPH\] PLAN_COMPLETE: Added (\d+) tasks', output_text)
                    task_count = task_count_match.group(1) if task_count_match else "?"
                    subprocess.run(['git', 'add', str(config.plan_file)], 
                                  cwd=config.repo_root, capture_output=True)
                    subprocess.run(['git', 'commit', '-m', f'ralph: plan {spec_file} ({task_count} tasks)'],
                                  cwd=config.repo_root, capture_output=True)
                    print(f"{Colors.GREEN}Committed plan with {task_count} tasks{Colors.NC}")
                break

            # Auto-prioritize after VERIFY stage before transitioning to next iteration
            # This covers: SPEC_INCOMPLETE signal, no signal (timeout/forgot), or SPEC_COMPLETE that was ignored
            if stage == 'VERIFY':
                f = io.StringIO()
                with redirect_stdout(f):
                    prioritize_result = cmd_task(config, 'prioritize')
                prioritize_output = f.getvalue().strip()
                if prioritize_result is None or prioritize_result == 0:
                    try:
                        pdata = json.loads(prioritize_output)
                        print(f"{Colors.GREEN}Auto-prioritized {pdata.get('prioritized', 0)} tasks (high: {pdata.get('high', 0)}, medium: {pdata.get('medium', 0)}, low: {pdata.get('low', 0)}){Colors.NC}")
                    except json.JSONDecodeError:
                        print(f"{Colors.GREEN}Auto-prioritized tasks{Colors.NC}")

            # Push changes
            try:
                subprocess.run(['git', 'push', 'origin', branch], 
                             capture_output=True, cwd=config.repo_root)
            except Exception:
                try:
                    subprocess.run(['git', 'push', '-u', 'origin', branch],
                                 capture_output=True, cwd=config.repo_root)
                except Exception:
                    pass

            if not interactive:
                # Show recent commits
                print()
                print("Recent commits:")
                try:
                    result = subprocess.run(
                        ['git', '--no-pager', 'log', '--oneline', '-3'],
                        capture_output=True, text=True, cwd=config.repo_root
                    )
                    print(result.stdout)
                except Exception:
                    pass

    except KeyboardInterrupt:
        print(f"\n{Colors.YELLOW}Interrupted by user{Colors.NC}")
    finally:
        clear_runtime_state(config)
        # Summary with success/failure status
        if metrics.failures == 0 and metrics.successes > 0:
            status = f"{Colors.GREEN}SUCCESS{Colors.NC}"
        elif metrics.failures > 0 and metrics.successes == 0:
            status = f"{Colors.RED}FAILED{Colors.NC}"
        elif metrics.failures > 0:
            status = f"{Colors.YELLOW}PARTIAL{Colors.NC} ({metrics.successes} ok, {metrics.failures} failed)"
        else:
            status = f"{Colors.YELLOW}NO RUNS{Colors.NC}"
        
        print(f"{Colors.BLUE}‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ{Colors.NC}")
        print(f"{status} | ${metrics.total_cost:.4f} | {metrics.total_iterations} iterations")
        
        # Show current plan state
        final_state = load_state(config)
        if final_state.tasks or final_state.issues:
            print_plan_report(final_state, mode)
        print(f"{Colors.BLUE}‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ{Colors.NC}")


# =============================================================================
# State CLI Commands
# =============================================================================

def cmd_query(config: RalphConfig, subquery: Optional[str] = None, done_only: bool = False):
    """Query current state."""
    state = load_state(config)
    
    if subquery == 'stage':
        print(state.get_stage())
    elif subquery == 'iteration':
        iteration = read_runtime_iteration(config)
        print(iteration if iteration is not None else 0)
    elif subquery == 'next':
        print(json.dumps(state.get_next(), indent=2))
    elif subquery == 'tasks':
        if done_only:
            print(json.dumps({
                "done": [task_to_query_dict(t) for t in state.done],
            }, indent=2))
        else:
            print(json.dumps({
                "pending": [task_to_query_dict(t) for t in state.get_sorted_pending()],
                "done": [task_to_query_dict(t) for t in state.done],
            }, indent=2))
    elif subquery == 'issues':
        print(json.dumps([{"id": i.id, "desc": i.desc} for i in state.issues], indent=2))
    else:
        # Full state with computed fields
        output = state.to_dict()
        output["stage"] = state.get_stage()
        output["next"] = state.get_next()
        # Include currently assigned task if BUILD is in progress
        assigned_task_id = load_current_task(config)
        if assigned_task_id:
            output["current_task"] = assigned_task_id
        print(json.dumps(output, indent=2))


def _add_single_task(config: RalphConfig, state: 'RalphState', task_input, batch_ids: list = None) -> int:
    """Add a single task to state. Returns 0 on success, 1 on failure.
    
    Args:
        config: Ralph configuration
        state: Current state (will be modified in place)
        task_input: Either a dict with task fields or a string (task name or JSON)
        batch_ids: List of task IDs added in current batch (for intra-batch deps)
    
    Note: Does NOT save state - caller must call save_state after.
    """
    batch_ids = batch_ids or []
    
    # Parse input
    if isinstance(task_input, dict):
        d = task_input
        name = d.get("name", "")
        notes = d.get("notes")
        accept = d.get("accept")
        deps = d.get("deps")
        priority = d.get("priority")
        parent = d.get("parent")
        created_from = d.get("created_from")
        custom_id = d.get("id")
        research_data = d.get("research")
    elif isinstance(task_input, str):
        try:
            if task_input.startswith('{'):
                d = json.loads(task_input)
                name = d.get("name", "")
                notes = d.get("notes")
                accept = d.get("accept")
                deps = d.get("deps")
                priority = d.get("priority")
                parent = d.get("parent")
                created_from = d.get("created_from")
                custom_id = d.get("id")
                research_data = d.get("research")
            else:
                name = task_input
                notes = None
                accept = None
                deps = None
                priority = None
                parent = None
                created_from = None
                custom_id = None
                research_data = None
        except json.JSONDecodeError:
            name = task_input
            notes = None
            accept = None
            deps = None
            priority = None
            parent = None
            created_from = None
            custom_id = None
            research_data = None
    else:
        print(f"{Colors.RED}Invalid task input type: {type(task_input)}{Colors.NC}")
        return 1
    
    if not name:
        print(f"{Colors.RED}Task name is required{Colors.NC}")
        return 1
    
    # Validate task notes
    is_valid, error_msg = validate_task_notes(notes)
    if not is_valid:
        print(f"{Colors.RED}ERROR: {error_msg}{Colors.NC}")
        return 1
    
    # Validate acceptance criteria
    is_valid, error_msg = validate_acceptance_criteria(accept)
    if not is_valid:
        print(f"{Colors.RED}ERROR: {error_msg}{Colors.NC}")
        return 1
    
    # Validate/generate task ID
    if custom_id:
        import re
        if not re.match(r'^t-[a-z0-9]{4,10}$', custom_id):
            print(f"{Colors.RED}ERROR: Invalid task ID format: {custom_id}{Colors.NC}")
            return 1
        existing_ids = {t.id for t in state.tasks}
        if custom_id in existing_ids:
            print(f"{Colors.RED}ERROR: Task ID already exists: {custom_id}{Colors.NC}")
            return 1
        task_id = custom_id
    else:
        task_id = _generate_id('t')
    
    # Validate dependencies (include batch_ids for intra-batch deps)
    if deps:
        valid_ids = get_all_valid_task_ids(config, state)
        valid_ids.update(batch_ids)  # Add IDs from current batch
        missing_deps = [d for d in deps if d not in valid_ids]
        if missing_deps:
            print(f"{Colors.RED}ERROR: Dependencies not found: {', '.join(missing_deps)}{Colors.NC}")
            return 1
    
    # Calculate decompose_depth
    decompose_depth = 0
    if parent:
        parent_task = next((t for t in state.tasks if t.id == parent), None)
        if parent_task:
            decompose_depth = parent_task.decompose_depth + 1
            MAX_DECOMPOSE_DEPTH = 3
            if decompose_depth > MAX_DECOMPOSE_DEPTH:
                print(f"{Colors.RED}ERROR: Maximum decomposition depth exceeded{Colors.NC}")
                return 1
    
    # Auto-inherit priority from issue
    if created_from and not priority:
        source_issue = next((i for i in state.issues if i.id == created_from), None)
        if source_issue and source_issue.priority:
            priority = source_issue.priority
    
    task = Task(
        id=task_id,
        name=name,
        spec=state.spec,
        notes=notes,
        accept=accept,
        deps=deps,
        status="p",
        priority=priority,
        parent=parent,
        created_from=created_from,
        decompose_depth=decompose_depth
    )
    state.tasks.append(task)
    print(f"{Colors.GREEN}Task added:{Colors.NC} {task.id} - {name}")
    if deps:
        print(f"  {Colors.DIM}Depends on: {', '.join(deps)}{Colors.NC}")
    return 0


def cmd_task(config: RalphConfig, action: str, desc: Optional[str] = None, arg3: Optional[str] = None):
    """Task mutations: done, add, accept, reject."""
    state = load_state(config)
    
    if action == 'done':
        # Support explicit task ID: ralph task done <task-id>
        task_source = None  # Track how we found the task for output clarity
        if desc:
            task = next((t for t in state.pending if t.id == desc), None)
            if not task:
                print(f"{Colors.RED}Task not found in pending tasks: {desc}{Colors.NC}")
                print(f"  {Colors.DIM}Pending tasks: {', '.join(t.id for t in state.pending)}{Colors.NC}")
                return 1
            task_source = "explicit"
        else:
            # First, check if there's a current task assigned by BUILD stage
            # This prevents the "wrong task marked done" bug when task ordering changes
            assigned_task_id = load_current_task(config)
            if assigned_task_id:
                task = next((t for t in state.pending if t.id == assigned_task_id), None)
                if task:
                    # Found the assigned task - use it
                    task_source = "assigned"
                else:
                    # Assigned task no longer pending (weird state) - fall back to get_next_task
                    print(f"{Colors.YELLOW}Warning: Assigned task {assigned_task_id} not in pending, using next task{Colors.NC}")
                    task = state.get_next_task()
                    task_source = "fallback"
            else:
                # No assigned task - fall back to get_next_task()
                # This respects priority and dependency ordering
                task = state.get_next_task()
                task_source = "next"
            
            if not task:
                print(f"{Colors.YELLOW}No pending tasks{Colors.NC}")
                return 1
        
        # Check if any code changes were made (not just plan.jsonl)
        result = subprocess.run(
            ['git', 'diff', '--name-only', 'HEAD'],
            cwd=config.repo_root, capture_output=True, text=True
        )
        changed_files = [f for f in result.stdout.strip().split('\n') if f and f != 'ralph/plan.jsonl']
        
        # Also check staged changes
        result_staged = subprocess.run(
            ['git', 'diff', '--name-only', '--cached'],
            cwd=config.repo_root, capture_output=True, text=True
        )
        staged_files = [f for f in result_staged.stdout.strip().split('\n') if f and f != 'ralph/plan.jsonl']
        
        # Also check untracked files (new files created but not yet staged)
        result_untracked = subprocess.run(
            ['git', 'ls-files', '--others', '--exclude-standard'],
            cwd=config.repo_root, capture_output=True, text=True
        )
        untracked_files = [f for f in result_untracked.stdout.strip().split('\n') 
                          if f and not f.startswith('ralph/plan') and not f.endswith('.log')]
        
        all_changed = set(changed_files + staged_files + untracked_files)
        
        if not all_changed:
            print(f"{Colors.RED}ERROR: No code changes detected!{Colors.NC}")
            print(f"  Task: {task.name}")
            print(f"  {Colors.YELLOW}You must make code changes before marking a task done.{Colors.NC}")
            print(f"  {Colors.DIM}If the task is already complete, use 'ralph task accept {task.id}' after verification.{Colors.NC}")
            return 1
        
        task.status = "d"
        task.done_at = get_current_commit(config)  # Record current HEAD before committing
        
        # Stage all tracked file changes (code changes made by AI)
        subprocess.run(['git', 'add', '-u'], cwd=config.repo_root, capture_output=True)
        
        # Also stage any untracked files that were detected as changes
        if untracked_files:
            for f in untracked_files:
                subprocess.run(['git', 'add', f], cwd=config.repo_root, capture_output=True)
        
        # Save plan state and stage it
        save_state(config, state)
        subprocess.run(['git', 'add', str(config.plan_file)], cwd=config.repo_root, capture_output=True)
        
        # Commit all staged changes (code + plan) together
        commit_msg = f"ralph: task done - {task.name[:50]}"
        subprocess.run(['git', 'commit', '-m', commit_msg], cwd=config.repo_root, capture_output=True)
        
        # Clear the current task lock file since task is now done
        clear_current_task(config)
        
        print(f"{Colors.GREEN}Task done:{Colors.NC} {task.id} - {task.name}")
        # Show how the task was selected for transparency
        if task_source == "assigned":
            print(f"  {Colors.DIM}(from BUILD stage assignment){Colors.NC}")
        elif task_source == "explicit":
            print(f"  {Colors.DIM}(explicit task ID){Colors.NC}")
        elif task_source == "fallback":
            print(f"  {Colors.DIM}(fallback - assigned task not found){Colors.NC}")
        # Don't print anything for "next" - it's the default behavior
        print(f"  {Colors.DIM}Changed files: {', '.join(sorted(all_changed)[:5])}{Colors.NC}")
        if len(all_changed) > 5:
            print(f"  {Colors.DIM}  ... and {len(all_changed) - 5} more{Colors.NC}")
        print(json.dumps(state.to_dict(), indent=2))
        
    elif action == 'add':
        if not desc:
            print(f"{Colors.RED}Usage: ralph task add \"name\" or ralph task add '{{\"name\": ..., \"notes\": ..., \"accept\": ...}}'{Colors.NC}")
            print(f"{Colors.DIM}Batch: ralph task add '[{{...}}, {{...}}]'{Colors.NC}")
            return 1
        if not state.spec:
            print(f"{Colors.RED}No spec set. Run 'ralph set-spec <file>' first.{Colors.NC}")
            return 1
        
        # Check for batch add (JSON array)
        if desc.strip().startswith('['):
            try:
                tasks_data = json.loads(desc)
                if not isinstance(tasks_data, list):
                    print(f"{Colors.RED}Expected JSON array for batch add{Colors.NC}")
                    return 1
                
                added_count = 0
                failed_count = 0
                added_ids = []  # Track IDs for dependency resolution within batch
                
                for i, task_dict in enumerate(tasks_data):
                    if not isinstance(task_dict, dict):
                        print(f"{Colors.RED}Item {i}: Expected object, got {type(task_dict).__name__}{Colors.NC}")
                        failed_count += 1
                        continue
                    
                    # Add previously added IDs to valid deps for intra-batch dependencies
                    result = _add_single_task(config, state, task_dict, batch_ids=added_ids)
                    if result == 0:
                        added_count += 1
                        # Extract the ID that was just added (last task in state)
                        if state.tasks:
                            added_ids.append(state.tasks[-1].id)
                    else:
                        failed_count += 1
                
                # Save once after all tasks added
                if added_count > 0:
                    save_state(config, state)
                
                print(f"{Colors.GREEN}Batch complete:{Colors.NC} {added_count} added, {failed_count} failed")
                return 0 if failed_count == 0 else 1
                
            except json.JSONDecodeError as e:
                print(f"{Colors.RED}Invalid JSON array: {e}{Colors.NC}")
                return 1
        
        # Single task add
        result = _add_single_task(config, state, desc)
        if result == 0:
            save_state(config, state)
        return result
        
    elif action == 'accept':
        done = state.done
        if not done:
            print(f"{Colors.YELLOW}No done tasks to accept{Colors.NC}")
            return 1
        
        if desc:
            task_id = desc
            task = next((t for t in done if t.id == task_id), None)
            if not task:
                print(f"{Colors.RED}Task not found in done tasks: {task_id}{Colors.NC}")
                print(f"  {Colors.DIM}Done tasks: {', '.join(t.id for t in done)}{Colors.NC}")
                return 1
            # Create accept tombstone and remove task
            # Tombstone preserves task ID in history for dependency validation
            tombstone = create_tombstone(config, task, "accept", reason=task.accept or "")
            state.tombstones.append(tombstone)
            state.tasks = [t for t in state.tasks if t.id != task_id]
            save_state(config, state)
            print(f"{Colors.GREEN}Accepted task:{Colors.NC} {task_id} - {task.name}")
        else:
            count = len(done)
            # Create accept tombstones for all done tasks
            for task in done:
                tombstone = create_tombstone(config, task, "accept", reason=task.accept or "")
                state.tombstones.append(tombstone)
            done_ids = {t.id for t in done}
            state.tasks = [t for t in state.tasks if t.id not in done_ids]
            save_state(config, state)
            print(f"{Colors.GREEN}Accepted {count} tasks{Colors.NC}")
        
    elif action == 'reject':
        if not desc or not arg3:
            print(f"{Colors.RED}Usage: ralph task reject <task-id> \"reason\"{Colors.NC}")
            return 1
        task_id = desc
        reason = arg3
        done = state.done
        if not done:
            print(f"{Colors.YELLOW}No done tasks to reject{Colors.NC}")
            return 1
        task = next((t for t in done if t.id == task_id), None)
        if not task:
            print(f"{Colors.RED}Task not found in done tasks: {task_id}{Colors.NC}")
            print(f"  {Colors.DIM}Done tasks: {', '.join(t.id for t in done)}{Colors.NC}")
            return 1
        tombstone = create_tombstone(config, task, "reject", reason=reason)
        state.tombstones.append(tombstone)
        task.status = "p"
        task.done_at = None
        task.reject_reason = reason  # Store on task so BUILD knows why it was rejected
        save_state(config, state, f"ralph: task reject - {task.name[:50]}")
        print(f"{Colors.YELLOW}Task rejected:{Colors.NC} {task.name}")
        print(f"  {Colors.DIM}Reason: {reason}{Colors.NC}")
        print(json.dumps(state.to_dict(), indent=2))
    
    elif action == 'delete':
        if not desc:
            print(f"{Colors.RED}Usage: ralph task delete <task-id>{Colors.NC}")
            return 1
        task_id = desc
        task = next((t for t in state.tasks if t.id == task_id), None)
        if not task:
            print(f"{Colors.RED}Task not found: {task_id}{Colors.NC}")
            return 1
        task_name = task.name
        state.tasks = [t for t in state.tasks if t.id != task_id]
        save_state(config, state)
        print(f"{Colors.GREEN}Task deleted:{Colors.NC} {task_id} - {task_name}")
    
    elif action == 'prioritize':
        pending = state.pending
        if not pending:
            print(json.dumps({"prioritized": 0, "high": 0, "medium": 0, "low": 0}))
            return 0
        
        task_ids = {task.id for task in pending}
        
        dependents: dict[str, list[str]] = {task.id: [] for task in pending}
        for task in pending:
            if task.deps:
                for dep_id in task.deps:
                    if dep_id in dependents:
                        dependents[dep_id].append(task.id)
        
        blocking_count = {tid: len(deps) for tid, deps in dependents.items()}
        
        critical_path_length: dict[str, int] = {}
        
        def compute_critical_path(task_id: str, visited: set[str]) -> int:
            if task_id in critical_path_length:
                return critical_path_length[task_id]
            if task_id in visited:
                return 0
            visited.add(task_id)
            
            deps = dependents.get(task_id, [])
            if not deps:
                critical_path_length[task_id] = 0
                return 0
            
            max_path = 0
            for dep_id in deps:
                if dep_id in task_ids:
                    path_len = 1 + compute_critical_path(dep_id, visited)
                    max_path = max(max_path, path_len)
            
            critical_path_length[task_id] = max_path
            return max_path
        
        for task in pending:
            compute_critical_path(task.id, set())
        
        task_by_id = {task.id: task for task in pending}
        depth_from_root: dict[str, int] = {}
        
        def compute_depth(task_id: str, visited: set[str]) -> int:
            if task_id in depth_from_root:
                return depth_from_root[task_id]
            if task_id in visited or task_id not in task_by_id:
                return 0
            visited.add(task_id)
            
            task = task_by_id[task_id]
            if not task.deps:
                depth_from_root[task_id] = 0
                return 0
            
            max_depth = 0
            for dep_id in task.deps:
                if dep_id in task_ids:
                    d = 1 + compute_depth(dep_id, visited)
                    max_depth = max(max_depth, d)
            
            depth_from_root[task_id] = max_depth
            return max_depth
        
        for task in pending:
            compute_depth(task.id, set())
        
        total_chain_length = {tid: depth_from_root.get(tid, 0) + critical_path_length.get(tid, 0) 
                              for tid in task_ids}
        
        def estimate_complexity(task: Task) -> str:
            text = (task.name + " " + (task.notes or "")).lower()
            large_indicators = ["refactor", "redesign", "rewrite", "implement", "overhaul", "migrate", "architecture"]
            small_indicators = ["rename", "fix typo", "update", "add flag", "add field", "change", "alias", "tweak"]
            for ind in large_indicators:
                if ind in text:
                    return "large"
            for ind in small_indicators:
                if ind in text:
                    return "small"
            return "medium"
        
        def is_docs_cleanup(task: Task) -> bool:
            text = (task.name + " " + (task.notes or "")).lower()
            indicators = ["doc", "readme", "comment", "cleanup", "clean up", "lint", "format", "typo"]
            for ind in indicators:
                if ind in text:
                    return True
            return False
        
        counts = {"high": 0, "medium": 0, "low": 0}
        prioritized = 0
        
        for task in pending:
            if task.priority:
                counts[task.priority] += 1
                continue
            
            complexity = estimate_complexity(task)
            blocks = blocking_count[task.id]
            path_len = critical_path_length.get(task.id, 0)
            chain_len = total_chain_length.get(task.id, 0)
            
            if is_docs_cleanup(task):
                task.priority = "low"
            elif path_len >= 2:
                task.priority = "high"
            elif chain_len >= 2 and blocks >= 1:
                task.priority = "high"
            elif complexity == "small" and blocks >= 2:
                task.priority = "high"
            elif blocks >= 3:
                task.priority = "high"
            elif complexity == "small" and blocks >= 1:
                task.priority = "high"
            elif complexity == "large":
                task.priority = "medium"
            else:
                task.priority = "medium"
            
            counts[task.priority] += 1
            prioritized += 1
        
        save_state(config, state)
        print(json.dumps({"prioritized": prioritized, "high": counts["high"], "medium": counts["medium"], "low": counts["low"]}))
        
    else:
        print(f"{Colors.RED}Unknown task action: {action}{Colors.NC}")
        print("Usage: ralph task [done|add|accept|reject|delete|prioritize]")
        return 1


def cmd_issue(config: RalphConfig, action: str, desc: Optional[str] = None):
    """Issue mutations: done, add."""
    state = load_state(config)
    
    if action == 'done':
        if not state.issues:
            print(f"{Colors.YELLOW}No issues{Colors.NC}")
            return 1
        issue = state.issues.pop(0)
        save_state(config, state)  # No auto-commit, issues are transient
        print(f"{Colors.GREEN}Issue resolved:{Colors.NC} {issue.desc}")
    
    elif action == 'done-all':
        if not state.issues:
            print(f"{Colors.YELLOW}No issues{Colors.NC}")
            return 1
        count = len(state.issues)
        state.issues = []
        save_state(config, state)
        print(f"{Colors.GREEN}All issues resolved:{Colors.NC} {count} issues cleared")
    
    elif action == 'done-ids':
        # Batch resolve specific issues by ID: ralph issue done-ids i-abc1 i-def2 i-ghi3
        if not desc:
            print(f"{Colors.RED}Usage: ralph issue done-ids <id1> <id2> ...{Colors.NC}")
            return 1
        ids_to_remove = set(desc.split())
        if not state.issues:
            print(f"{Colors.YELLOW}No issues{Colors.NC}")
            return 1
        original_count = len(state.issues)
        state.issues = [i for i in state.issues if i.id not in ids_to_remove]
        removed_count = original_count - len(state.issues)
        if removed_count > 0:
            save_state(config, state)
            print(f"{Colors.GREEN}Issues resolved:{Colors.NC} {removed_count} issues cleared")
        else:
            print(f"{Colors.YELLOW}No matching issue IDs found{Colors.NC}")
            return 1
        
    elif action == 'add':
        if not desc:
            print(f"{Colors.RED}Usage: ralph issue add \"description\"{Colors.NC}")
            return 1
        if not state.spec:
            print(f"{Colors.RED}No spec set. Run 'ralph set-spec <file>' first.{Colors.NC}")
            return 1
        issue = Issue(id=_generate_id('i'), desc=desc, spec=state.spec)
        state.issues.append(issue)
        save_state(config, state)  # No auto-commit, issues are transient
        print(f"{Colors.GREEN}Issue added:{Colors.NC} {issue.id} - {desc}")
        
    else:
        print(f"{Colors.RED}Unknown issue action: {action}{Colors.NC}")
        print("Usage: ralph issue [done|done-all|done-ids|add]")
        return 1


def cmd_set_spec(config: RalphConfig, spec_file: str):
    """Set current spec."""
    # Validate spec exists - handle full path, relative path, or just filename
    spec_path = Path(spec_file)
    if spec_path.is_absolute() or spec_path.exists():
        # Full or relative path provided
        if not spec_path.exists():
            print(f"{Colors.RED}Spec not found: {spec_file}{Colors.NC}")
            return 1
    else:
        # Just filename - look in specs_dir
        spec_path = config.specs_dir / spec_file
        if not spec_path.exists():
            if not spec_file.endswith('.md'):
                spec_path = config.specs_dir / f"{spec_file}.md"
            if not spec_path.exists():
                print(f"{Colors.RED}Spec not found: {spec_file}{Colors.NC}")
                return 1
    
    state = load_state(config)
    
    # Only clear tasks/tombstones when actually switching to a different spec
    if state.spec != spec_path.name:
        state.spec = spec_path.name
        # Clear tasks when switching specs
        state.tasks = []
        # Clear tombstones - they served their audit purpose for the previous spec
        state.tombstones = []
        # Keep issues - they may be relevant across specs
        save_state(config, state, f"ralph: set spec {spec_path.name}")
        print(f"{Colors.GREEN}Spec set:{Colors.NC} {spec_path.name}")
    else:
        # Same spec - nothing to do
        pass


def cmd_log(config: RalphConfig, show_all: bool = False, spec_filter: Optional[str] = None, 
            branch_filter: Optional[str] = None, since: Optional[str] = None):
    """Query git history for task lifecycle data."""
    cmd = ['git', 'log', '--format=%H|%aI|%an <%ae>|%s', '--reverse', '--follow', '--', 'ralph/plan.jsonl']
    
    if since:
        cmd.insert(2, f'--since={since}')
    if branch_filter:
        cmd.insert(2, branch_filter)
    
    result = subprocess.run(cmd, capture_output=True, text=True, cwd=config.repo_root)
    
    if result.returncode != 0 or not result.stdout.strip():
        print(json.dumps({"tasks": []}, indent=2))
        return
    
    tasks: Dict[str, dict] = {}
    tombstones: Dict[str, dict] = {}  # task_id -> {commit, date, reason}
    prev_task_ids: set = set()
    
    for line in result.stdout.strip().split('\n'):
        if not line or '|' not in line:
            continue
        parts = line.split('|', 3)
        if len(parts) != 4:
            continue
        
        full_commit = parts[0]
        commit = full_commit[:7]
        date = parts[1].strip()
        author = parts[2].strip()
        
        plan_result = subprocess.run(
            ['git', 'show', f'{full_commit}:ralph/plan.jsonl'],
            capture_output=True, text=True, cwd=config.repo_root
        )
        
        if plan_result.returncode != 0:
            continue
        
        current_tasks: Dict[str, dict] = {}
        for plan_line in plan_result.stdout.strip().split('\n'):
            if not plan_line:
                continue
            try:
                entry = json.loads(plan_line)
                if entry.get('t') == 'task':
                    task_id = entry.get('id')
                    if task_id:
                        current_tasks[task_id] = entry
                elif entry.get('t') == 'reject':
                    task_id = entry.get('id')
                    if task_id and task_id not in tombstones:
                        tombstones[task_id] = {
                            "commit": commit,
                            "date": date,
                            "reason": entry.get("reason", "")
                        }
            except json.JSONDecodeError:
                continue
        
        current_task_ids = set(current_tasks.keys())
        
        for task_id, task_data in current_tasks.items():
            if task_id not in tasks:
                branch_result = subprocess.run(
                    ['git', 'branch', '--contains', full_commit, '--format=%(refname:short)'],
                    capture_output=True, text=True, cwd=config.repo_root
                )
                branch = branch_result.stdout.strip().split('\n')[0] if branch_result.returncode == 0 else None
                
                tasks[task_id] = {
                    "id": task_id,
                    "desc": task_data.get("name", ""),
                    "notes": task_data.get("notes"),
                    "accept": task_data.get("accept"),
                    "deps": task_data.get("deps"),
                    "spec": task_data.get("spec"),
                    "branch": branch,
                    "author": author,
                    "created": {"commit": commit, "date": date},
                    "done": None,
                    "accepted": None,
                    "rejected": None
                }
            
            if task_data.get("s") == "d" and task_data.get("done_at"):
                if tasks[task_id]["done"] is None:
                    tasks[task_id]["done"] = {"commit": task_data["done_at"][:7], "date": date}
        
        removed_ids = prev_task_ids - current_task_ids
        for task_id in removed_ids:
            if task_id in tasks and tasks[task_id]["accepted"] is None:
                tasks[task_id]["accepted"] = {"commit": commit, "date": date}
        
        prev_task_ids = current_task_ids
    
    for task_id, tombstone_data in tombstones.items():
        if task_id in tasks:
            tasks[task_id]["rejected"] = tombstone_data
    
    task_list = list(tasks.values())
    
    for task in task_list:
        if task.get("accepted"):
            task["status"] = "accepted"
        elif task.get("rejected"):
            task["status"] = "rejected"
        else:
            task["status"] = "pending"
    
    if spec_filter:
        task_list = [t for t in task_list if t.get("spec") == spec_filter]
    
    if not show_all:
        current_state = load_state(config)
        current_ids = {t.id for t in current_state.tasks}
        task_list = [t for t in task_list if t["id"] in current_ids]
    
    print(json.dumps({"tasks": task_list}, indent=2))


def main():
    parser = argparse.ArgumentParser(
        description='Ralph Wiggum - Autonomous AI Development Loop',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog='''
Examples:
  ralph init                    Initialize in current repo
  ralph plan spec.md            Plan tasks for a specific spec
  ralph construct               Construct mode, unlimited (Ctrl+C to stop)
  ralph construct 10            Construct mode, max 10 iterations
  ralph config                  Show global config (model, timeouts, etc.)
  ralph query                   Show current state as JSON
  ralph query stage             Show current stage (PLAN/BUILD/VERIFY/etc)
  ralph query iteration         Show current iteration number
  ralph task done               Mark first pending task as done
  ralph task add "description"  Add a new task
  ralph task accept             Accept all done tasks (after verification)
  ralph issue add "description" Add a discovered issue
  ralph issue done              Resolve first issue
  ralph set-spec spec.md        Set current spec
  ralph log                     Show state change history
  ralph watch                   Live progress dashboard
  ralph stream                  Pipe opencode JSON for pretty output
        '''
    )
    
    parser.add_argument('command', nargs='?', default='construct',
                       help='Command: init, plan, construct, config, query, task, issue, set-spec, log, status, watch, stream (build is alias for construct)')
    parser.add_argument('arg', nargs='?', default=None,
                       help='Subcommand or argument')
    parser.add_argument('arg2', nargs='?', default=None,
                       help='Additional argument (e.g., task description)')
    parser.add_argument('arg3', nargs='?', default=None,
                       help='Third argument (e.g., reject reason)')
    # Get defaults from global config
    gcfg = get_global_config()
    parser.add_argument('--max-cost', type=float, default=0,
                       help='Stop when cost exceeds $N')
    parser.add_argument('--max-failures', type=int, default=gcfg.max_failures,
                       help=f'Circuit breaker: stop after N consecutive failures (default: {gcfg.max_failures})')
    parser.add_argument('--completion-promise', type=str, default='',
                       help='Stop when output contains this text')
    parser.add_argument('--timeout', type=int, default=gcfg.stage_timeout_ms,
                       help=f'Kill stage after N milliseconds (default: {gcfg.stage_timeout_ms}ms)')
    parser.add_argument('--context-limit', type=int, default=gcfg.context_window,
                       help=f'Context window size in tokens (default: {gcfg.context_window})')
    parser.add_argument('--no-ui', action='store_true',
                       help='Disable interactive dashboard, show streaming output')
    parser.add_argument('--all', action='store_true',
                       help='For log: show all history')
    parser.add_argument('--done', action='store_true',
                       help='For query tasks: show only done tasks')
    parser.add_argument('--spec', type=str, default=None,
                       help='For log: filter by spec')
    parser.add_argument('--branch', type=str, default=None,
                       help='For log: filter by branch')
    parser.add_argument('--since', type=str, default=None,
                        help='For log: filter since date/commit')
    parser.add_argument('--max-iterations', type=int, default=None,
                         help='For construct: max iterations (0 = unlimited)')
    parser.add_argument('--profile', '-p', type=str, default=None,
                         help='Cost profile: budget, balanced, hybrid, cost_smart, quality (or set RALPH_PROFILE)')

    args = parser.parse_args()

    # Handle numeric first arg (e.g., "ralph 10")
    if args.command and args.command.isdigit():
        args.arg = args.command
        args.command = 'construct'

    # Parse iterations: --max-iterations flag takes precedence, then positional arg
    iterations = 0
    if args.max_iterations is not None:
        iterations = args.max_iterations
    elif args.arg and args.arg.isdigit():
        iterations = int(args.arg)

    # Stream command doesn't need a repo
    if args.command == 'stream':
        cmd_stream()
        return

    # Find repo
    repo_root = find_repo_root()
    if not repo_root:
        print(f"{Colors.RED}Error: Not in a git repository{Colors.NC}")
        sys.exit(1)

    config = RalphConfig.from_repo(repo_root)

    # Dispatch command
    if args.command == 'init':
        cmd_init(config)
    elif args.command == 'config':
        cmd_config()
    elif args.command == 'status':
        cmd_status(config)
    elif args.command == 'validate':
        cmd_validate(config)
    elif args.command == 'compact':
        cmd_compact(config)
    elif args.command == 'watch':
        cmd_watch(config)
    elif args.command == 'query':
        cmd_query(config, args.arg, done_only=args.done)
    elif args.command == 'task':
        if not args.arg:
            print(f"{Colors.RED}Usage: ralph task [done|add|accept|reject]{Colors.NC}")
            sys.exit(1)
        cmd_task(config, args.arg, args.arg2, args.arg3)
    elif args.command == 'issue':
        if not args.arg:
            print(f"{Colors.RED}Usage: ralph issue [done|add]{Colors.NC}")
            sys.exit(1)
        cmd_issue(config, args.arg, args.arg2)
    elif args.command == 'set-spec':
        if not args.arg:
            print(f"{Colors.RED}Usage: ralph set-spec <spec.md>{Colors.NC}")
            sys.exit(1)
        cmd_set_spec(config, args.arg)
    elif args.command == 'log':
        cmd_log(config, show_all=args.all, spec_filter=args.spec, 
                branch_filter=args.branch, since=args.since)
    elif args.command == 'plan':
        # Plan requires a spec file
        spec_file = args.arg
        if not spec_file:
            # List available specs
            specs = list(config.specs_dir.glob('*.md')) if config.specs_dir.exists() else []
            if not specs:
                print(f"{Colors.RED}No specs found in ralph/specs/{Colors.NC}")
                print("Create a spec file first, e.g.: ralph/specs/my-feature.md")
                sys.exit(1)
            print(f"{Colors.YELLOW}Usage: ralph plan <spec.md>{Colors.NC}")
            print()
            print("Available specs:")
            for spec in sorted(specs):
                print(f"  {spec.name}")
            sys.exit(1)
        
        # Validate spec exists - handle full path, relative path, or just filename
        spec_path = Path(spec_file)
        if spec_path.is_absolute() or spec_path.exists():
            # Full or relative path provided
            if not spec_path.exists():
                print(f"{Colors.RED}Spec not found: {spec_file}{Colors.NC}")
                sys.exit(1)
        else:
            # Just filename - look in specs_dir
            spec_path = config.specs_dir / spec_file
            if not spec_path.exists():
                # Try without .md extension
                if not spec_file.endswith('.md'):
                    spec_path = config.specs_dir / f"{spec_file}.md"
                if not spec_path.exists():
                    print(f"{Colors.RED}Spec not found: {spec_file}{Colors.NC}")
                    print(f"Expected at: {config.specs_dir / spec_file}")
                    sys.exit(1)
        
        # Check for unfinished tasks before switching specs
        if not check_unfinished_tasks(config, spec_path.name):
            sys.exit(0)
        
        # Set the spec in state before running plan
        cmd_set_spec(config, spec_path.name)
        
        ensure_profile_selected(args.profile)
        
        # Plan mode needs more time to analyze spec and create tasks - minimum 15 min
        # Also allow multiple iterations for complex specs (default 5, can be overridden with --max-iter)
        plan_timeout = max(args.timeout, 900000)
        plan_max_iter = args.max_iterations if args.max_iterations and args.max_iterations > 0 else 5
        cmd_run(config, 'plan', plan_max_iter, args.max_cost, args.max_failures, 
                args.completion_promise, args.no_ui, spec_file=spec_path.name,
                stage_timeout_ms=plan_timeout, context_limit=args.context_limit)
    elif args.command in ('construct', 'build', ''):
        # Note: 'build' is supported as an alias for backward compatibility
        
        # Profile selection first - before any agent work
        ensure_profile_selected(args.profile)
        
        # Check if a spec file was provided as argument
        spec_arg = args.arg
        if spec_arg and not spec_arg.isdigit():
            # Looks like a spec file argument - validate and switch to it
            spec_path = Path(spec_arg)
            if spec_path.is_absolute() or spec_path.exists():
                if not spec_path.exists():
                    print(f"{Colors.RED}Spec not found: {spec_arg}{Colors.NC}")
                    sys.exit(1)
            else:
                spec_path = config.specs_dir / spec_arg
                if not spec_path.exists():
                    if not spec_arg.endswith('.md'):
                        spec_path = config.specs_dir / f"{spec_arg}.md"
                    if not spec_path.exists():
                        print(f"{Colors.RED}Spec not found: {spec_arg}{Colors.NC}")
                        print(f"Expected at: {config.specs_dir / spec_arg}")
                        sys.exit(1)
            
            # Check for unfinished tasks before switching specs
            if not check_unfinished_tasks(config, spec_path.name):
                sys.exit(0)
            
            # Load current state to check if this spec has tasks
            state = load_state(config)
            
            # Check if we're switching specs or using current spec
            if state.spec != spec_path.name:
                # Switching to a different spec - set it (this clears tasks)
                cmd_set_spec(config, spec_path.name)
                state = load_state(config)  # Reload after set
            
            # Check if there are any tasks for this spec
            if not state.tasks:
                print(f"{Colors.YELLOW}No tasks found for spec: {spec_path.name}{Colors.NC}")
                print(f"Auto-running plan to generate tasks...")
                print()
                
                # Run plan mode first to generate tasks
                result = cmd_run(config, 'plan', 1, args.max_cost, args.max_failures, 
                        args.completion_promise, args.no_ui, spec_file=spec_path.name,
                        stage_timeout_ms=args.timeout, context_limit=args.context_limit)
                
                if result != 0:
                    print(f"{Colors.RED}Plan failed. Cannot proceed with construct.{Colors.NC}")
                    sys.exit(1)
                
                # Reload state to get the newly created tasks
                state = load_state(config)
                if not state.tasks:
                    print(f"{Colors.RED}Plan completed but no tasks were created.{Colors.NC}")
                    sys.exit(1)
                
                print()
                print(f"{Colors.GREEN}Plan complete. Starting construct mode...{Colors.NC}")
                print()
        
        # Ensure plan.jsonl is committed before starting construct mode
        if has_uncommitted_plan(config):
            print(f"{Colors.YELLOW}plan.jsonl has uncommitted changes.{Colors.NC}")
            try:
                response = input(f"Commit now? [Y/n] ").strip().lower()
                if response in ('', 'y', 'yes'):
                    subprocess.run(['git', 'add', str(config.plan_file)], 
                                  cwd=config.repo_root, check=True)
                    subprocess.run(['git', 'commit', '-m', 'ralph: update plan'],
                                  cwd=config.repo_root, check=True)
                    print(f"{Colors.GREEN}Committed.{Colors.NC}")
                else:
                    print(f"{Colors.RED}Aborted.{Colors.NC}")
                    sys.exit(1)
            except KeyboardInterrupt:
                print(f"\n{Colors.RED}Aborted.{Colors.NC}")
                sys.exit(1)
        
        # Use the new state machine for construct mode
        cmd_construct(config, iterations, args.max_cost, args.max_failures, 
                      args.completion_promise, args.no_ui,
                      stage_timeout_ms=args.timeout, context_limit=args.context_limit)
    elif args.command == 'help':
        parser.print_help()
    else:
        print(f"{Colors.RED}Unknown command: {args.command}{Colors.NC}")
        parser.print_help()
        sys.exit(1)


if __name__ == '__main__':
    main()
