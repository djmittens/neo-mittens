#!/usr/bin/env python3
"""
Ralph Wiggum - Autonomous AI Development Loop
https://ghuntley.com/ralph/

Usage: ralph [command] [options]
  ralph              - Construct mode, unlimited iterations
  ralph 10           - Construct mode, max 10 iterations
  ralph plan         - Plan mode, generate implementation plan
  ralph init         - Initialize ralph in current repo
  ralph status       - Show current status
  ralph watch        - Live dashboard with cost tracking

Options:
  --max-cost N             Stop when cumulative cost exceeds $N
  --max-failures N         Circuit breaker: stop after N consecutive failures (default: 3)
  --timeout N              Kill iteration after N seconds (default: 900)
  --context-limit N        Context window size in tokens (default: 200000)
  --completion-promise T   Stop when output contains TEXT

Safety Features:
  - Iterations are killed if they exceed the timeout (prevents stuck agents)
  - Iterations are killed if context usage exceeds 80% (prevents context overflow)
  - A warning is shown when context usage exceeds 50%
  - After a kill, the next iteration receives guidance to break down the problem
"""

import argparse
import io
import json
import os
import re
import select
import stat
import subprocess
import sys
import threading
import time
from collections import deque
from contextlib import redirect_stdout
from dataclasses import dataclass, field
from datetime import datetime
from pathlib import Path
from typing import Optional

# Textual TUI framework (lazy import to avoid startup penalty for non-TUI commands)
_textual_available = None
def _check_textual():
    global _textual_available
    if _textual_available is None:
        try:
            import textual
            _textual_available = True
        except ImportError:
            _textual_available = False
    return _textual_available


# Colors
class Colors:
    RED = '\033[0;31m'
    GREEN = '\033[0;32m'
    YELLOW = '\033[1;33m'
    BLUE = '\033[0;34m'
    MAGENTA = '\033[0;35m'
    CYAN = '\033[0;36m'
    WHITE = '\033[0;37m'
    NC = '\033[0m'  # No Color
    
    # Extended colors for Ralph ASCII art
    BRIGHT_YELLOW = '\033[93m'
    BRIGHT_RED = '\033[91m'
    BRIGHT_WHITE = '\033[97m'
    BRIGHT_BLUE = '\033[94m'
    BRIGHT_MAGENTA = '\033[95m'
    DIM = '\033[2m'
    PINK = '\033[38;5;218m'
    SKIN = '\033[38;5;223m'
    HAIR = '\033[38;5;220m'
    SHIRT_BLUE = '\033[38;5;39m'
    SHIRT_DARK = '\033[38;5;25m'


# =============================================================================
# Context and Timeout Limits
# =============================================================================
# Context window size for Claude models (in tokens)
DEFAULT_CONTEXT_WINDOW = 200_000

# Soft limit: warn when context usage exceeds this percentage
CONTEXT_SOFT_LIMIT_PCT = 70

# Compact limit: attempt compaction when context usage exceeds this percentage
CONTEXT_COMPACT_LIMIT_PCT = 85

# Hard limit: kill iteration when context usage exceeds this percentage  
CONTEXT_HARD_LIMIT_PCT = 95

# Default iteration timeout in seconds (15 minutes)
DEFAULT_ITERATION_TIMEOUT = 900


# =============================================================================
# Ralph Wiggum ASCII Art Options
# =============================================================================
# Multiple art styles available. Set RALPH_ART_STYLE environment variable to choose:
#   - "braille" (default): Braille dot art with colored regions (11 lines)
#   - "braille_full": Full-body braille art (15 lines, includes legs)
#   - "blocks": Block art using ░▒▓█ characters (11 lines)
#   - "minimal": Simple/minimal text art (5 lines)
#   - "none": No art displayed

def _colorize_art(raw_lines, color_map_list, color_codes):
    """Build colored art lines from raw art and color map."""
    result = []
    for line_idx, line in enumerate(raw_lines):
        if line_idx >= len(color_map_list):
            result.append(line + Colors.NC)
            continue
        colored_line = ""
        colors = color_map_list[line_idx]
        for start, end, color_name in colors:
            segment = line[start:end]
            colored_line += f"{color_codes.get(color_name, '')}{segment}"
        colored_line += Colors.NC
        result.append(colored_line)
    return result

# Color code mapping
_COLOR_CODES = {
    'HAIR': Colors.HAIR,
    'SKIN': Colors.SKIN,
    'SHIRT_BLUE': Colors.SHIRT_BLUE,
    'NC': Colors.NC,
}

# -----------------------------------------------------------------------------
# Style 1: Braille dot art (default) - compact upper body
# -----------------------------------------------------------------------------
_BRAILLE_RAW = [
    "⠀⠀⠀⠀⠀⠀⣀⣤⣶⡶⢛⠟⡿⠻⢻⢿⢶⢦⣄⡀⠀⠀⠀⠀⠀⠀",
    "⠀⠀⠀⢀⣠⡾⡫⢊⠌⡐⢡⠊⢰⠁⡎⠘⡄⢢⠙⡛⡷⢤⡀⠀⠀⠀",
    "⠀⠀⢠⢪⢋⡞⢠⠃⡜⠀⠎⠀⠉⠀⠃⠀⠃⠀⠃⠙⠘⠊⢻⠦⠀⠀",
    "⠀⠀⢇⡇⡜⠀⠜⠀⠁⠀⢀⠔⠉⠉⠑⠄⠀⠀⡰⠊⠉⠑⡄⡇⠀⠀",
    "⠀⠀⡸⠧⠄⠀⠀⠀⠀⠀⠘⡀⠾⠀⠀⣸⠀⠀⢧⠀⠛⠀⠌⡇⠀⠀",
    "⠀⠘⡇⠀⠀⠀⠀⠀⠀⠀⠀⠙⠒⠒⠚⠁⠈⠉⠲⡍⠒⠈⠀⡇⠀⠀",
    "⠀⠀⠈⠲⣆⠀⠀⠀⠀⠀⠀⠀⠀⣠⠖⠉⡹⠤⠶⠁⠀⠀⠀⠈⢦⠀",
    "⠀⠀⠀⠀⠈⣦⡀⠀⠀⠀⠀⠧⣴⠁⠀⠘⠓⢲⣄⣀⣀⣀⡤⠔⠃⠀",
    "⠀⠀⠀⠀⣜⠀⠈⠓⠦⢄⣀⣀⣸⠀⠀⠀⠀⠁⢈⢇⣼⡁⠀⠀⠀⠀",
    "⠀⠀⢠⠒⠛⠲⣄⠀⠀⠀⣠⠏⠀⠉⠲⣤⠀⢸⠋⢻⣤⡛⣄⠀⠀⠀",
    "⠀⠀⢡⠀⠀⠀⠀⠉⢲⠾⠁⠀⠀⠀⠀⠈⢳⡾⣤⠟⠁⠹⣿⢆⠀⠀",
]
_BRAILLE_COLORS = [
    [(0, 26, 'HAIR')],
    [(0, 26, 'HAIR')],
    [(0, 26, 'HAIR')],
    [(0, 5, 'HAIR'), (5, 22, 'SKIN'), (22, 26, 'HAIR')],
    [(0, 5, 'HAIR'), (5, 22, 'SKIN'), (22, 26, 'HAIR')],
    [(0, 3, 'HAIR'), (3, 22, 'SKIN'), (22, 26, 'HAIR')],
    [(0, 26, 'SKIN')],
    [(0, 26, 'SKIN')],
    [(0, 10, 'SKIN'), (10, 17, 'SHIRT_BLUE'), (17, 26, 'SKIN')],
    [(0, 2, 'SKIN'), (2, 26, 'SHIRT_BLUE')],
    [(0, 26, 'SHIRT_BLUE')],
]
_BRAILLE_WIDTH = 26

# -----------------------------------------------------------------------------
# Style 2: Full-body braille art (from emojicombos.com)
# -----------------------------------------------------------------------------
_BRAILLE_FULL_RAW = [
    "⠀⠀⠀⠀⠀⠀⣀⣤⣶⡶⢛⠟⡿⠻⢻⢿⢶⢦⣄⡀⠀⠀⠀⠀⠀⠀",
    "⠀⠀⠀⢀⣠⡾⡫⢊⠌⡐⢡⠊⢰⠁⡎⠘⡄⢢⠙⡛⡷⢤⡀⠀⠀⠀",
    "⠀⠀⢠⢪⢋⡞⢠⠃⡜⠀⠎⠀⠉⠀⠃⠀⠃⠀⠃⠙⠘⠊⢻⠦⠀⠀",
    "⠀⠀⢇⡇⡜⠀⠜⠀⠁⠀⢀⠔⠉⠉⠑⠄⠀⠀⡰⠊⠉⠑⡄⡇⠀⠀",
    "⠀⠀⡸⠧⠄⠀⠀⠀⠀⠀⠘⡀⠾⠀⠀⣸⠀⠀⢧⠀⠛⠀⠌⡇⠀⠀",
    "⠀⠘⡇⠀⠀⠀⠀⠀⠀⠀⠀⠙⠒⠒⠚⠁⠈⠉⠲⡍⠒⠈⠀⡇⠀⠀",
    "⠀⠀⠈⠲⣆⠀⠀⠀⠀⠀⠀⠀⠀⣠⠖⠉⡹⠤⠶⠁⠀⠀⠀⠈⢦⠀",
    "⠀⠀⠀⠀⠈⣦⡀⠀⠀⠀⠀⠧⣴⠁⠀⠘⠓⢲⣄⣀⣀⣀⡤⠔⠃⠀",
    "⠀⠀⠀⠀⣜⠀⠈⠓⠦⢄⣀⣀⣸⠀⠀⠀⠀⠁⢈⢇⣼⡁⠀⠀⠀⠀",
    "⠀⠀⢠⠒⠛⠲⣄⠀⠀⠀⣠⠏⠀⠉⠲⣤⠀⢸⠋⢻⣤⡛⣄⠀⠀⠀",
    "⠀⠀⢡⠀⠀⠀⠀⠉⢲⠾⠁⠀⠀⠀⠀⠈⢳⡾⣤⠟⠁⠹⣿⢆⠀⠀",
    "⠀⢀⠼⣆⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⣼⠃⠀⠀⠀⠀⠀⠈⣧⠀",
    "⠀⡏⠀⠘⢦⡀⠀⠀⠀⠀⠀⠀⠀⠀⣠⠞⠁⠀⠀⠀⠀⠀⠀⠀⢸⣧",
    "⢰⣄⠀⠀⠀⠉⠳⠦⣤⣤⡤⠴⠖⠋⠁⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⢯",
    "⢸⣉⠉⠓⠲⢦⣤⣄⣀⣀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⢀⣀⣀⣀⣠⣼",
]
_BRAILLE_FULL_COLORS = [
    [(0, 26, 'HAIR')],
    [(0, 26, 'HAIR')],
    [(0, 26, 'HAIR')],
    [(0, 5, 'HAIR'), (5, 22, 'SKIN'), (22, 26, 'HAIR')],
    [(0, 5, 'HAIR'), (5, 22, 'SKIN'), (22, 26, 'HAIR')],
    [(0, 3, 'HAIR'), (3, 22, 'SKIN'), (22, 26, 'HAIR')],
    [(0, 26, 'SKIN')],
    [(0, 26, 'SKIN')],
    [(0, 10, 'SKIN'), (10, 17, 'SHIRT_BLUE'), (17, 26, 'SKIN')],
    [(0, 2, 'SKIN'), (2, 26, 'SHIRT_BLUE')],
    [(0, 26, 'SHIRT_BLUE')],
    [(0, 26, 'SHIRT_BLUE')],
    [(0, 26, 'SHIRT_BLUE')],
    [(0, 26, 'SHIRT_BLUE')],
    [(0, 26, 'SHIRT_BLUE')],
]
_BRAILLE_FULL_WIDTH = 30

# -----------------------------------------------------------------------------
# Style 3: Block art (using ░▒▓█ characters)
# -----------------------------------------------------------------------------
_BLOCKS_RAW = [
    "   ▓░  ▓  ░▓   ",
    "  ▓▓▓▓▓▓▓▓▓▓▓  ",
    " ▓▓▒▒▒▒▒▒▒▒▒▓▓ ",
    " ▓▒▒▒▒▒▒▒▒▒▒▒▓ ",
    " ▓▒ ●▒▒▒▒▒● ▒▓ ",
    " ▓▒▒▒▒ o ▒▒▒▒▓ ",
    " ▓▒▒ ~~~~~ ▒▒▓ ",
    " ▓▒▒▒▒▒▒▒▒▒▒▒▓ ",
    "  ▓▓▒▒▒▒▒▒▒▓▓  ",
    "   ███████████ ",
    "   █████████   ",
]
_BLOCKS_COLORS = [
    [(0, 15, 'HAIR')],                                           # hair spikes
    [(0, 15, 'HAIR')],                                           # hair band
    [(0, 3, 'HAIR'), (3, 12, 'SKIN'), (12, 15, 'HAIR')],         # forehead
    [(0, 2, 'HAIR'), (2, 13, 'SKIN'), (13, 15, 'HAIR')],         # face
    [(0, 2, 'HAIR'), (2, 13, 'SKIN'), (13, 15, 'HAIR')],         # eyes
    [(0, 2, 'HAIR'), (2, 13, 'SKIN'), (13, 15, 'HAIR')],         # nose
    [(0, 2, 'HAIR'), (2, 13, 'SKIN'), (13, 15, 'HAIR')],         # mouth
    [(0, 2, 'HAIR'), (2, 13, 'SKIN'), (13, 15, 'HAIR')],         # chin
    [(0, 3, 'HAIR'), (3, 12, 'SKIN'), (12, 15, 'HAIR')],         # jaw
    [(0, 15, 'SHIRT_BLUE')],                                     # shirt
    [(0, 15, 'SHIRT_BLUE')],                                     # shirt
]
_BLOCKS_WIDTH = 18

# -----------------------------------------------------------------------------
# Style 4: Minimal text art
# -----------------------------------------------------------------------------
_MINIMAL_RAW = [
    f"{Colors.HAIR}  .-~~~-.  {Colors.NC}",
    f"{Colors.HAIR} /  {Colors.SKIN}o o{Colors.HAIR}  \\ {Colors.NC}",
    f"{Colors.SKIN}|    <    |{Colors.NC}",
    f"{Colors.SKIN} \\  ===  / {Colors.NC}",
    f"{Colors.SHIRT_BLUE}  '-----'  {Colors.NC}",
]
_MINIMAL_COLORS = []  # Pre-colored
_MINIMAL_WIDTH = 14

# -----------------------------------------------------------------------------
# Build the active art based on environment variable
# -----------------------------------------------------------------------------
def _get_ralph_art():
    """Get Ralph art based on RALPH_ART_STYLE environment variable."""
    style = os.environ.get('RALPH_ART_STYLE', 'braille').lower()
    
    if style == 'none':
        return [], 0
    elif style == 'braille_full':
        return _colorize_art(_BRAILLE_FULL_RAW, _BRAILLE_FULL_COLORS, _COLOR_CODES), _BRAILLE_FULL_WIDTH
    elif style == 'blocks':
        return _colorize_art(_BLOCKS_RAW, _BLOCKS_COLORS, _COLOR_CODES), _BLOCKS_WIDTH
    elif style == 'minimal':
        return _MINIMAL_RAW, _MINIMAL_WIDTH  # Already colored
    else:  # default: braille
        return _colorize_art(_BRAILLE_RAW, _BRAILLE_COLORS, _COLOR_CODES), _BRAILLE_WIDTH

RALPH_ART, RALPH_WIDTH = _get_ralph_art()


@dataclass
class Metrics:
    """In-memory metrics for the current session."""
    total_cost: float = 0.0
    total_iterations: int = 0
    total_tokens_in: int = 0
    total_tokens_out: int = 0
    failures: int = 0
    successes: int = 0
    kills_timeout: int = 0
    kills_context: int = 0
    started_at: Optional[str] = None
    last_kill_reason: str = ""  # "timeout" or "context_limit"
    last_kill_activity: str = ""  # What agent was doing when killed


@dataclass
class IterationKillInfo:
    """Information about why an iteration was killed."""
    reason: str  # "timeout", "context_limit", "compaction_failed", or "none"
    task_name: Optional[str] = None
    tokens_used: int = 0
    context_limit: int = 0
    timeout_seconds: int = 0
    elapsed_seconds: int = 0
    last_activity: Optional[str] = None  # What the agent was doing when killed
    
    def to_prompt_injection(self) -> str:
        """Generate prompt text to inject into the next iteration."""
        if self.reason == "none":
            return ""
        
        lines = [
            "# CRITICAL: Previous Iteration Failed",
            "",
        ]
        
        if self.reason == "timeout":
            lines.extend([
                f"The previous iteration was KILLED after {self.elapsed_seconds}s (timeout: {self.timeout_seconds}s).",
                f"Task: {self.task_name or 'unknown'}",
                "",
                f"Last activity before kill: {self.last_activity or 'unknown'}",
                "",
                "## Required Actions:",
                "1. DO NOT repeat the same approach - it will fail again",
                "2. Break down the problem into SMALLER steps",
                "3. If investigating code, use targeted searches instead of reading entire files",
                "4. If the task is too complex, create sub-tasks using `ralph task add`",
                "5. Complete ONE small step, then EXIT to let the next iteration continue",
                "",
            ])
        elif self.reason == "context_limit" or self.reason == "compaction_failed":
            pct_used = (self.tokens_used / self.context_limit * 100) if self.context_limit > 0 else 0
            reason_text = "compaction failed (still >80% after attempt)" if self.reason == "compaction_failed" else "context overflow"
            lines.extend([
                f"The previous iteration was KILLED due to {reason_text} ({self.tokens_used:,} tokens, {pct_used:.0f}% of {self.context_limit:,} limit).",
                f"Task: {self.task_name or 'unknown'}",
                "",
                f"Last activity before kill: {self.last_activity or 'unknown'}",
                "",
                "## Required Actions - YOU MUST USE SUBAGENTS:",
                "",
                "You are reading too much code directly. USE THE TASK TOOL to spawn subagents:",
                "",
                "```",
                'Task: "Research how [X] works in this codebase. Find the relevant files, understand the implementation, and report back: 1) which files, 2) how it works, 3) what needs to change"',
                "```",
                "",
                "Each subagent gets a FRESH context window. Spawn multiple subagents in parallel for different research questions.",
                "",
                "DO NOT:",
                "- Read files directly (use subagents)",
                "- Explore broadly (be specific in subagent prompts)", 
                "- Try to understand everything at once",
                "",
                "DO:",
                "- Spawn a subagent for each research question",
                "- Wait for subagent results before proceeding",
                "- Make targeted edits based on subagent findings",
                "",
            ])
        
        lines.append("---\n")
        return "\n".join(lines)


@dataclass
class RalphConfig:
    repo_root: Path
    ralph_dir: Path
    log_dir: Path
    prompt_plan: Path
    prompt_build: Path
    prompt_verify: Path
    prompt_investigate: Path
    prompt_decompose: Path
    specs_dir: Path
    output_fifo: Path
    plan_file: Path

    @classmethod
    def from_repo(cls, repo_root: Path) -> 'RalphConfig':
        ralph_dir = repo_root / 'ralph'
        log_dir = repo_root / 'build' / 'ralph-logs'
        return cls(
            repo_root=repo_root,
            ralph_dir=ralph_dir,
            log_dir=log_dir,
            prompt_plan=ralph_dir / 'PROMPT_plan.md',
            prompt_build=ralph_dir / 'PROMPT_build.md',
            prompt_verify=ralph_dir / 'PROMPT_verify.md',
            prompt_investigate=ralph_dir / 'PROMPT_investigate.md',
            prompt_decompose=ralph_dir / 'PROMPT_decompose.md',
            specs_dir=ralph_dir / 'specs',
            output_fifo=log_dir / 'output.fifo',
            plan_file=ralph_dir / 'plan.jsonl',
        )


# =============================================================================
# State Management (JSONL-based)
# =============================================================================
# 
# plan.jsonl format - each line is an independent record:
#   {"t": "spec", "spec": "coverage.md"}
#   {"t": "task", "id": "t-xxxx", "desc": "...", "s": "p"}        # pending
#   {"t": "task", "id": "t-yyyy", "desc": "...", "s": "d", "done_at": "abc"}  # done
#   {"t": "issue", "id": "i-zzzz", "desc": "..."}
#
# Benefits: Git-friendly merges (line-based), clean diffs, no conflicts on parallel adds

def _generate_id(prefix: str = 't') -> str:
    """Generate a short random ID like t-a1b2 or i-c3d4."""
    import random
    import string
    chars = string.ascii_lowercase + string.digits
    suffix = ''.join(random.choice(chars) for _ in range(4))
    return f"{prefix}-{suffix}"


@dataclass
class Task:
    id: str
    name: str  # Short task name (what to do)
    spec: str  # Spec file this task belongs to
    notes: Optional[str] = None  # Implementation notes/context (how to do it)
    accept: Optional[str] = None  # Acceptance criteria / test plan (how to verify)
    deps: Optional[list] = None  # List of task IDs this depends on
    status: str = "p"  # "p" = pending, "d" = done
    done_at: Optional[str] = None  # Commit hash when marked done
    needs_decompose: bool = False  # True if task was killed and needs breakdown
    kill_reason: Optional[str] = None  # "timeout" or "context" if killed
    kill_log: Optional[str] = None  # Path to log file from killed iteration
    priority: Optional[str] = None  # "high", "medium", or "low"
    
    def to_jsonl(self) -> str:
        d = {"t": "task", "id": self.id, "spec": self.spec, "name": self.name, "s": self.status}
        if self.notes:
            d["notes"] = self.notes
        if self.accept:
            d["accept"] = self.accept
        if self.deps:
            d["deps"] = self.deps
        if self.done_at:
            d["done_at"] = self.done_at
        if self.needs_decompose:
            d["decompose"] = True
        if self.kill_reason:
            d["kill"] = self.kill_reason
        if self.kill_log:
            d["kill_log"] = self.kill_log
        if self.priority:
            d["priority"] = self.priority
        return json.dumps(d)
    
    @classmethod
    def from_jsonl(cls, d: dict) -> 'Task':
        # Support legacy 'desc' field as 'name'
        name = d.get("name") or d.get("desc", "")
        return cls(
            id=d["id"], 
            name=name,
            spec=d.get("spec", ""),  # Empty for legacy tasks
            notes=d.get("notes"),
            accept=d.get("accept"),
            deps=d.get("deps"),
            status=d.get("s", "p"),
            done_at=d.get("done_at"),
            needs_decompose=d.get("decompose", False),
            kill_reason=d.get("kill"),
            kill_log=d.get("kill_log"),
            priority=d.get("priority")
        )


@dataclass 
class Issue:
    id: str
    desc: str
    spec: str  # Spec file this issue belongs to
    
    def to_jsonl(self) -> str:
        return json.dumps({"t": "issue", "id": self.id, "spec": self.spec, "desc": self.desc})
    
    @classmethod
    def from_jsonl(cls, d: dict) -> 'Issue':
        return cls(id=d["id"], desc=d["desc"], spec=d.get("spec", ""))


@dataclass
class Tombstone:
    id: str  # Task ID that was rejected
    done_at: str  # Commit hash where task was marked done
    reason: str  # Why the task was rejected
    
    def to_jsonl(self) -> str:
        return json.dumps({"t": "reject", "id": self.id, "done_at": self.done_at, "reason": self.reason})
    
    @classmethod
    def from_jsonl(cls, d: dict) -> 'Tombstone':
        return cls(id=d["id"], done_at=d["done_at"], reason=d["reason"])


@dataclass
class RalphPlanConfig:
    """Configuration from plan.jsonl config record."""
    timeout_ms: int = 300000  # 5 min default
    max_iterations: int = 10
    context_warn: float = 0.70
    context_compact: float = 0.85
    context_kill: float = 0.95
    
    def to_jsonl(self) -> str:
        return json.dumps({
            "t": "config",
            "timeout_ms": self.timeout_ms,
            "max_iterations": self.max_iterations,
            "context_warn": self.context_warn,
            "context_compact": self.context_compact,
            "context_kill": self.context_kill
        })
    
    @classmethod
    def from_jsonl(cls, d: dict) -> 'RalphPlanConfig':
        return cls(
            timeout_ms=d.get("timeout_ms", 300000),
            max_iterations=d.get("max_iterations", 10),
            context_warn=d.get("context_warn", 0.70),
            context_compact=d.get("context_compact", 0.85),
            context_kill=d.get("context_kill", 0.95)
        )


@dataclass
class RalphState:
    spec: Optional[str] = None
    tasks: list = field(default_factory=list)   # List of Task (both pending and done)
    issues: list = field(default_factory=list)  # List of Issue
    tombstones: list = field(default_factory=list)  # List of Tombstone
    config: Optional[RalphPlanConfig] = None  # Optional config record from plan.jsonl
    
    @property
    def pending(self) -> list:
        return [t for t in self.tasks if t.status == "p"]
    
    @property
    def done(self) -> list:
        return [t for t in self.tasks if t.status == "d"]
    
    @property
    def done_ids(self) -> set:
        """Set of completed task IDs."""
        return {t.id for t in self.done}
    
    def get_next_task(self) -> Optional[Task]:
        """Get next task respecting dependencies, sorted by priority (high > medium > low > None)."""
        done_ids = self.done_ids
        priority_order = {"high": 0, "medium": 1, "low": 2, None: 3}
        
        unblocked = []
        for idx, task in enumerate(self.pending):
            if not task.deps or all(dep in done_ids for dep in task.deps):
                unblocked.append((idx, task))
        
        if not unblocked:
            return self.pending[0] if self.pending else None
        
        unblocked.sort(key=lambda x: (priority_order.get(x[1].priority, 3), x[0]))
        return unblocked[0][1]
    
    def get_sorted_pending(self) -> list:
        """Return pending tasks sorted by priority (high > medium > low > None), then by topological order."""
        done_ids = self.done_ids
        priority_order = {"high": 0, "medium": 1, "low": 2, None: 3}
        result = []
        remaining = [(idx, task) for idx, task in enumerate(self.pending)]
        seen = set()
        
        changed = True
        while changed and remaining:
            changed = False
            ready = []
            still_waiting = []
            
            for idx, task in remaining:
                if not task.deps or all(dep in done_ids or dep in seen for dep in task.deps):
                    ready.append((idx, task))
                else:
                    still_waiting.append((idx, task))
            
            if ready:
                ready.sort(key=lambda x: (priority_order.get(x[1].priority, 3), x[0]))
                for idx, task in ready:
                    result.append(task)
                    seen.add(task.id)
                remaining = still_waiting
                changed = True
        
        remaining.sort(key=lambda x: (priority_order.get(x[1].priority, 3), x[0]))
        result.extend([task for _, task in remaining])
        return result
    
    def to_dict(self) -> dict:
        """For JSON output (ralph query)."""
        def task_to_dict(t: Task) -> dict:
            d = {"id": t.id, "name": t.name}
            if t.notes:
                d["notes"] = t.notes
            if t.accept:
                d["accept"] = t.accept
            if t.deps:
                d["deps"] = t.deps
            if t.done_at:
                d["done_at"] = t.done_at
            return d
        
        return {
            "spec": self.spec,
            "tasks": {
                "pending": [task_to_dict(t) for t in self.get_sorted_pending()],
                "done": [task_to_dict(t) for t in self.done],
            },
            "issues": [{"id": i.id, "desc": i.desc} for i in self.issues],
        }
    
    def get_stage(self) -> str:
        """Compute current stage based on state."""
        if self.spec is None:
            return "PLAN"
        # INVESTIGATE takes priority - process all issues before building
        if self.issues:
            return "INVESTIGATE"
        # DECOMPOSE takes priority over BUILD - must break down killed tasks first
        if any(t.needs_decompose for t in self.pending):
            return "DECOMPOSE"
        if self.pending:
            return "BUILD"
        if self.done:
            return "VERIFY"
        return "COMPLETE"
    
    def get_task_needing_decompose(self) -> Optional['Task']:
        """Get first task that needs decomposition."""
        for t in self.pending:
            if t.needs_decompose:
                return t
        return None
    
    def get_next(self) -> dict:
        """Get next action to take."""
        stage = self.get_stage()
        if stage == "PLAN":
            return {"action": "PLAN", "item": None}
        elif stage == "DECOMPOSE":
            task = self.get_task_needing_decompose()
            return {"action": "DECOMPOSE", "task": task_to_query_dict(task, include_decompose_info=True) if task else None}
        elif stage == "BUILD":
            task = self.get_next_task()
            return {"action": "BUILD", "task": task_to_query_dict(task) if task else None}
        elif stage == "VERIFY":
            return {"action": "VERIFY", "item": f"Verify {len(self.done)} completed tasks against spec"}
        elif stage == "INVESTIGATE":
            return {"action": "INVESTIGATE", "items": [{"id": i.id, "desc": i.desc} for i in self.issues], "count": len(self.issues)}
        else:
            return {"action": "COMPLETE", "item": None}


def task_to_query_dict(t: Task, include_decompose_info: bool = False) -> dict:
    """Convert task to dict for query output.
    
    Args:
        t: Task to convert
        include_decompose_info: If True, include kill_reason and kill_log for decompose context
    """
    d = {"id": t.id, "name": t.name}
    if t.notes:
        d["notes"] = t.notes
    if t.accept:
        d["accept"] = t.accept
    if t.deps:
        d["deps"] = t.deps
    if t.done_at:
        d["done_at"] = t.done_at
    if include_decompose_info and t.needs_decompose:
        if t.kill_reason:
            d["kill_reason"] = t.kill_reason
        if t.kill_log:
            d["kill_log"] = t.kill_log
    return d


def load_state(config: RalphConfig) -> RalphState:
    """Load state from plan.jsonl by reading all lines."""
    state = RalphState()
    
    if not config.plan_file.exists():
        return state
    
    try:
        for line in config.plan_file.read_text().strip().split('\n'):
            if not line.strip():
                continue
            d = json.loads(line)
            t = d.get("t")
            if t == "spec":
                state.spec = d.get("spec")
            elif t == "task":
                state.tasks.append(Task.from_jsonl(d))
            elif t == "issue":
                state.issues.append(Issue.from_jsonl(d))
            elif t == "reject":
                state.tombstones.append(Tombstone.from_jsonl(d))
            elif t == "config":
                state.config = RalphPlanConfig.from_jsonl(d)
    except (json.JSONDecodeError, KeyError):
        pass
    
    return state


def save_state(config: RalphConfig, state: RalphState, commit_msg: Optional[str] = None):
    """Save state to plan.jsonl, optionally commit."""
    lines = []
    
    if state.config:
        lines.append(state.config.to_jsonl())
    
    if state.spec:
        lines.append(json.dumps({"t": "spec", "spec": state.spec}))
    
    for task in state.tasks:
        lines.append(task.to_jsonl())
    
    for issue in state.issues:
        lines.append(issue.to_jsonl())
    
    for tombstone in state.tombstones:
        lines.append(tombstone.to_jsonl())
    
    config.plan_file.write_text('\n'.join(lines) + '\n' if lines else '')
    
    if commit_msg:
        subprocess.run(['git', 'add', str(config.plan_file)], 
                      cwd=config.repo_root, capture_output=True)
        subprocess.run(['git', 'commit', '-m', commit_msg],
                      cwd=config.repo_root, capture_output=True)


def get_current_commit(config: RalphConfig) -> str:
    """Get current HEAD commit hash (short)."""
    result = subprocess.run(
        ['git', 'rev-parse', '--short', 'HEAD'],
        capture_output=True, text=True, cwd=config.repo_root
    )
    return result.stdout.strip() if result.returncode == 0 else "unknown"


def check_unfinished_tasks(config: RalphConfig, new_spec: str) -> bool:
    """Check for unfinished tasks and prompt user. Returns True if OK to proceed."""
    state = load_state(config)
    
    if not state.tasks:
        return True
    
    current_spec = state.spec or "unknown"
    pending_tasks = state.pending
    done_tasks = state.done
    
    if not pending_tasks and not done_tasks:
        return True
    
    # Different messaging for same spec vs different spec
    same_spec = (current_spec == new_spec)
    
    if same_spec:
        print(f"{Colors.YELLOW}Found existing tasks for spec '{current_spec}':{Colors.NC}")
    else:
        print(f"{Colors.YELLOW}Found unfinished tasks from spec '{current_spec}':{Colors.NC}")
    
    for t in pending_tasks:
        print(f"  - [pending] {t.id}: {t.name}")
    for t in done_tasks:
        print(f"  - [done] {t.id}: {t.name}")
    print()
    print("What would you like to do?")
    print("  [c] Cancel existing tasks and start fresh")
    if same_spec:
        print("  [k] Keep existing tasks (continue where you left off)")
    print("  [a] Abort (keep current plan)")
    
    try:
        response = input(f"Choice [c/{'k/' if same_spec else ''}a]: ").strip().lower()
        if response == 'c':
            # Clear tasks before proceeding
            state.tasks = []
            save_state(config, state)
            print(f"{Colors.GREEN}Cleared existing tasks.{Colors.NC}")
            return True
        elif response == 'k' and same_spec:
            print(f"{Colors.GREEN}Keeping existing tasks. Plan will add to them.{Colors.NC}")
            return True
        else:
            print(f"{Colors.YELLOW}Aborted. Keeping current plan.{Colors.NC}")
            return False
    except (KeyboardInterrupt, EOFError):
        print()
        print(f"{Colors.YELLOW}Aborted. Keeping current plan.{Colors.NC}")
        return False


def has_uncommitted_plan(config: RalphConfig) -> bool:
    """Check if plan.jsonl has uncommitted changes (staged or unstaged)."""
    if not config.plan_file.exists():
        return False
    
    # Check for both staged and unstaged changes
    result = subprocess.run(
        ['git', 'status', '--porcelain', str(config.plan_file)],
        capture_output=True, text=True, cwd=config.repo_root
    )
    # Porcelain output is empty if file is clean
    return bool(result.stdout.strip())


def find_repo_root() -> Optional[Path]:
    """Find git repository root."""
    dir = Path.cwd()
    while dir != dir.parent:
        if (dir / '.git').exists():
            return dir
        dir = dir.parent
    return None


def find_project_rules(repo_root: Path) -> Optional[str]:
    """Find and load project rules from AGENTS.md or CLAUDE.md.
    
    Searches for rules files in order of precedence (first found wins):
    1. AGENTS.md in repo root
    2. CLAUDE.md in repo root
    
    Returns the content or None if no rules file found.
    """
    candidates = [
        repo_root / 'AGENTS.md',
        repo_root / 'CLAUDE.md',
    ]
    
    for path in candidates:
        if path.exists():
            try:
                return path.read_text()
            except (OSError, IOError):
                pass
    
    return None


def build_prompt_with_rules(prompt_content: str, project_rules: Optional[str]) -> str:
    """Combine project rules with ralph prompt.
    
    If project rules exist, prepend them to the prompt with clear separation.
    This ensures the AI follows repo-specific conventions while executing ralph tasks.
    """
    if not project_rules:
        return prompt_content
    
    return f"""# Project Rules (from AGENTS.md)

The following rules are MANDATORY for this repository. Follow them strictly.

{project_rules}

---

# Ralph Task

{prompt_content}
"""


def get_current_branch() -> str:
    """Get current git branch name."""
    try:
        result = subprocess.run(
            ['git', 'branch', '--show-current'],
            capture_output=True, text=True, check=True
        )
        return result.stdout.strip()
    except subprocess.CalledProcessError:
        return 'unknown'


def count_running_opencode(repo_root: Path) -> int:
    """Count opencode processes spawned by ralph in this repo."""
    count = 0
    try:
        result = subprocess.run(['pgrep', '-x', 'opencode'], capture_output=True, text=True)
        for pid in result.stdout.strip().split('\n'):
            if not pid:
                continue
            try:
                # Check if it's in this repo
                cwd = Path(f'/proc/{pid}/cwd').resolve()
                if not str(cwd).startswith(str(repo_root)):
                    continue
                
                # Check if parent is ralph (python running ralph.py)
                ppid = Path(f'/proc/{pid}/stat').read_text().split()[3]
                parent_cmdline = Path(f'/proc/{ppid}/cmdline').read_bytes().decode('utf-8', errors='replace')
                if 'ralph' in parent_cmdline:
                    count += 1
            except (OSError, PermissionError, FileNotFoundError):
                pass
    except subprocess.CalledProcessError:
        pass
    return count


def parse_cost_line(line: str) -> Optional[tuple[float, int, int]]:
    """Parse a cost line from ralph-stream output.
    
    Returns (cost, tokens_in, tokens_out) or None if not a cost line.
    """
    match = re.search(r'Cost: \$([0-9.]+) \| Tokens: (\d+)in/(\d+)out', line)
    if match:
        return (float(match.group(1)), int(match.group(2)), int(match.group(3)))
    return None


# ============================================================================
# Prompt Merge Helpers
# ============================================================================

def prompt_merge_choice(filename: str) -> str:
    """Ask user how to handle an existing prompt file.
    
    Returns: 'merge', 'keep', or 'override'
    """
    print(f"\n{Colors.YELLOW}Found existing: {filename}{Colors.NC}")
    print("  [1] Auto-merge (use LLM to merge your customizations with new template)")
    print("  [2] Keep existing (don't modify)")
    print("  [3] Override with default (replace with new template)")
    
    while True:
        try:
            choice = input(f"{Colors.CYAN}Choice [1/2/3]: {Colors.NC}").strip()
            if choice == '1':
                return 'merge'
            elif choice == '2':
                return 'keep'
            elif choice == '3':
                return 'override'
            else:
                print(f"{Colors.RED}Invalid choice. Enter 1, 2, or 3.{Colors.NC}")
        except (EOFError, KeyboardInterrupt):
            print(f"\n{Colors.YELLOW}Keeping existing file.{Colors.NC}")
            return 'keep'


def llm_merge_prompts(existing_content: str, new_template: str, filename: str, repo_root: Path) -> Optional[str]:
    """Use opencode to intelligently merge existing prompt customizations with new template.
    
    Returns merged content, or None if merge failed.
    """
    merge_prompt = f'''You are merging two versions of a Ralph prompt file: {filename}

EXISTING (user's customized version):
```
{existing_content}
```

NEW TEMPLATE (latest default):
```
{new_template}
```

Your task:
1. Identify any customizations the user made to the existing version
2. Preserve those customizations while incorporating any new features/improvements from the template
3. If the existing version has the same content as the template, just return the template
4. Output ONLY the merged content, no explanations or markdown code blocks

Merged content:'''

    try:
        # Use ephemeral state directory to avoid polluting session list
        opencode_env = os.environ.copy()
        opencode_env['XDG_STATE_HOME'] = '/tmp/ralph-opencode-state'
        # Deny external directory access to fail fast instead of hanging on permission prompts
        opencode_env['OPENCODE_PERMISSION'] = json.dumps({
            "external_directory": "deny",
            "doom_loop": "deny"
        })
        
        result = subprocess.run(
            ['opencode', 'run', '--print', merge_prompt],
            capture_output=True,
            text=True,
            cwd=repo_root,
            timeout=120,
            env=opencode_env
        )
        
        if result.returncode == 0 and result.stdout.strip():
            merged = result.stdout.strip()
            # Remove any markdown code block wrappers if present
            if merged.startswith('```') and merged.endswith('```'):
                lines = merged.split('\n')
                merged = '\n'.join(lines[1:-1])
            return merged
        else:
            print(f"{Colors.RED}LLM merge failed: {result.stderr}{Colors.NC}")
            return None
    except subprocess.TimeoutExpired:
        print(f"{Colors.RED}LLM merge timed out{Colors.NC}")
        return None
    except FileNotFoundError:
        print(f"{Colors.RED}opencode not found - cannot perform LLM merge{Colors.NC}")
        return None
    except Exception as e:
        print(f"{Colors.RED}LLM merge error: {e}{Colors.NC}")
        return None


def handle_prompt_file(prompt_path: Path, new_content: str, repo_root: Path) -> None:
    """Handle creating or updating a prompt file with merge options."""
    if not prompt_path.exists():
        # Fresh file, just create it
        prompt_path.write_text(new_content)
        return
    
    existing_content = prompt_path.read_text()
    
    # If content is identical, skip
    if existing_content.strip() == new_content.strip():
        print(f"  {Colors.DIM}{prompt_path.name} - unchanged{Colors.NC}")
        return
    
    choice = prompt_merge_choice(prompt_path.name)
    
    if choice == 'keep':
        print(f"  {Colors.YELLOW}Keeping existing {prompt_path.name}{Colors.NC}")
        return
    elif choice == 'override':
        prompt_path.write_text(new_content)
        print(f"  {Colors.GREEN}Replaced {prompt_path.name} with default template{Colors.NC}")
        return
    elif choice == 'merge':
        print(f"  {Colors.CYAN}Merging {prompt_path.name} with LLM...{Colors.NC}")
        merged = llm_merge_prompts(existing_content, new_content, prompt_path.name, repo_root)
        if merged:
            prompt_path.write_text(merged)
            print(f"  {Colors.GREEN}Merged {prompt_path.name} successfully{Colors.NC}")
        else:
            print(f"  {Colors.YELLOW}Merge failed, keeping existing {prompt_path.name}{Colors.NC}")


# ============================================================================
# Commands
# ============================================================================

def cmd_init(config: RalphConfig):
    """Initialize ralph in current repo, or update prompts if already initialized."""
    is_update = config.ralph_dir.exists()
    
    if is_update:
        print(f"{Colors.BLUE}Updating Ralph in {config.repo_root}{Colors.NC}")
    else:
        print(f"{Colors.BLUE}Initializing Ralph in {config.repo_root}{Colors.NC}")
    
    config.ralph_dir.mkdir(parents=True, exist_ok=True)
    config.specs_dir.mkdir(parents=True, exist_ok=True)
    config.log_dir.mkdir(parents=True, exist_ok=True)

    # Define prompt templates
    # Note: {{SPEC_FILE}} is replaced at runtime with the target spec filename
    plan_prompt_template = '''\
## Target Spec: {{SPEC_FILE}}

1. Run `ralph query` to see current state
2. Read the spec file: `ralph/specs/{{SPEC_FILE}}`

## CRITICAL: Use Subagents for Research

Your context window is LIMITED. Do NOT read many files yourself.

**Launch subagents in parallel to research different aspects:**

```
Task: "Research how [aspect] is currently implemented. Find relevant files, understand the patterns used, and report back what exists and what's missing for [spec requirement]"
```

Launch multiple Task calls in a single message to parallelize research.

## Task: Gap Analysis for {{SPEC_FILE}}

Compare the spec against the CURRENT codebase and generate a task list:

1. Use subagents to study the spec and relevant source code thoroughly
2. For each requirement in the spec, check if it's already implemented
3. Create tasks ONLY for what's missing or broken
4. DO NOT implement anything - planning only

## Output

For each task identified, run:
```
ralph task add '{"name": "Short task name", "notes": "Implementation details", "accept": "How to verify", "deps": ["t-xxxx"]}'
```

Task fields:
- `name` (required): Short description of what to do (e.g., "Add unit tests for parser")
- `notes` (optional): Implementation context, hints, relevant files
- `accept` (optional): Acceptance criteria / test plan (e.g., "pytest tests/test_parser.py passes")
- `deps` (optional): List of task IDs this task depends on

The command returns the new task ID (e.g., "Task added: t-1a2b - ..."). Use this ID when other tasks depend on it.

Rules:
- Each task should be completable in ONE iteration
- Add tasks in dependency order - add prerequisite tasks first so you have their IDs
- Be specific - "Add X to Y" not "Improve Z"
- Tasks are for {{SPEC_FILE}} only
- Include `accept` criteria when testable
- Use `deps` when a task requires another task to be done first

When done adding tasks, output:
```
[RALPH] PLAN_COMPLETE: Added N tasks for {{SPEC_FILE}}
```
'''

    build_prompt_template = '''\
# BUILD Stage

Implement the next pending task.

## Step 1: Get Task

Run `ralph query` to get current state. The `next.task` field shows:
- `name`: what to do
- `notes`: implementation hints (if provided)
- `accept`: how to verify it works (if provided)

## Step 2: Understand Context

1. Read the spec file: `ralph/specs/<spec>`
2. Review `notes` for implementation hints
3. **Use subagents for research** - see below

## CRITICAL: Use Subagents for Codebase Research

Your context window is LIMITED. Do NOT read many files yourself - you will run out of context and be killed.

**For any research task, use the Task tool to spawn subagents:**

```
Task: "Find how X is implemented in the codebase. Search for Y, read relevant files, and report back:
1. Which files contain X
2. How it currently works
3. What would need to change for Z"
```

**When to use subagents:**
- Understanding how a feature currently works
- Finding all usages of a function/type
- Exploring unfamiliar parts of the codebase
- Any task requiring reading more than 2-3 files

**When NOT to use subagents:**
- You already know exactly which file to edit
- Making a small, targeted change
- Running tests or build commands

Each subagent gets a fresh context window. Use them liberally for exploration.

## Step 3: Implement

Build the feature/fix. Rules:
- Complete implementations only, no stubs
- No code comments unless explicitly requested

## Step 4: Check Acceptance Criteria

Before marking done, verify the task's acceptance criteria:
1. Check **only** the `accept` criteria for this task
2. Run any tests specified in the criteria
3. Do NOT re-read the full spec - that's VERIFY stage's job

If acceptance criteria pass, mark done. VERIFY stage will do the thorough spec check later.

## Step 5: Complete

```
ralph task done
```

This marks the task done and auto-commits.

## Discovering Issues - IMPORTANT

You MUST record any problems you notice, even if unrelated to the current task:
```
ralph issue add "description of issue"
```

**Always add an issue when you see:**
- Test warnings (TSAN, ASAN, valgrind warnings)
- Compiler warnings
- Code that "works but has problems" (memory leaks, thread leaks, etc.)
- TODOs or FIXMEs you encounter
- Potential bugs you notice while reading code
- Missing test coverage you observe

**Do NOT ignore problems** just because your current task passes. If you see something wrong, record it.

Issues are investigated later in the INVESTIGATE stage.

## Spec Ambiguities - CRITICAL

**Do NOT make design decisions yourself.** If the spec is ambiguous or conflicts with technical constraints:

1. **Log an issue** with the ambiguity:
   ```
   ralph issue add "Spec ambiguity: <what the spec says> vs <technical reality>. Options: (1) ... (2) ..."
   ```

2. **Skip the task** or implement a minimal stub that makes the conflict visible

3. **Do NOT "interpret" the spec** - your interpretation may be wrong

**Examples of spec ambiguities:**
- Spec requires X but the architecture doesn't support X
- Spec is vague about behavior in edge case Y
- Two parts of the spec contradict each other
- Spec assumes a capability that doesn't exist

**Wrong:** "The pragmatic interpretation is..." then implementing your guess
**Right:** `ralph issue add "Spec says X but Y prevents this. Need clarification."`

Design decisions belong to the user, not the agent.

## Progress Reporting

```
[RALPH] === START: <task name> ===
```

```
[RALPH] === DONE: <task name> ===
[RALPH] RESULT: <summary>
```

## EXIT after marking task done
'''

    verify_prompt_template = '''\
# VERIFY Stage

All tasks are done. Verify the spec is actually complete.

## CRITICAL: The Spec File is the Source of Truth

**Do NOT just check task acceptance criteria.** The spec file may have been updated since tasks were created. You MUST verify against the CURRENT spec file content.

## Step 1: Read the Spec File

Read the ENTIRE spec file: `ralph/specs/<spec>`

Extract ALL requirements, including:
- Acceptance criteria checkboxes (`- [ ]`)
- Requirements stated in prose
- Behavioral expectations in examples
- Edge cases mentioned anywhere

**List every requirement you find.** Do not skip any.

## Step 2: Get Completed Tasks

Run `ralph query` to see completed tasks (status "done").

## Step 3: Verify Each Done Task (Parallelized)

For EACH done task, spawn a subagent to verify:

```
Task: "Verify task '{task.name}' with acceptance criteria: {task.accept}

1. RE-CHECK: Does the implementation meet the acceptance criteria?
   - Search codebase for the implementation
   - Run any tests specified
   - Check edge cases

2. ALIGNMENT CHECK (only if re-check passes): 
   - Does the acceptance criteria fully cover the related spec requirement?
   - Are there aspects of the spec requirement not covered by the criteria?

Return JSON:
{
  \\"task_id\\": \\"{task.id}\\",
  \\"recheck_passed\\": true | false,
  \\"recheck_evidence\\": \\"<what you found>\\",
  \\"alignment_ok\\": true | false,  // only if recheck passed
  \\"alignment_gap\\": \\"<what criteria missed>\\"  // only if alignment failed
}"
```

**Run all task verification subagents in parallel** (fork/join pattern).

## Step 4: Verify Spec Coverage (Parallelized)

For EACH requirement extracted from the spec file, spawn a subagent:

```
Task: "Verify this spec requirement is satisfied: <requirement>

1. Search codebase for the implementation
2. Check if it fully satisfies the requirement
3. Identify any gaps

Return JSON:
{
  \\"requirement\\": \\"<the requirement>\\",
  \\"satisfied\\": true | false,
  \\"evidence\\": \\"<what you found>\\",
  \\"gap\\": \\"<what's missing>\\"  // only if not satisfied
}"
```

**Run all spec verification subagents in parallel** (fork/join pattern).

## Step 5: Collect Results and Apply

After all subagents return:

### For each task:
- **Re-check failed** → `ralph task reject "<task_id>" "<reason>"`
- **Re-check passed, alignment gap** → `ralph task accept` + create new task for gap
- **Both passed** → `ralph task accept`

### For spec gaps:
- Create new task: `ralph task add '{"name": "what's missing", "accept": "how to verify"}'`

### Final decision:

If NO rejections and NO gaps:
```
[RALPH] SPEC_COMPLETE
```

If ANY rejections or gaps:
```
[RALPH] SPEC_INCOMPLETE: <summary>
```

The loop will continue with BUILD stage.

## Progress Reporting

```
[RALPH] === VERIFY: <spec name> ===
[RALPH] Requirements found: <count>
[RALPH] Tasks to verify: <count>
[RALPH] Verifying...
```

## EXIT after applying all verdicts
'''

    investigate_prompt_template = '''\
# INVESTIGATE Stage

Issues were discovered during build. Research and resolve ALL of them in parallel.

## Step 1: Get All Issues

Run `ralph query issues` to see all pending issues.

## Step 2: Parallel Investigation

Use the Task tool to investigate ALL issues in parallel. Launch one subagent per issue:

```
For each issue, launch a Task with prompt:
"Investigate this issue: <issue description>

1. Read relevant code to understand the problem
2. Determine root cause
3. Decide resolution:
   - If fix is non-trivial: describe the fix task needed
   - If fix is trivial: describe the simple fix
   - If out of scope: explain why

Return a JSON object:
{
  \\"issue_id\\": \\"<id>\\",
  \\"root_cause\\": \\"<what you found>\\",
  \\"resolution\\": \\"task\\" | \\"trivial\\" | \\"out_of_scope\\",
  \\"task\\": {  // only if resolution is \\"task\\"
    \\"name\\": \\"<fix description>\\",
    \\"notes\\": \\"<root cause and approach>\\",
    \\"accept\\": \\"<how to verify>\\"
  },
  \\"trivial_fix\\": \\"<description>\\"  // only if resolution is \\"trivial\\"
}
"
```

## Step 3: Collect Results and Apply

After all subagents complete:

1. Add all tasks in batch:
```
ralph task add \'{"name": "...", "notes": "...", "accept": "..."}\'
ralph task add \'{"name": "...", "notes": "...", "accept": "..."}\'
...
```

2. Clear all issues in one command:
```
ralph issue done-all
```

Or if only clearing specific issues:
```
ralph issue done-ids i-abc1 i-def2 i-ghi3
```

## Step 4: Report Summary

```
[RALPH] === INVESTIGATE COMPLETE ===
[RALPH] Processed: N issues
[RALPH] Tasks created: X
[RALPH] Trivial fixes: Y
[RALPH] Out of scope: Z
```

## IMPORTANT

- Launch ALL investigations in parallel using multiple Task tool calls in a single message
- Wait for all results before applying any changes
- Do NOT make code changes during investigation - only create tasks
- Use `ralph issue done-all` to clear all issues at once
- EXIT after all issues are resolved
'''

    decompose_prompt_template = '''\
# DECOMPOSE Stage

A task was killed because it was too large (exceeded context or timeout limits).
You must break it down into smaller subtasks.

## Step 1: Get the Failed Task

Run `ralph query` to see the task that needs decomposition.
The `next.task` field shows:
- `name`: The task that failed
- `kill_reason`: Why it was killed ("timeout" or "context_limit")
- `kill_log`: Path to the log from the failed iteration

## Step 2: Review the Failed Iteration Log (if available)

If `kill_log` is provided in the task, review it to understand what went wrong.

**CRITICAL**: The log file may be HUGE (it killed the previous iteration's context!). 
NEVER read the entire file. Always use head/tail:

```bash
# First check the size
wc -l <kill_log_path>

# Read ONLY the header (first 50 lines) - shows what task started
head -50 <kill_log_path>

# Read ONLY the tail (last 100 lines) - shows where it stopped  
tail -100 <kill_log_path>

# If you need to search for specific content
grep -n -E "error|Error|ERROR|failed|FAILED" <kill_log_path> | head -20
```

From this limited sample, determine:
- What work was started but not completed
- Where the iteration got stuck or ran out of context
- Which files were being modified
- Any partial progress that was made
- **What output flooded the context** (e.g., sanitizer output, verbose test logs)
  - This is important! Subtasks may need to suppress or redirect verbose output

If no `kill_log` is provided, skip this step and proceed to analyze the task based on its description.

## Step 3: Analyze the Task

Use subagents to understand what the task requires:

```
Task: "Analyze what's needed to implement: [task name]

Research the codebase and report:
1. Which files need to be modified
2. What are the distinct pieces of work
3. What order should they be done in
4. Any dependencies between pieces"
```

## Step 4: Create Subtasks

Break the original task into 2-5 smaller tasks that:
- Can each be completed in ONE iteration
- Have clear, specific scope
- Together accomplish the original task
- Account for any partial progress from the failed iteration

For each subtask:
```
ralph task add \'{"name": "Specific subtask", "notes": "What to do", "accept": "How to verify"}\'
```

Use `deps` to specify order if needed.

## Step 5: Remove the Original Task

After adding all subtasks, delete the original oversized task:
```
ralph task delete <task-id>
```

## Step 6: Report

```
[RALPH] === DECOMPOSE COMPLETE ===
[RALPH] Original: <original task name>
[RALPH] Kill reason: <timeout|context_limit>
[RALPH] Split into: N subtasks
```

Then EXIT to let the build loop process the new subtasks.

## Rules

- ALWAYS read the log file first to understand what happened
- Each subtask should be completable in ONE iteration (< 100k tokens)
- Be specific: "Add X to file Y" not "Implement feature Z"
- If a subtask is still too big, it will be killed and decomposed again
- DO NOT try to implement anything - just create the task breakdown
'''

    # Handle prompt files (with merge options if updating)
    if is_update:
        handle_prompt_file(config.prompt_plan, plan_prompt_template, config.repo_root)
        handle_prompt_file(config.prompt_build, build_prompt_template, config.repo_root)
        handle_prompt_file(config.prompt_verify, verify_prompt_template, config.repo_root)
        handle_prompt_file(config.prompt_investigate, investigate_prompt_template, config.repo_root)
        handle_prompt_file(config.prompt_decompose, decompose_prompt_template, config.repo_root)
    else:
        config.prompt_plan.write_text(plan_prompt_template)
        config.prompt_build.write_text(build_prompt_template)
        config.prompt_verify.write_text(verify_prompt_template)
        config.prompt_investigate.write_text(investigate_prompt_template)
        config.prompt_decompose.write_text(decompose_prompt_template)

    # Create example spec only on fresh init (preserve existing specs)
    if not is_update:
        (config.specs_dir / 'example.md').write_text('''\
# Example Specification

Delete this file and create your own specs.

## Overview

Describe what you want to build.

## Requirements

- Requirement 1
- Requirement 2

## Acceptance Criteria

- [ ] Criterion 1
- [ ] Criterion 2
''')

    # Initialize empty plan.jsonl on fresh init
    if not is_update and not config.plan_file.exists():
        save_state(config, RalphState())

    # Add logs to gitignore
    gitignore = config.repo_root / '.gitignore'
    if gitignore.exists():
        content = gitignore.read_text()
        if 'build/ralph-logs' not in content:
            with gitignore.open('a') as f:
                f.write('\n# Ralph logs\nbuild/ralph-logs/\n')

    if is_update:
        print(f"{Colors.GREEN}Ralph updated!{Colors.NC}")
        print()
        print("Updated files:")
        print(f"  {config.ralph_dir}/")
        print("  ├── PROMPT_plan.md        (planning mode)")
        print("  ├── PROMPT_build.md       (build stage)")
        print("  ├── PROMPT_verify.md      (verify stage)")
        print("  └── PROMPT_investigate.md (investigate stage)")
        print()
        print("Preserved:")
        print("  ├── plan.jsonl")
        print("  └── specs/*")
    else:
        print(f"{Colors.GREEN}Ralph initialized!{Colors.NC}")
        print()
        print("Next steps:")
        print("  1. Write specs in ralph/specs/")
        print("  2. Run 'ralph plan <spec.md>' to generate tasks")
        print("  3. Run 'ralph' to start building")
        print()
        print("Files created:")
        print(f"  {config.ralph_dir}/")
        print("  ├── PROMPT_plan.md        (planning mode)")
        print("  ├── PROMPT_build.md       (build stage)")
        print("  ├── PROMPT_verify.md      (verify stage)")
        print("  ├── PROMPT_investigate.md (investigate stage)")
        print("  ├── plan.jsonl            (task/issue state)")
        print("  └── specs/")
        print("      └── example.md        (delete and add your own)")


def cmd_status(config: RalphConfig):
    """Show current status."""
    if not config.ralph_dir.exists():
        print(f"{Colors.YELLOW}Ralph not initialized. Run 'ralph init' first.{Colors.NC}")
        return 1

    print(f"{Colors.BLUE}Ralph Status{Colors.NC}")
    print(f"  Repo: {config.repo_root}")
    print(f"  Branch: {get_current_branch()}")
    print()
    
    # Load state
    state = load_state(config)
    
    # Current spec
    if state.spec:
        print(f"  Spec: {Colors.CYAN}{state.spec}{Colors.NC}")
    else:
        print(f"  Spec: {Colors.YELLOW}None - run 'ralph plan <spec.md>'{Colors.NC}")
    
    # Stage
    stage = state.get_stage()
    stage_colors = {
        'PLAN': Colors.YELLOW,
        'BUILD': Colors.GREEN,
        'VERIFY': Colors.CYAN,
        'INVESTIGATE': Colors.RED,
        'COMPLETE': Colors.GREEN,
    }
    print(f"  Stage: {stage_colors.get(stage, '')}{stage}{Colors.NC}")
    
    # Tasks
    pending = len(state.pending)
    done = len(state.done)
    print(f"  Tasks: {pending} pending, {done} done (awaiting verification)")
    
    # Issues
    if state.issues:
        print(f"  Issues: {Colors.RED}{len(state.issues)} discovered{Colors.NC}")
    
    # Count specs
    spec_count = len(list(config.specs_dir.glob('*.md'))) if config.specs_dir.exists() else 0
    print(f"  Specs available: {spec_count} files")
    
    print()
    
    # Check for project rules
    rules_file = None
    for candidate in ['AGENTS.md', 'CLAUDE.md']:
        if (config.repo_root / candidate).exists():
            rules_file = candidate
            break
    if rules_file:
        print(f"  Rules: {Colors.GREEN}{rules_file}{Colors.NC}")
    
    # Running status
    running = count_running_opencode(config.repo_root)
    if running > 0:
        print(f"  Status: {Colors.GREEN}Running{Colors.NC} ({running} process(es))")
    else:
        print(f"  Status: {Colors.YELLOW}Stopped{Colors.NC}")
    
    # Next action
    next_action = state.get_next()
    action = next_action['action']
    print()
    print(f"{Colors.CYAN}Next: {action}{Colors.NC}")
    if action in ('BUILD', 'DECOMPOSE') and next_action.get('task'):
        task = next_action['task']
        print(f"  {task['id']}: {task['name'][:60]}...")
    elif action == 'INVESTIGATE' and next_action.get('items'):
        print(f"  {next_action['count']} issue(s) to investigate")
    elif next_action.get('item'):
        print(f"  {next_action['item']}")
    
    # Hint
    print()
    print(f"{Colors.DIM}Use 'ralph query' for JSON output, 'ralph watch' for live dashboard{Colors.NC}")


@dataclass
class DashboardState:
    """State for rendering the dashboard."""
    config: RalphConfig
    branch: str
    cost: float = 0.0  # Parsed from stream
    tokens_in: int = 0
    tokens_out: int = 0
    context_tokens: int = 0  # Current context window size
    context_limit: int = DEFAULT_CONTEXT_WINDOW
    iteration: Optional[int] = None
    output_lines: list[str] = field(default_factory=list)
    is_running: bool = False
    running_count: int = 0
    footer_text: str = "Watching..."
    scroll_offset: int = 0  # For scrollable output
    auto_scroll: bool = True  # Auto-scroll to bottom on new output
    stage: str = ""  # Current stage: PLAN, BUILD, VERIFY, INVESTIGATE, COMPLETE
    kills_timeout: int = 0
    kills_context: int = 0
    last_kill_reason: str = ""
    last_kill_activity: str = ""


# =============================================================================
# Textual TUI Application
# =============================================================================
# Uses Textual framework for smooth, optimized rendering with built-in:
# - Double-buffered rendering with character-level diffing
# - Smooth scrolling with mouse wheel support
# - Full ANSI color and emoji preservation
# - Reactive UI updates

def _create_textual_app():
    """Create and return the Textual app class. Lazy import to avoid startup cost."""
    from textual.app import App, ComposeResult
    from textual.containers import Container, Horizontal, Vertical, ScrollableContainer
    from textual.widgets import Static, Footer, Header, RichLog
    from textual.reactive import reactive
    from textual.binding import Binding
    from textual import work
    from textual.worker import Worker, get_current_worker
    from rich.text import Text
    from rich.console import Console
    from rich.markup import escape
    import asyncio

    class OutputLog(RichLog):
        """Scrollable output log that preserves ANSI colors."""
        
        BINDINGS = [
            Binding("g", "scroll_home", "Top", show=False),
            Binding("G", "scroll_end", "Bottom", show=False),
            Binding("d", "page_down", "Page Down", show=False),
            Binding("u", "page_up", "Page Up", show=False),
            Binding("ctrl+d", "page_down", "Page Down", show=False),
            Binding("ctrl+u", "page_up", "Page Up", show=False),
        ]
        
        def __init__(self, **kwargs):
            super().__init__(highlight=False, markup=False, wrap=False, auto_scroll=True, **kwargs)
            self._follow_mode = True
            self._pending_scroll = 0  # Accumulate scroll delta
            self._scroll_timer = None
        
        @property 
        def follow_mode(self) -> bool:
            return self._follow_mode
        
        @follow_mode.setter
        def follow_mode(self, value: bool):
            self._follow_mode = value
            self.auto_scroll = value
        
        def toggle_follow(self):
            self.follow_mode = not self.follow_mode
            if self.follow_mode:
                self.scroll_end(animate=False)
        
        def _flush_scroll(self):
            """Apply accumulated scroll and reset."""
            if self._pending_scroll != 0:
                self.scroll_relative(y=self._pending_scroll, animate=False)
                self.follow_mode = False
                self._pending_scroll = 0
            self._scroll_timer = None
        
        def on_key(self, event) -> None:
            """Handle j/k with coalescing for fast key repeat."""
            if event.key == 'j':
                self._pending_scroll += 1
                event.prevent_default()
                event.stop()
            elif event.key == 'k':
                self._pending_scroll -= 1
                event.prevent_default()
                event.stop()
            else:
                return  # Let other keys bubble up
            
            # Schedule flush on next frame if not already scheduled
            if self._scroll_timer is None:
                self._scroll_timer = self.set_timer(0.016, self._flush_scroll)  # ~60fps
        
        def action_page_down(self):
            self._flush_scroll()  # Apply any pending scroll first
            self.scroll_relative(y=self.size.height // 2, animate=False)
            self.follow_mode = False
        
        def action_page_up(self):
            self._flush_scroll()
            self.scroll_relative(y=-self.size.height // 2, animate=False)
            self.follow_mode = False
        
        def action_scroll_home(self):
            self._flush_scroll()
            self.scroll_home(animate=False)
            self.follow_mode = False
        
        def action_scroll_end(self):
            self._flush_scroll()
            self.scroll_end(animate=False)
            self.follow_mode = True
        
        def on_mouse_scroll_down(self, event) -> None:
            self.follow_mode = False
        
        def on_mouse_scroll_up(self, event) -> None:
            self.follow_mode = False

    class RalphArtWidget(Static):
        """Widget to display Ralph ASCII art with colors."""
        
        DEFAULT_CSS = """
        RalphArtWidget {
            width: auto;
            height: auto;
        }
        """
        
        def __init__(self, art_lines: list[str], **kwargs):
            # Art already has ANSI codes, convert to Rich Text
            super().__init__(**kwargs)
            self._art_lines = art_lines
        
        def render(self):
            return Text.from_ansi('\n'.join(self._art_lines))

    class StatusPanel(Static):
        """Status information panel."""
        
        DEFAULT_CSS = """
        StatusPanel {
            width: 100%;
            height: auto;
            padding: 0 1;
        }
        """
        
        branch = reactive("")
        status_text = reactive("")
        stage_text = reactive("")
        cost_text = reactive("")
        context_text = reactive("")
        progress_text = reactive("")
        spec_text = reactive("")
        task_text = reactive("")
        kill_text = reactive("")
        
        def render(self):
            lines = []
            if self.branch:
                lines.append(f"[green]Branch:[/] {escape(self.branch)}")
            if self.status_text:
                lines.append(self.status_text)
            if self.stage_text:
                lines.append(self.stage_text)
            if self.cost_text:
                lines.append(self.cost_text)
            if self.context_text:
                lines.append(self.context_text)
            lines.append("")
            if self.progress_text:
                lines.append(self.progress_text)
            lines.append("")
            if self.spec_text:
                lines.append(self.spec_text)
            if self.task_text:
                lines.append(f"[green]Task:[/]")
                lines.append(f"  {escape(self.task_text)}")
            if self.kill_text:
                lines.append("")
                lines.append(self.kill_text)
            return Text.from_markup('\n'.join(lines))

    class IssuesPanel(Static):
        """Issues display panel."""
        
        DEFAULT_CSS = """
        IssuesPanel {
            width: 100%;
            height: auto;
            padding: 0 1;
            display: none;
        }
        IssuesPanel.visible {
            display: block;
        }
        """
        
        def __init__(self, **kwargs):
            super().__init__(**kwargs)
            self._issues = []
            self._open_count = 0
            self._fixed_count = 0
        
        def update_issues(self, issues: list, open_count: int, fixed_count: int):
            self._issues = issues[:5]
            self._open_count = open_count
            self._fixed_count = fixed_count
            if self._issues:
                self.add_class("visible")
            else:
                self.remove_class("visible")
            self.refresh()
        
        def render(self):
            if not self._issues:
                return ""
            lines = [f"[yellow]Issues:[/] ({self._open_count} open, {self._fixed_count} fixed)"]
            for status, text in self._issues:
                # Strip **[STATUS]** markers
                text = re.sub(r'^\*\*\[[A-Z_]+\]\*\*\s*', '', text)
                if status == 'fixed':
                    lines.append(f"  [green]FIXED[/] {escape(text[:60])}")
                else:
                    lines.append(f"  [red]OPEN[/]  {escape(text[:60])}")
            return Text.from_markup('\n'.join(lines))

    class RalphDashboard(App):
        """Main Ralph Wiggum dashboard application."""
        
        TITLE = "Ralph Wiggum"
        
        CSS = """
        Screen {
            background: $surface;
        }
        
        #header-bar {
            background: $primary;
            color: $text;
            height: 3;
            padding: 0 1;
            content-align: center middle;
        }
        
        #header-bar Static {
            text-style: bold;
            width: 100%;
            content-align: center middle;
        }
        
        #main-content {
            height: 1fr;
        }
        
        #info-panel {
            height: auto;
            max-height: 50%;
            padding: 1 0;
        }
        
        #ralph-section {
            height: auto;
            width: 100%;
            padding: 0 1;
        }
        
        #ralph-art {
            width: auto;
            min-width: 20;
        }
        
        #separator {
            width: 1;
            height: 100%;
            margin: 0 1;
        }
        
        #status {
            width: 1fr;
        }
        
        #divider {
            height: 1;
            width: 100%;
            border-top: solid $primary-lighten-2;
        }
        
        #issues {
            height: auto;
            max-height: 8;
        }
        
        #output-section {
            height: 1fr;
            border-top: solid $primary-lighten-2;
        }
        
        #output-header {
            height: 1;
            padding: 0 1;
            background: $surface-darken-1;
        }
        
        #output-log {
            height: 1fr;
            padding: 0 1;
        }
        
        #footer-bar {
            height: 1;
            background: $surface-darken-1;
            padding: 0 1;
        }
        
        .follow-on {
            color: $success;
        }
        
        .follow-off {
            color: $warning;
        }
        """
        
        BINDINGS = [
            Binding("q", "quit", "Quit"),
            Binding("f", "toggle_follow", "Follow"),
            Binding("j", "focus_log_down", "Down", show=False),
            Binding("k", "focus_log_up", "Up", show=False),
        ]
        
        def __init__(self, config: 'RalphConfig', watch_mode: bool = False, 
                     iteration: Optional[int] = None, **kwargs):
            super().__init__(**kwargs)
            self._config = config
            self._watch_mode = watch_mode
            self._iteration = iteration
            self._cost = 0.0
            self._tokens_in = 0
            self._tokens_out = 0
            self._context_tokens = 0
            self._context_limit = DEFAULT_CONTEXT_WINDOW
            self._branch = ""
            self._is_running = False
            self._running_count = 0
            self._output_lines: deque = deque(maxlen=2000)
            self._fifo_fd = None
            self._process = None  # For run mode
            self._output_buffer = None  # For run mode
            self._stop_requested = False
            self._kills_timeout = 0
            self._kills_context = 0
            self._last_kill_reason = ""
            self._last_kill_activity = ""
        
        def compose(self) -> ComposeResult:
            # Header
            with Container(id="header-bar"):
                yield Static(self._get_title())
            
            # Main content area
            with Vertical(id="main-content"):
                # Info panel (Ralph + status)
                with Vertical(id="info-panel"):
                    with Horizontal(id="ralph-section"):
                        yield RalphArtWidget(RALPH_ART if RALPH_ART else [], id="ralph-art")
                        yield Static("│", id="separator")
                        yield StatusPanel(id="status")
                    yield IssuesPanel(id="issues")
                
                # Output section
                with Vertical(id="output-section"):
                    yield Static("Output: [FOLLOW]", id="output-header")
                    yield OutputLog(id="output-log")
            
            # Footer
            yield Static(" q:quit  j/k:scroll  g/G:top/bottom  f:follow  d/u:page", id="footer-bar")
        
        def _get_title(self) -> str:
            ts = datetime.now().strftime('%H:%M:%S')
            kills_str = ""
            if self._kills_timeout > 0 or self._kills_context > 0:
                parts = []
                if self._kills_timeout > 0:
                    parts.append(f"T:{self._kills_timeout}")
                if self._kills_context > 0:
                    parts.append(f"C:{self._kills_context}")
                kills_str = f" | Kills: {' '.join(parts)}"
            if self._iteration is not None:
                return f"RALPH WIGGUM - Iteration {self._iteration} - {ts}{kills_str}"
            return f"RALPH WIGGUM - {ts}{kills_str}"
        
        def on_mount(self) -> None:
            """Start background tasks when app mounts."""
            self._branch = get_current_branch()
            
            # Start update loop
            self.set_interval(0.1, self._update_display)
            
            if self._watch_mode:
                # Start FIFO reader for watch mode
                self._start_fifo_reader()
            
            # Initial display update
            self._update_status_panel()
        
        def _start_fifo_reader(self):
            """Start reading from FIFO in background."""
            @work(thread=True, exclusive=True)
            async def read_fifo(self):
                while not self._stop_requested:
                    # Try to open FIFO if not open
                    if self._fifo_fd is None and self._config.output_fifo.exists():
                        try:
                            self._fifo_fd = os.open(str(self._config.output_fifo), os.O_RDWR | os.O_NONBLOCK)
                        except OSError:
                            pass
                    
                    # Read data
                    if self._fifo_fd is not None:
                        try:
                            ready, _, _ = select.select([self._fifo_fd], [], [], 0.05)
                            if ready:
                                data = os.read(self._fifo_fd, 8192)
                                if data:
                                    for line in data.decode('utf-8', errors='replace').splitlines():
                                        if line:
                                            self._output_lines.append(line)
                                            # Parse cost info from stream
                                            cost_info = parse_cost_line(line)
                                            if cost_info:
                                                self._cost = cost_info[0]
                                                self._tokens_in = cost_info[1]
                                                self._tokens_out = cost_info[2]
                                                self._context_tokens = cost_info[1]  # input tokens = context size
                                            # Post to main thread
                                            self.call_from_thread(self._append_output, line)
                        except OSError:
                            if self._fifo_fd is not None:
                                try:
                                    os.close(self._fifo_fd)
                                except OSError:
                                    pass
                            self._fifo_fd = None
                    else:
                        await asyncio.sleep(0.1)
            
            read_fifo(self)
        
        def _append_output(self, line: str):
            """Append a line to output log (called from main thread)."""
            log = self.query_one("#output-log", OutputLog)
            # Write with ANSI preserved - RichLog will render it
            log.write(Text.from_ansi(line))
        
        def _update_display(self):
            """Periodic display update."""
            # Update title with current time
            header = self.query_one("#header-bar Static", Static)
            header.update(self._get_title())
            
            # Update running status
            if self._watch_mode:
                self._running_count = count_running_opencode(self._config.repo_root)
                self._is_running = self._running_count > 0
            
            self._update_status_panel()
            self._update_output_header()
        
        def _update_status_panel(self):
            """Update the status panel."""
            status = self.query_one("#status", StatusPanel)
            state = load_state(self._config)
            
            status.branch = self._branch
            
            if self._is_running:
                if self._running_count > 0:
                    status.status_text = f"[green]Status:[/] Running ({self._running_count})"
                else:
                    status.status_text = "[green]Status:[/] Running"
            else:
                status.status_text = "[yellow]Status:[/] Stopped"
            
            # Show current stage with color coding
            stage = state.get_stage()
            stage_colors = {
                'PLAN': 'magenta',
                'BUILD': 'cyan',
                'VERIFY': 'yellow',
                'INVESTIGATE': 'red',
                'COMPLETE': 'green',
            }
            color = stage_colors.get(stage, 'white')
            status.stage_text = f"[green]Stage:[/] [{color}]{stage}[/]"
            
            if self._cost > 0:
                status.cost_text = f"[cyan]Cost:[/] ${self._cost:.4f}"
            else:
                status.cost_text = f"[cyan]Cost:[/] --"
            
            # Show context usage
            if self._context_tokens > 0:
                pct = self._context_tokens / self._context_limit * 100
                if pct >= 90:
                    color = "red"
                elif pct >= 70:
                    color = "yellow"
                else:
                    color = "cyan"
                status.context_text = f"[{color}]Context:[/] {self._context_tokens:,} / {self._context_limit:,} ({pct:.0f}%)"
            else:
                status.context_text = ""
            
            # Show last kill reason if any
            if self._last_kill_reason:
                status.kill_text = f"[red]Last Kill:[/] {self._last_kill_reason}"
                if self._last_kill_activity:
                    status.kill_text += f" @ {self._last_kill_activity}"
            else:
                status.kill_text = ""
            
            pending = len(state.pending)
            done = len(state.done)
            status.progress_text = f"[green]Progress:[/] {done} done, {pending} pending"
            
            if plan['current_spec']:
                status.spec_text = f"[green]Spec:[/] {plan['current_spec']}"
            else:
                status.spec_text = ""
            
            status.task_text = plan['next_task'] if plan['next_task'] else "(no pending tasks)"
            
            # Update issues
            issues_panel = self.query_one("#issues", IssuesPanel)
            issues_panel.update_issues(
                plan['issues']['items'],
                plan['issues']['open'],
                plan['issues']['fixed']
            )
        
        def _update_output_header(self):
            """Update output header with scroll/follow status."""
            log = self.query_one("#output-log", OutputLog)
            header = self.query_one("#output-header", Static)
            
            if log.follow_mode:
                header.update("Output: [green][FOLLOW][/]")
            else:
                header.update("Output: [yellow][SCROLL][/]")
        
        def action_toggle_follow(self):
            """Toggle follow mode."""
            log = self.query_one("#output-log", OutputLog)
            log.toggle_follow()
            self._update_output_header()
        
        def action_focus_log_down(self):
            """Scroll log down."""
            log = self.query_one("#output-log", OutputLog)
            log.action_scroll_down()
            self._update_output_header()
        
        def action_focus_log_up(self):
            """Scroll log up."""
            log = self.query_one("#output-log", OutputLog)
            log.action_scroll_up()
            self._update_output_header()
        
        def action_quit(self):
            """Quit the application."""
            self._stop_requested = True
            if self._fifo_fd is not None:
                try:
                    os.close(self._fifo_fd)
                except OSError:
                    pass
            self.exit()
        
        # Methods for run mode (not watch mode)
        def set_process(self, process, output_buffer: 'OutputBuffer'):
            """Set the process to monitor (for run mode)."""
            self._process = process
            self._output_buffer = output_buffer
            self._is_running = True
        
        def add_output_line(self, line: str):
            """Add a line to output (for run mode, called from output thread)."""
            self._output_lines.append(line)
            self.call_from_thread(self._append_output, line)
        
        def check_process_done(self) -> Optional[int]:
            """Check if process is done, return exit code or None."""
            if self._process is not None:
                ret = self._process.poll()
                if ret is not None:
                    self._is_running = False
                    return ret
            return None

    return RalphDashboard, OutputLog


class FallbackDashboard:
    """Shared ANSI fallback dashboard for watch and build modes."""
    
    def __init__(self, config: RalphConfig, iteration: Optional[int] = None):
        self.config = config
        self.iteration = iteration
        self.output_lines: deque = deque(maxlen=2000)
        self.scroll_offset = 0
        self.auto_scroll = True
        self.old_settings = None
        self.term_width = 80
        self.term_height = 24
        
        # Cached data
        self.cost = 0.0
        self.tokens_in = 0
        self.tokens_out = 0
        self.context_tokens = 0
        self.context_limit = DEFAULT_CONTEXT_WINDOW
        self.branch = ""
        self.is_running = False
        self.running_count = 0
        self.kills_timeout = 0
        self.kills_context = 0
        self.last_kill_reason = ""
        self.last_kill_activity = ""
    
    def get_input(self) -> Optional[str | tuple[str, int]]:
        """Non-blocking keyboard input with coalescing for scroll keys.
        
        Returns:
            - None if no input
            - str for single actions ('quit', 'page_down', etc.)
            - ('scroll', delta) for coalesced j/k scroll (delta can be negative)
        """
        scroll_delta = 0
        last_action = None
        
        try:
            # Drain all available input and coalesce scroll keys
            while True:
                ready, _, _ = select.select([sys.stdin], [], [], 0)
                if not ready:
                    break
                    
                ch = sys.stdin.read(1)
                if ch == 'q' or ch == 'Q':
                    return 'quit'  # Quit takes priority, return immediately
                elif ch == 'j':
                    scroll_delta += 1
                elif ch == 'k':
                    scroll_delta -= 1
                elif ch == 'g':
                    last_action = 'scroll_top'
                    scroll_delta = 0  # Reset scroll delta, jump takes priority
                elif ch == 'G':
                    last_action = 'scroll_bottom'
                    scroll_delta = 0
                elif ch == 'd':
                    last_action = 'page_down'
                elif ch == 'u':
                    last_action = 'page_up'
                elif ch == 'f' or ch == 'F':
                    last_action = 'toggle_follow'
                elif ch == '\x1b':  # Escape sequence
                    ready2, _, _ = select.select([sys.stdin], [], [], 0.01)
                    if ready2:
                        seq = sys.stdin.read(2)
                        if seq == '[A':
                            scroll_delta -= 1
                        elif seq == '[B':
                            scroll_delta += 1
                        elif seq == '[5':  # Page up
                            sys.stdin.read(1)  # consume ~
                            last_action = 'page_up'
                        elif seq == '[6':  # Page down
                            sys.stdin.read(1)  # consume ~
                            last_action = 'page_down'
        except:
            pass
        
        # Return coalesced scroll if any, otherwise last action
        if scroll_delta != 0:
            return ('scroll', scroll_delta)
        return last_action
    
    def handle_action(self, action) -> bool:
        """Handle a keyboard action. Returns True if should quit.
        
        Args:
            action: Either a string action or ('scroll', delta) tuple for coalesced scroll.
        """
        import shutil
        self.term_width, self.term_height = shutil.get_terminal_size((80, 24))
        viewport_height = max(1, self.term_height - 20)
        max_offset = max(0, len(self.output_lines) - viewport_height)
        
        # Handle coalesced scroll tuple
        if isinstance(action, tuple) and action[0] == 'scroll':
            delta = action[1]
            self.scroll_offset = max(0, min(self.scroll_offset + delta, max_offset))
            self.auto_scroll = (self.scroll_offset >= max_offset)
            return False
        
        if action == 'quit':
            return True
        elif action == 'scroll_top':
            self.scroll_offset = 0
            self.auto_scroll = False
        elif action == 'scroll_bottom':
            self.scroll_offset = max_offset
            self.auto_scroll = True
        elif action == 'page_down':
            self.scroll_offset = min(self.scroll_offset + viewport_height // 2, max_offset)
            self.auto_scroll = (self.scroll_offset >= max_offset)
        elif action == 'page_up':
            self.scroll_offset = max(self.scroll_offset - viewport_height // 2, 0)
            self.auto_scroll = False
        elif action == 'toggle_follow':
            self.auto_scroll = not self.auto_scroll
            if self.auto_scroll:
                self.scroll_offset = max_offset
        return False
    
    def render(self):
        """Render the dashboard."""
        import shutil
        self.term_width, self.term_height = shutil.get_terminal_size((80, 24))
        viewport_height = max(1, self.term_height - 20)
        
        # Auto-scroll if enabled
        if self.auto_scroll:
            self.scroll_offset = max(0, len(self.output_lines) - viewport_height)
        
        # Get visible output slice
        visible_output = list(self.output_lines)[self.scroll_offset:self.scroll_offset + viewport_height]
        
        # Build scroll indicator
        if len(self.output_lines) > viewport_height:
            scroll_info = f"[{self.scroll_offset + 1}-{min(self.scroll_offset + viewport_height, len(self.output_lines))}/{len(self.output_lines)}]"
            scroll_info += " FOLLOW" if self.auto_scroll else " SCROLL"
        else:
            scroll_info = "FOLLOW" if self.auto_scroll else ""
        
        state = DashboardState(
            config=self.config,
            branch=self.branch,
            cost=self.cost,
            tokens_in=self.tokens_in,
            tokens_out=self.tokens_out,
            context_tokens=self.context_tokens,
            context_limit=self.context_limit,
            iteration=self.iteration,
            output_lines=visible_output,
            is_running=self.is_running,
            running_count=self.running_count,
            footer_text=f"q:quit j/k:scroll g/G:top/bot f:follow | {scroll_info}",
            kills_timeout=self.kills_timeout,
            kills_context=self.kills_context,
            last_kill_reason=self.last_kill_reason,
            last_kill_activity=self.last_kill_activity
        )
        
        # Move cursor to top and render
        sys.stdout.write('\033[H')
        lines = render_dashboard(state, self.term_width, self.term_height)
        sys.stdout.write('\n'.join(lines))
        sys.stdout.flush()
    
    def enter(self):
        """Enter dashboard mode - set up terminal."""
        import termios
        self.old_settings = termios.tcgetattr(sys.stdin)
        new_settings = termios.tcgetattr(sys.stdin)
        new_settings[3] = new_settings[3] & ~termios.ECHO
        new_settings[3] = new_settings[3] & ~termios.ICANON
        termios.tcsetattr(sys.stdin, termios.TCSANOW, new_settings)
        
        sys.stdout.write('\033[?1049h')  # Alternate screen
        sys.stdout.write('\033[?25l')    # Hide cursor
        sys.stdout.flush()
    
    def exit(self):
        """Exit dashboard mode - restore terminal."""
        import termios
        if self.old_settings:
            termios.tcsetattr(sys.stdin, termios.TCSADRAIN, self.old_settings)
        sys.stdout.write('\033[?25h')  # Show cursor
        sys.stdout.write('\033[?1049l')  # Exit alternate screen
        sys.stdout.flush()
    
    def add_line(self, line: str):
        """Add an output line."""
        self.output_lines.append(line)
        # Parse cost info
        cost_info = parse_cost_line(line)
        if cost_info:
            self.cost = cost_info[0]
            self.tokens_in = cost_info[1]
            self.tokens_out = cost_info[2]
            self.context_tokens = cost_info[1]  # input tokens = context size


def render_dashboard(state: DashboardState, term_width: int, term_height: int) -> list[str]:
    """Render the dashboard and return lines."""
    CLEAR_LINE = '\033[K'
    
    def truncate(text, max_width, prefix_len=0):
        """Truncate text to fit terminal, accounting for ANSI codes."""
        visible_max = max_width - prefix_len - 3
        if len(text) > visible_max:
            return text[:visible_max] + "..."
        return text
    
    lines = []
    def add(text=''):
        lines.append(f"{text}{CLEAR_LINE}")
    
    header_bar = "═" * (term_width - 1)
    section_bar = "─" * (term_width - 1)
    footer_bar = "─" * (term_width - 1)
    
    # Header
    add(f"{Colors.BLUE}{header_bar}{Colors.NC}")
    
    # Build kills string for header
    kills_str = ""
    if state.kills_timeout > 0 or state.kills_context > 0:
        parts = []
        if state.kills_timeout > 0:
            parts.append(f"T:{state.kills_timeout}")
        if state.kills_context > 0:
            parts.append(f"C:{state.kills_context}")
        kills_str = f" | {Colors.RED}Kills: {' '.join(parts)}{Colors.NC}"
    
    if state.iteration is not None:
        title = f"  RALPH WIGGUM - Iteration {state.iteration} - {datetime.now().strftime('%H:%M:%S')}{kills_str}"
    else:
        title = f"  RALPH WIGGUM - {datetime.now().strftime('%H:%M:%S')}{kills_str}"
    add(f"{Colors.BLUE}{title}{Colors.NC}")
    add(f"{Colors.BLUE}{header_bar}{Colors.NC}")
    add()
    
    # Load state data
    ralph_state = load_state(state.config)
    
    # Build status lines to display next to Ralph
    status_lines = []
    status_lines.append(f"🌿 {Colors.GREEN}Branch:{Colors.NC} {state.branch}")
    
    if state.is_running:
        if state.running_count > 0:
            status_lines.append(f"🟢 {Colors.GREEN}Status:{Colors.NC} Running ({state.running_count})")
        else:
            status_lines.append(f"🟢 {Colors.GREEN}Status:{Colors.NC} Running")
    else:
        status_lines.append(f"🟡 {Colors.YELLOW}Status:{Colors.NC} Stopped")
    
    # Show current stage with color coding
    stage = ralph_state.get_stage()
    stage_colors = {
        'PLAN': Colors.MAGENTA,
        'BUILD': Colors.CYAN,
        'VERIFY': Colors.YELLOW,
        'INVESTIGATE': Colors.RED,
        'COMPLETE': Colors.GREEN,
    }
    stage_color = stage_colors.get(stage, Colors.WHITE)
    status_lines.append(f"🔧 {Colors.GREEN}Stage:{Colors.NC} {stage_color}{stage}{Colors.NC}")
    
    if state.cost > 0:
        status_lines.append(f"💰 {Colors.CYAN}Cost:{Colors.NC} ${state.cost:.4f}")
    else:
        status_lines.append(f"💰 {Colors.CYAN}Cost:{Colors.NC} --")
    
    # Show context usage (always show, even if 0, for debugging)
    pct = (state.context_tokens / state.context_limit * 100) if state.context_limit > 0 else 0
    if pct >= 90:
        ctx_color = Colors.RED
    elif pct >= 70:
        ctx_color = Colors.YELLOW
    else:
        ctx_color = Colors.CYAN
    status_lines.append(f"🧠 {ctx_color}Context:{Colors.NC} {state.context_tokens:,} / {state.context_limit:,} ({pct:.0f}%)")
    
    # Show last kill reason if any
    if state.last_kill_reason:
        kill_msg = f"⚠️  {Colors.RED}Kill:{Colors.NC} {state.last_kill_reason}"
        if state.last_kill_activity:
            kill_msg += f" @ {state.last_kill_activity[:30]}"
        status_lines.append(kill_msg)
    
    pending = len(ralph_state.pending)
    done = len(ralph_state.done)
    status_lines.append(f"")
    status_lines.append(f"📊 {Colors.GREEN}Progress:{Colors.NC} {done} done, {pending} pending")
    status_lines.append(f"")
    if ralph_state.spec:
        status_lines.append(f"📋 {Colors.GREEN}Spec:{Colors.NC} {ralph_state.spec}")
    status_lines.append(f"🎯 {Colors.GREEN}Task:{Colors.NC}")
    next_task = ralph_state.pending[0].name if ralph_state.pending else None
    if next_task:
        status_lines.append(f"   {truncate(next_task, term_width - RALPH_WIDTH - 6, 3)}")
    else:
        status_lines.append(f"   (no pending tasks)")
    
    # Print Ralph art alongside status info with vertical separator
    num_art_lines = max(len(RALPH_ART), len(status_lines))
    for i in range(num_art_lines):
        ralph_line = RALPH_ART[i] if i < len(RALPH_ART) else " " * RALPH_WIDTH
        status_line = status_lines[i] if i < len(status_lines) else ""
        add(f"{ralph_line} {Colors.DIM}│{Colors.NC} {status_line}")
    
    # T-join separator (┴) connecting vertical bar to horizontal
    # The │ is at position RALPH_WIDTH + 1 (after ralph art + space)
    left_width = RALPH_WIDTH + 1  # Ralph art width + space before │
    right_width = term_width - left_width - 1  # rest after ┴
    if right_width < 0:
        right_width = 0
    t_join_separator = "─" * left_width + "┴" + "─" * right_width
    add(f"{Colors.DIM}{t_join_separator}{Colors.NC}")
    
    # Discovered Issues
    if ralph_state.issues:
        add(f"{Colors.YELLOW}Discovered Issues:{Colors.NC} ({len(ralph_state.issues)} open)")
        for issue in ralph_state.issues[:5]:
            truncated_text = truncate(issue.desc, term_width, 9)
            add(f"  {Colors.RED}OPEN{Colors.NC}   {truncated_text}")
        if len(ralph_state.issues) > 5:
            add(f"  {Colors.YELLOW}... and {len(ralph_state.issues) - 5} more{Colors.NC}")
        add(f"{Colors.DIM}{section_bar}{Colors.NC}")
    
    # Latest output - fill rest of screen
    lines_used = len(lines)
    available_lines = term_height - lines_used - 3  # Reserve for Output: header + footer (2 lines)
    add(f"{Colors.GREEN}Output:{Colors.NC}")
    if available_lines >= 1:
        display_lines = state.output_lines[-available_lines:] if state.output_lines else []
        for line in display_lines:
            add(f"  {truncate(line, term_width, 2)}")
        for _ in range(available_lines - len(display_lines)):
            add()
    
    add(f"{Colors.BLUE}{footer_bar}{Colors.NC}")
    # Footer text without newline (handled by caller)
    lines.append(f"{state.footer_text}{CLEAR_LINE}")
    
    return lines


def cmd_watch(config: RalphConfig):
    """Live dashboard showing current status with streamed output."""
    if not _check_textual():
        # Use the original ANSI-based dashboard (still good, just not as optimized)
        _cmd_watch_fallback(config)
        return
    
    # Use Textual TUI
    RalphDashboard, _ = _create_textual_app()
    app = RalphDashboard(config, watch_mode=True)
    app.run()
    print("Stopped watching.")


def _cmd_watch_fallback(config: RalphConfig):
    """Fallback watch mode without Textual - uses shared FallbackDashboard."""
    fifo_fd = None
    dashboard = FallbackDashboard(config)
    last_expensive_update = 0
    EXPENSIVE_UPDATE_INTERVAL = 1.0
    needs_redraw = True
    last_output_count = 0
    
    dashboard.branch = get_current_branch()
    dashboard.running_count = count_running_opencode(config.repo_root)
    dashboard.is_running = dashboard.running_count > 0
    
    dashboard.enter()
    
    try:
        while True:
            now = time.time()
            
            # Try to open FIFO if not open
            if fifo_fd is None and config.output_fifo.exists():
                try:
                    fifo_fd = os.open(str(config.output_fifo), os.O_RDWR | os.O_NONBLOCK)
                except OSError:
                    pass
            
            # Read any available data from FIFO
            if fifo_fd is not None:
                try:
                    while True:
                        ready, _, _ = select.select([fifo_fd], [], [], 0)
                        if not ready:
                            break
                        data = os.read(fifo_fd, 4096)
                        if not data:
                            break
                        for line in data.decode('utf-8', errors='replace').splitlines():
                            if line:
                                dashboard.add_line(line)
                except OSError:
                    if fifo_fd is not None:
                        try:
                            os.close(fifo_fd)
                        except OSError:
                            pass
                    fifo_fd = None
            
            # Check if output changed
            if len(dashboard.output_lines) != last_output_count:
                last_output_count = len(dashboard.output_lines)
                needs_redraw = True
            
            # Handle keyboard input
            action = dashboard.get_input()
            if action:
                if dashboard.handle_action(action):
                    break
                dashboard.render()
                continue
            
            # Refresh expensive data periodically
            if now - last_expensive_update >= EXPENSIVE_UPDATE_INTERVAL:
                dashboard.running_count = count_running_opencode(config.repo_root)
                dashboard.is_running = dashboard.running_count > 0
                if int(now) % 5 == 0:
                    dashboard.branch = get_current_branch()
                last_expensive_update = now
                needs_redraw = True
            
            # Render if needed
            if needs_redraw:
                dashboard.render()
                needs_redraw = False
            
            time.sleep(0.016)
                
    except KeyboardInterrupt:
        pass
    finally:
        dashboard.exit()
        if fifo_fd is not None:
            try:
                os.close(fifo_fd)
            except OSError:
                pass
        print("Stopped watching.")


def cmd_stream():
    """Filter opencode stream-json output to show human-readable progress with syntax highlighting.
    
    Usage: opencode --format json | ralph stream
    
    Note: This command doesn't require being in a git repo since it just processes stdin.
    """
    # ANSI color codes
    class C:
        RESET = '\033[0m'
        BOLD = '\033[1m'
        DIM = '\033[2m'
        RED = '\033[31m'
        GREEN = '\033[32m'
        YELLOW = '\033[33m'
        BLUE = '\033[34m'
        MAGENTA = '\033[35m'
        CYAN = '\033[36m'
        WHITE = '\033[37m'
        BRIGHT_BLACK = '\033[90m'
        BRIGHT_GREEN = '\033[92m'
        BRIGHT_YELLOW = '\033[93m'
        BRIGHT_BLUE = '\033[94m'
        BRIGHT_MAGENTA = '\033[95m'
        BRIGHT_CYAN = '\033[96m'

    for line in sys.stdin:
        line = line.strip()
        if not line:
            continue
        
        try:
            event = json.loads(line)
        except json.JSONDecodeError:
            continue
        
        event_type = event.get("type", "")
        part = event.get("part", {})
        
        # OpenCode format
        if event_type == "text":
            text = part.get("text", "")
            if text:
                # Model's thinking/explanation text - dim white
                print(f"\n{C.WHITE}{text}{C.RESET}")
                sys.stdout.flush()
        
        elif event_type == "tool_use":
            tool = part.get("tool", "?")
            state = part.get("state", {})
            args = state.get("input", {})
            title = state.get("title", "")
            output = state.get("output", "")
            
            # Tool label color based on tool type
            if tool == "bash":
                cmd = args.get("command", "")
                desc = args.get("description", "") or title
                print(f"\n⚡ {C.BRIGHT_YELLOW}Bash:{C.RESET} {C.DIM}{cmd[:80]}{C.RESET}")
                if desc:
                    print(f"  {C.YELLOW}{desc}{C.RESET}")
            elif tool == "read":
                path = args.get("filePath", "")
                print(f"\n📖 {C.BRIGHT_CYAN}Read:{C.RESET} {C.CYAN}{path}{C.RESET}")
            elif tool == "edit":
                path = args.get("filePath", "")
                print(f"\n✏️  {C.BRIGHT_GREEN}Edit:{C.RESET} {C.GREEN}{path}{C.RESET}")
            elif tool == "write":
                path = args.get("filePath", "")
                print(f"\n📝 {C.BRIGHT_GREEN}Write:{C.RESET} {C.GREEN}{path}{C.RESET}")
            elif tool == "grep":
                pattern = args.get("pattern", "")
                print(f"\n🔍 {C.BRIGHT_MAGENTA}Grep:{C.RESET} {C.MAGENTA}{pattern}{C.RESET}")
            elif tool == "glob":
                pattern = args.get("pattern", "")
                print(f"\n📁 {C.BRIGHT_MAGENTA}Glob:{C.RESET} {C.MAGENTA}{pattern}{C.RESET}")
            elif tool == "task":
                desc = args.get("description", "") or title
                print(f"\n🤖 {C.BRIGHT_BLUE}Task:{C.RESET} {C.BLUE}{desc}{C.RESET}")
            elif tool == "ddg-search" or tool == "webfetch":
                query = args.get("query", "") or args.get("url", "") or title
                print(f"\n🦆 {C.BRIGHT_CYAN}Web:{C.RESET} {C.CYAN}{query}{C.RESET}")
            elif tool.startswith("ralph") or tool.startswith("mcp_ralph"):
                desc = args.get("description", "") or title or tool
                print(f"\n👮 {C.BRIGHT_YELLOW}Ralph:{C.RESET} {C.YELLOW}{desc}{C.RESET}")
            else:
                label = f"{tool}: {title}" if title else tool
                print(f"\n🔧 {C.WHITE}{label}{C.RESET}")
            
            # Show brief output - dimmed
            if output:
                lines = str(output).strip().split('\n')
                if len(lines) <= 3:
                    for l in lines:
                        print(f"  {C.DIM}{l[:100]}{C.RESET}")
                else:
                    print(f"  {C.DIM}({len(lines)} lines){C.RESET}")
            sys.stdout.flush()
        
        elif event_type == "step_finish":
            cost = part.get("cost", 0)
            tokens = part.get("tokens", {})
            input_tokens = tokens.get("input", 0)
            output_tokens = tokens.get("output", 0)
            cache = tokens.get("cache", {})
            cache_read = cache.get("read", 0)
            # Context window = new input tokens + cached tokens (both are "in" the context)
            context_size = input_tokens + cache_read
            # Soft divider
            print(f"\n{C.BRIGHT_BLACK}· · ·{C.RESET}")
            # Metrics line for parse_cost_line() - prefixed with \x00 to filter from display
            print(f"\x00Cost: ${cost:.4f} | Tokens: {context_size}in/{output_tokens}out")
            sys.stdout.flush()


@dataclass 
class OutputBuffer:
    """Thread-safe buffer for output lines."""
    lines: deque = field(default_factory=lambda: deque(maxlen=100))
    lock: threading.Lock = field(default_factory=threading.Lock)
    total_output: list = field(default_factory=list)  # For completion promise check
    last_activity: str = ""  # Last tool/action observed
    iteration_tokens: int = 0  # Latest context window size (not cumulative)
    
    def add(self, line: str):
        with self.lock:
            self.lines.append(line)
            self.total_output.append(line)
    
    def set_last_activity(self, activity: str):
        with self.lock:
            self.last_activity = activity
    
    def get_last_activity(self) -> str:
        with self.lock:
            return self.last_activity
    
    def set_context_tokens(self, tokens: int):
        """Set current context window size (replaces, doesn't accumulate)."""
        with self.lock:
            self.iteration_tokens = tokens
    
    def get_iteration_tokens(self) -> int:
        with self.lock:
            return self.iteration_tokens
    
    def get_lines(self) -> list[str]:
        with self.lock:
            return list(self.lines)
    
    def get_all(self) -> str:
        with self.lock:
            return '\n'.join(self.total_output)


def run_with_live_ui(process, config: RalphConfig, iteration: int,
                     metrics: Metrics, branch: str, output_buffer: OutputBuffer) -> int:
    """Run process with live dashboard UI, return exit code."""
    
    if not _check_textual():
        # Fallback: just wait for process without fancy UI
        return _run_with_simple_ui(process, config, iteration, metrics, branch, output_buffer)
    
    # Use Textual TUI with process monitoring
    RalphDashboard, _ = _create_textual_app()
    
    # Create a custom app that monitors the process
    app = RalphDashboard(config, watch_mode=False, iteration=iteration)
    app._cost = metrics.total_cost
    app._tokens_in = metrics.total_tokens_in
    app._tokens_out = metrics.total_tokens_out
    app._branch = branch
    app._is_running = True
    app._output_buffer = output_buffer  # For context tracking
    
    # We need to run the app and stream output simultaneously
    # The output thread is already running, we just need to hook it up
    exit_code = [None]
    
    def check_process():
        """Check if process is done and update app."""
        ret = process.poll()
        if ret is not None:
            exit_code[0] = ret
            app._is_running = False
            # Give a moment for final output then exit
            app.set_timer(0.5, lambda: app.exit())
        
        # Update context tokens from output buffer
        if app._output_buffer:
            app._context_tokens = app._output_buffer.get_iteration_tokens()
        
        # Feed new output lines to the app
        for line in output_buffer.get_lines()[-50:]:  # Get recent lines
            # Skip if already added (crude dedup by checking last few)
            pass
    
    # Start the app with a process monitor
    original_on_mount = app.on_mount
    
    def patched_on_mount():
        original_on_mount()
        # Set up process monitoring
        app.set_interval(0.1, check_process)
        # Set up output feeding
        def feed_output():
            lines = output_buffer.get_lines()
            log = app.query_one("#output-log")
            # Only add new lines
            current_count = getattr(app, '_fed_lines', 0)
            from rich.text import Text
            for line in lines[current_count:]:
                log.write(Text.from_ansi(line))
            app._fed_lines = len(lines)
        app.set_interval(0.1, feed_output)
    
    app.on_mount = patched_on_mount
    
    try:
        app.run()
    except KeyboardInterrupt:
        process.terminate()
        process.wait()
        raise
    
    # If we exited before process finished, wait for it
    if exit_code[0] is None:
        process.terminate()
        process.wait()
        return process.returncode
    
    return exit_code[0]


def _run_with_simple_ui(process, config: RalphConfig, iteration: int,
                        metrics: Metrics, branch: str, output_buffer: OutputBuffer) -> int:
    """Simple fallback UI without Textual - uses shared FallbackDashboard."""
    dashboard = FallbackDashboard(config, iteration=iteration)
    dashboard.branch = branch
    dashboard.is_running = True
    last_line_count = 0
    
    dashboard.enter()
    
    try:
        while process.poll() is None:
            # Sync output from buffer to dashboard
            all_lines = output_buffer.get_lines()
            for line in all_lines[last_line_count:]:
                dashboard.add_line(line)
            last_line_count = len(all_lines)
            
            # Sync metrics
            dashboard.cost = metrics.total_cost
            dashboard.tokens_in = metrics.total_tokens_in
            dashboard.tokens_out = metrics.total_tokens_out
            dashboard.kills_timeout = metrics.kills_timeout
            dashboard.kills_context = metrics.kills_context
            ctx = output_buffer.get_iteration_tokens()
            if ctx > 0:
                dashboard.context_tokens = ctx  # Only update if we have a value
            dashboard.last_kill_reason = metrics.last_kill_reason
            dashboard.last_kill_activity = metrics.last_kill_activity
            
            # Handle keyboard input
            action = dashboard.get_input()
            if action:
                if action == 'quit':
                    process.terminate()
                    process.wait()
                    return process.returncode
                dashboard.handle_action(action)
            
            dashboard.render()
            time.sleep(0.05)
        
        return process.returncode
        
    except KeyboardInterrupt:
        process.terminate()
        process.wait()
        raise
    finally:
        dashboard.exit()


def stream_output(pipe, output_buffer: OutputBuffer, metrics: Metrics, 
                  print_to_stdout: bool = False, fifo_path: Optional[Path] = None,
                  stop_event: Optional[threading.Event] = None):
    """Read from pipe, update buffer and metrics. Runs in a thread.
    
    Args:
        stop_event: Optional event to signal the thread should stop reading.
    """
    fifo_fd = None
    
    # Use select for non-blocking reads with timeout if stop_event provided
    if stop_event is not None:
        import select as sel
        fd = pipe.fileno()
        while not stop_event.is_set():
            # Wait up to 0.5s for data
            ready, _, _ = sel.select([fd], [], [], 0.5)
            if not ready:
                continue
            line = pipe.readline()
            if not line:  # EOF
                break
            decoded = line.decode('utf-8', errors='replace').rstrip('\n')
            _process_stream_line(decoded, output_buffer, metrics, print_to_stdout, fifo_path)
    else:
        # Original blocking mode
        for line in iter(pipe.readline, b''):
            decoded = line.decode('utf-8', errors='replace').rstrip('\n')
            _process_stream_line(decoded, output_buffer, metrics, print_to_stdout, fifo_path)
    
    if fifo_fd is not None:
        try:
            os.close(fifo_fd)
        except OSError:
            pass


def _process_stream_line(decoded: str, output_buffer: OutputBuffer, metrics: Metrics,
                         print_to_stdout: bool, fifo_path: Optional[Path]):
    """Process a single line from the stream."""
    # Parse cost info (before filtering - metrics lines start with \x00)
    cost_info = parse_cost_line(decoded)
    if cost_info:
        metrics.total_cost = cost_info[0]
        metrics.total_tokens_in = cost_info[1]
        metrics.total_tokens_out = cost_info[2]
        # Track context window size (latest value, not cumulative)
        # The tokens reported are the current context size, not a delta
        output_buffer.set_context_tokens(cost_info[1])
    
    # Track last activity from tool calls (look for tool indicators)
    # Match emoji followed by tool name and description
    activity_match = re.search(r'(?:📖|✏️|⚡|💻|🔍|📁|🤖|🦆|👮|🔧|📝)\s*(?:\x1b\[[0-9;]*m)*(\w+:\s*.{0,60})', decoded)
    if activity_match:
        # Clean ANSI codes from the match
        activity = re.sub(r'\x1b\[[0-9;]*m', '', activity_match.group(1))
        output_buffer.set_last_activity(activity.strip()[:80])
    
    # Filter out hidden metrics lines (prefixed with \x00) from display
    if decoded.startswith('\x00'):
        return
    
    output_buffer.add(decoded)
    
    if print_to_stdout:
        print(decoded)
        sys.stdout.flush()
    
    # Write to FIFO for watchers
    # Use O_RDWR so we don't block/fail when no reader is connected
    if fifo_path is not None:
        fifo_fd = getattr(_process_stream_line, '_fifo_fd', None)
        if fifo_fd is None:
            try:
                fifo_fd = os.open(str(fifo_path), os.O_RDWR | os.O_NONBLOCK)
                _process_stream_line._fifo_fd = fifo_fd
            except OSError:
                pass  # FIFO doesn't exist
        
        if fifo_fd is not None:
            try:
                os.write(fifo_fd, (decoded + '\n').encode('utf-8'))
            except OSError:
                # Broken pipe - close and retry next time
                try:
                    os.close(fifo_fd)
                except OSError:
                    pass
                _process_stream_line._fifo_fd = None


def get_prompt_for_stage(config: RalphConfig, mode: str, stage: str) -> Path:
    """Get the appropriate prompt file based on mode and stage."""
    if mode == 'plan':
        return config.prompt_plan
    
    # Build mode - select based on stage
    if stage == 'VERIFY':
        return config.prompt_verify
    elif stage == 'INVESTIGATE':
        return config.prompt_investigate
    elif stage == 'DECOMPOSE':
        return config.prompt_decompose
    else:
        # BUILD, PLAN, COMPLETE all use build prompt
        return config.prompt_build


def print_plan_report(state: RalphState, mode: str):
    """Print a detailed plan report for developer review."""
    print(f"{Colors.BLUE}━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━{Colors.NC}")
    
    if mode == 'plan':
        print(f"{Colors.CYAN}PLAN REVIEW{Colors.NC} - {state.spec or 'no spec'}")
        print()
    
    # Build task ID to name map for dependency display
    task_names = {t.id: t.name for t in state.tasks}
    done_ids = state.done_ids
    
    # Show pending tasks in topological order with full details
    if state.pending:
        sorted_pending = state.get_sorted_pending()
        print(f"{Colors.YELLOW}PENDING TASKS ({len(sorted_pending)}){Colors.NC}")
        print()
        for i, t in enumerate(sorted_pending, 1):
            # Check if task is blocked
            blocked = t.deps and not all(dep in done_ids for dep in t.deps)
            if blocked:
                print(f"  {Colors.DIM}{i}. {t.name}{Colors.NC} [{t.id}] {Colors.RED}(blocked){Colors.NC}")
            else:
                print(f"  {Colors.WHITE}{i}. {t.name}{Colors.NC} [{t.id}]")
            
            if t.deps:
                dep_strs = []
                for dep in t.deps:
                    dep_name = task_names.get(dep, dep)[:30]
                    if dep in done_ids:
                        dep_strs.append(f"{Colors.GREEN}✓ {dep_name}{Colors.NC}")
                    else:
                        dep_strs.append(f"{Colors.RED}○ {dep_name}{Colors.NC}")
                print(f"     {Colors.CYAN}Deps:{Colors.NC} {', '.join(dep_strs)}")
            
            if t.notes:
                # Wrap notes nicely
                for line in t.notes.split('\n'):
                    print(f"     {Colors.DIM}{line}{Colors.NC}")
            if t.accept:
                print(f"     {Colors.GREEN}Verify:{Colors.NC} {t.accept}")
            print()
    
    # Show done tasks (completed but not yet accepted)
    if state.done:
        print(f"{Colors.GREEN}DONE ({len(state.done)}){Colors.NC} - awaiting verification")
        print()
        for i, t in enumerate(state.done, 1):
            print(f"  {Colors.DIM}{i}. {t.name}{Colors.NC} [{t.id}]")
            if t.accept:
                print(f"     {Colors.GREEN}Verify:{Colors.NC} {t.accept}")
            if t.done_at:
                print(f"     {Colors.DIM}Completed at: {t.done_at}{Colors.NC}")
            print()
    
    # Show issues
    if state.issues:
        print(f"{Colors.RED}ISSUES ({len(state.issues)}){Colors.NC}")
        print()
        for i in state.issues:
            print(f"  - {i.desc} [{i.id}]")
        print()
    
    # Summary
    total = len(state.pending) + len(state.done)
    if total > 0:
        print(f"{Colors.DIM}Total: {len(state.pending)} pending, {len(state.done)} done{Colors.NC}")


def cmd_run(config: RalphConfig, mode: str, max_iterations: int, max_cost: float,
            max_failures: int, completion_promise: str, no_ui: bool = False,
            spec_file: Optional[str] = None, iteration_timeout: int = DEFAULT_ITERATION_TIMEOUT,
            context_limit: int = DEFAULT_CONTEXT_WINDOW):
    """Run the main loop."""
    if not config.ralph_dir.exists():
        print(f"{Colors.RED}Ralph not initialized. Run 'ralph init' first.{Colors.NC}")
        return 1

    # For plan mode, spec_file is required
    if mode == 'plan' and not spec_file:
        print(f"{Colors.RED}Plan mode requires a spec file: ralph plan <spec.md>{Colors.NC}")
        return 1

    # Initialize metrics
    metrics = Metrics(started_at=datetime.now().isoformat())
    config.log_dir.mkdir(parents=True, exist_ok=True)
    
    branch = get_current_branch()
    consecutive_failures = 0
    
    # Detect interactive terminal (can be overridden with --no-ui)
    interactive = sys.stdout.isatty() and not no_ui
    
    # Create FIFO for watch command
    if config.output_fifo.exists():
        if not stat.S_ISFIFO(config.output_fifo.stat().st_mode):
            config.output_fifo.unlink()  # Remove regular file
            os.mkfifo(str(config.output_fifo))
    else:
        os.mkfifo(str(config.output_fifo))

    # Check for project rules upfront
    project_rules = find_project_rules(config.repo_root)
    rules_source = None
    if project_rules:
        for candidate in ['AGENTS.md', 'CLAUDE.md']:
            if (config.repo_root / candidate).exists():
                rules_source = candidate
                break

    # Load plan config to get context thresholds
    plan_state = load_state(config)
    plan_config = plan_state.config
    
    # Calculate context limits, using plan config if available
    if plan_config:
        soft_limit_pct = plan_config.context_warn * 100
        compact_limit_pct = plan_config.context_compact * 100
        hard_limit_pct = plan_config.context_kill * 100
    else:
        soft_limit_pct = CONTEXT_SOFT_LIMIT_PCT
        compact_limit_pct = CONTEXT_COMPACT_LIMIT_PCT
        hard_limit_pct = CONTEXT_HARD_LIMIT_PCT
    
    soft_limit = int(context_limit * soft_limit_pct / 100)
    compact_limit = int(context_limit * compact_limit_pct / 100)
    hard_limit = int(context_limit * hard_limit_pct / 100)

    print(f"{Colors.BLUE}━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━{Colors.NC}")
    print(f"Mode:   {Colors.GREEN}{mode}{Colors.NC}")
    if spec_file:
        print(f"Spec:   {Colors.CYAN}{spec_file}{Colors.NC}")
    print(f"Branch: {branch}")
    if rules_source:
        print(f"Rules:  {Colors.GREEN}{rules_source}{Colors.NC}")
    else:
        print(f"Rules:  {Colors.YELLOW}None{Colors.NC}")
    if max_iterations > 0:
        print(f"Max iterations: {max_iterations}")
    if max_cost > 0:
        print(f"Max cost:       ${max_cost}")
    print(f"Max failures:   {max_failures} (circuit breaker)")
    print(f"Timeout:        {iteration_timeout}s per iteration")
    print(f"Context:        {context_limit:,} tokens (warn: {soft_limit:,}, compact: {compact_limit:,}, kill: {hard_limit:,})")
    if completion_promise:
        print(f"Completion:     \"{completion_promise}\"")
    print(f"{Colors.BLUE}━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━{Colors.NC}")

    iteration = 0
    try:
        while True:
            # Check iteration limit
            if max_iterations > 0 and iteration >= max_iterations:
                print(f"{Colors.BLUE}━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━{Colors.NC}")
                print(f"Reached max iterations: {max_iterations}")
                print(f"{Colors.CYAN}Total cost: ${metrics.total_cost:.4f}{Colors.NC}")
                print(f"{Colors.BLUE}━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━{Colors.NC}")
                break

            # Check cost limit
            if max_cost > 0 and metrics.total_cost >= max_cost:
                print(f"{Colors.YELLOW}━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━{Colors.NC}")
                print(f"{Colors.YELLOW}COST LIMIT REACHED{Colors.NC}")
                print(f"Spent: ${metrics.total_cost:.4f} / ${max_cost}")
                print(f"{Colors.YELLOW}━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━{Colors.NC}")
                break

            # Check circuit breaker
            if consecutive_failures >= max_failures:
                print(f"{Colors.RED}━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━{Colors.NC}")
                print(f"{Colors.RED}CIRCUIT BREAKER TRIPPED{Colors.NC}")
                print(f"{consecutive_failures} consecutive failures detected")
                print(f"{Colors.RED}━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━{Colors.NC}")
                break

            iteration += 1
            metrics.total_iterations += 1
            start_time = time.time()

            if not interactive:
                # Cost display for non-interactive mode
                if max_cost > 0:
                    cost_display = f" | Cost: ${metrics.total_cost:.4f}/${max_cost}"
                else:
                    cost_display = f" | Cost: ${metrics.total_cost:.4f}"

                print()
                print(f"{Colors.GREEN}╔═══════════════════════════════════════════════════════════════╗{Colors.NC}")
                print(f"{Colors.GREEN}║  ITERATION {iteration} - {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}{cost_display}{Colors.NC}")
                print(f"{Colors.GREEN}╚═══════════════════════════════════════════════════════════════╝{Colors.NC}")
                print()

            # Determine prompt based on current stage
            state = load_state(config)
            stage = state.get_stage()
            
            # Check for terminal states in build mode
            if mode != 'plan':
                if stage == 'COMPLETE':
                    print(f"{Colors.GREEN}━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━{Colors.NC}")
                    print(f"{Colors.GREEN}COMPLETE{Colors.NC} - No tasks to execute")
                    if state.spec:
                        print(f"Spec: {state.spec}")
                    print(f"Run 'ralph plan <spec.md>' to add new tasks")
                    print(f"{Colors.GREEN}━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━{Colors.NC}")
                    break
                elif stage == 'PLAN':
                    print(f"{Colors.YELLOW}━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━{Colors.NC}")
                    print(f"{Colors.YELLOW}NO PLAN{Colors.NC} - No spec configured")
                    print(f"Run 'ralph plan <spec.md>' to create a plan first")
                    print(f"{Colors.YELLOW}━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━{Colors.NC}")
                    break
            
            # Ensure plan.jsonl is committed before BUILD stage begins
            # This catches changes made by INVESTIGATE stage (task additions)
            if stage == 'BUILD' and has_uncommitted_plan(config):
                subprocess.run(['git', 'add', str(config.plan_file)], 
                              cwd=config.repo_root, capture_output=True)
                subprocess.run(['git', 'commit', '-m', 'ralph: update plan (from investigate)'],
                              cwd=config.repo_root, capture_output=True)
                print(f"{Colors.GREEN}Committed plan.jsonl before BUILD stage{Colors.NC}")
            
            prompt_file = get_prompt_for_stage(config, mode, stage)
            
            if not prompt_file.exists():
                print(f"{Colors.RED}Prompt file not found: {prompt_file}{Colors.NC}")
                return 1
            
            prompt_content = prompt_file.read_text()
            
            # Substitute spec file placeholder for plan mode
            if spec_file:
                prompt_content = prompt_content.replace('{{SPEC_FILE}}', spec_file)
            
            # Incorporate project rules (already loaded above, reuse for efficiency)
            prompt_content = build_prompt_with_rules(prompt_content, project_rules)
            
            # Get current task info for kill tracking and log naming
            current_task_id = None
            current_task_name = None
            if state.pending:
                current_task_id = state.pending[0].id
                current_task_name = state.pending[0].name
            
            output_buffer = OutputBuffer()

            cmd = ['opencode', 'run', '--model', 'anthropic/claude-opus-4-5', 
                   '--format', 'json', prompt_content]
            
            # Use ephemeral state directory to avoid polluting session list
            opencode_env = os.environ.copy()
            opencode_env['XDG_STATE_HOME'] = '/tmp/ralph-opencode-state'
            # Permission config:
            # - Deny external_directory by default to fail fast instead of hanging on prompts
            # - But allow reading /tmp/ralph-logs/* for DECOMPOSE stage to review failed iteration
            permission_config = {
                "external_directory": "deny",
                "doom_loop": "deny"
            }
            if stage == 'DECOMPOSE':
                # Allow reading ralph logs so decompose can analyze the killed iteration
                # Logs are in build/ralph-logs/ which is within repo and already readable
                permission_config["read"] = {
                    "*": "allow"
                }
                permission_config["external_directory"] = {
                    "*": "deny"
                }
            opencode_env['OPENCODE_PERMISSION'] = json.dumps(permission_config)
            
            # opencode | ralph stream, capture stdout
            # Use DEVNULL for stdin to prevent any prompts from blocking
            opencode_proc = subprocess.Popen(
                cmd,
                stdin=subprocess.DEVNULL,
                stdout=subprocess.PIPE,
                stderr=subprocess.STDOUT,
                cwd=config.repo_root,
                env=opencode_env
            )
            
            ralph_stream_proc = subprocess.Popen(
                [sys.executable, __file__, 'stream'],
                stdin=opencode_proc.stdout,
                stdout=subprocess.PIPE,
                stderr=subprocess.STDOUT,
            )
            
            # Allow opencode to receive SIGPIPE if ralph stream exits
            if opencode_proc.stdout:
                opencode_proc.stdout.close()
            
            # Track if we killed this iteration (shared state for monitor thread)
            kill_state = {"killed": False, "reason": "none", "info": None}
            soft_warned = [False]  # Use list for mutability in closure
            compact_attempted = [False]  # Track if we've attempted compaction at 85%
            reader_stop = threading.Event()
            
            # Start reader thread with stop event for clean shutdown
            reader_thread = threading.Thread(
                target=stream_output,
                args=(ralph_stream_proc.stdout, output_buffer, metrics, not interactive, config.output_fifo, reader_stop)
            )
            reader_thread.daemon = True
            reader_thread.start()
            
            def monitor_limits():
                """Monitor thread that checks timeout and context limits."""
                deadline = time.time() + iteration_timeout
                check_interval = 2.0
                
                while ralph_stream_proc.poll() is None and opencode_proc.poll() is None:
                    if kill_state["killed"]:
                        break
                        
                    elapsed = int(time.time() - start_time)
                    current_tokens = output_buffer.get_iteration_tokens()
                    
                    # Check timeout
                    if time.time() >= deadline:
                        kill_state["killed"] = True
                        kill_state["reason"] = "timeout"
                        kill_state["info"] = IterationKillInfo(
                            reason="timeout",
                            task_name=current_task_name,
                            timeout_seconds=iteration_timeout,
                            elapsed_seconds=elapsed,
                            last_activity=output_buffer.get_last_activity()
                        )
                        # Kill the processes
                        try:
                            opencode_proc.terminate()
                            ralph_stream_proc.terminate()
                        except:
                            pass
                        break
                    
                    # Check context hard limit (95%)
                    if current_tokens >= hard_limit:
                        kill_state["killed"] = True
                        kill_state["reason"] = "context_limit"
                        kill_state["info"] = IterationKillInfo(
                            reason="context_limit",
                            task_name=current_task_name,
                            tokens_used=current_tokens,
                            context_limit=context_limit,
                            elapsed_seconds=elapsed,
                            last_activity=output_buffer.get_last_activity()
                        )
                        # Kill the processes
                        try:
                            opencode_proc.terminate()
                            ralph_stream_proc.terminate()
                        except:
                            pass
                        break
                    
                    # Check compact limit (85%) - attempt compaction, then kill if still high
                    if not interactive and current_tokens >= compact_limit and not compact_attempted[0]:
                        compact_attempted[0] = True
                        pct = current_tokens / context_limit * 100
                        print(f"\n{Colors.YELLOW}[RALPH] Context at {pct:.0f}% - attempting compaction...{Colors.NC}")
                        
                        # Compaction cannot be done mid-execution (stdin is DEVNULL).
                        # Log the attempt and proceed to kill since compaction "fails".
                        print(f"{Colors.RED}[RALPH] Compaction failed (cannot compact mid-execution) - killing iteration{Colors.NC}")
                        
                        kill_state["killed"] = True
                        kill_state["reason"] = "compaction_failed"
                        kill_state["info"] = IterationKillInfo(
                            reason="compaction_failed",
                            task_name=current_task_name,
                            tokens_used=current_tokens,
                            context_limit=context_limit,
                            elapsed_seconds=elapsed,
                            last_activity=output_buffer.get_last_activity()
                        )
                        # Kill the processes
                        try:
                            opencode_proc.terminate()
                            ralph_stream_proc.terminate()
                        except:
                            pass
                        break
                    
                    # Soft warning at 70% (only in non-interactive mode)
                    if not interactive and current_tokens >= soft_limit and not soft_warned[0]:
                        pct = current_tokens / context_limit * 100
                        print(f"\n{Colors.YELLOW}[RALPH] Context pressure: {pct:.0f}% - consider wrapping up ({current_tokens:,}/{context_limit:,} tokens){Colors.NC}")
                        soft_warned[0] = True
                    
                    time.sleep(check_interval)
            
            # Start monitor thread
            monitor_thread = threading.Thread(target=monitor_limits, daemon=True)
            monitor_thread.start()
            
            if interactive:
                exit_code = run_with_live_ui(ralph_stream_proc, config, iteration, 
                                              metrics, branch, output_buffer)
            else:
                # Poll instead of blocking wait, so monitor thread can kill us
                while ralph_stream_proc.poll() is None:
                    if kill_state["killed"]:
                        break
                    time.sleep(0.1)
                exit_code = ralph_stream_proc.returncode if ralph_stream_proc.returncode is not None else -1
            
            # Wait for monitor to finish
            monitor_thread.join(timeout=1.0)
            
            # Check if we were killed by the monitor
            if kill_state["killed"]:
                print(f"\n{Colors.RED}━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━{Colors.NC}")
                if kill_state["reason"] == "timeout":
                    print(f"{Colors.RED}TIMEOUT: Iteration killed after {iteration_timeout}s{Colors.NC}")
                else:
                    pct = kill_state["info"].tokens_used / context_limit * 100
                    print(f"{Colors.RED}CONTEXT LIMIT: Iteration killed at {kill_state['info'].tokens_used:,} tokens ({pct:.0f}%){Colors.NC}")
                print(f"Last activity: {output_buffer.get_last_activity() or 'unknown'}")
                
                print(f"{Colors.RED}━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━{Colors.NC}")
                # Signal reader thread to stop and ensure processes are dead
                reader_stop.set()
                try:
                    ralph_stream_proc.kill()
                    opencode_proc.kill()
                except:
                    pass
                exit_code = -1
            
            # Signal reader to stop (in case of normal exit too)
            reader_stop.set()
            reader_thread.join(timeout=2.0)
            if opencode_proc.poll() is None:
                opencode_proc.wait()

            duration = int(time.time() - start_time)

            # Track success/failure
            # Context/timeout kills are NOT failures - they're expected behavior that triggers retry
            if exit_code == 0:
                consecutive_failures = 0
                metrics.successes += 1
            elif kill_state["killed"]:
                # Killed by monitor (timeout or context limit) - don't count as failure
                # The next iteration will get guidance to break down the problem
                kill_info = kill_state["info"]
                metrics.last_kill_reason = kill_state["reason"]
                metrics.last_kill_activity = kill_info.last_activity or "unknown"
                if kill_state["reason"] == "timeout":
                    metrics.kills_timeout += 1
                elif kill_state["reason"] == "context_limit":
                    metrics.kills_context += 1
            else:
                consecutive_failures += 1
                metrics.failures += 1

            # Log iteration output to build/ralph-logs/
            # Filename format: ralph-<timestamp>-<stage>.log per spec
            config.log_dir.mkdir(parents=True, exist_ok=True)
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            log_file = config.log_dir / f"ralph-{timestamp}-{stage.lower()}.log"
            try:
                with log_file.open('w') as f:
                    f.write(f"# Ralph {mode} iteration {iteration} - {stage}\n")
                    f.write(f"# Date: {datetime.now().isoformat()}\n")
                    f.write(f"# Exit code: {exit_code}\n")
                    f.write(f"# Duration: {duration}s\n")
                    f.write(f"# Spec: {spec_file or 'N/A'}\n")
                    f.write(f"# Stage: {stage}\n")
                    f.write(f"# Task: {current_task_name or 'N/A'}\n")
                    f.write(f"# Repo: {config.repo_root}\n")
                    if kill_state["killed"]:
                        f.write(f"# Kill reason: {kill_state['reason']}\n")
                    f.write("\n")
                    f.write(output_buffer.get_all())
                log_file_written = str(log_file)
            except Exception as e:
                log_file_written = None

            # Mark task for decomposition AFTER writing log so we can reference it
            if kill_state["killed"] and current_task_name and stage == 'BUILD':
                current_state = load_state(config)
                task = current_state.get_next_task()
                if task and task.name == current_task_name:
                    task.needs_decompose = True
                    task.kill_reason = kill_state["reason"]
                    task.kill_log = log_file_written
                    save_state(config, current_state)
                    print(f"{Colors.YELLOW}Task marked for decomposition: {task.id}{Colors.NC}")
                    if log_file_written:
                        print(f"{Colors.YELLOW}Kill log: {log_file_written}{Colors.NC}")
                    print(f"{Colors.YELLOW}Next iteration will break it into smaller tasks{Colors.NC}")

            if not interactive:
                print()
                print(f"{Colors.BLUE}┌───────────────────────────────────────────────────────────────┐{Colors.NC}")
                print(f"{Colors.BLUE}│  Iteration {iteration}: {duration}s (total: ${metrics.total_cost:.4f}){Colors.NC}")
                print(f"{Colors.BLUE}│  Exit: {exit_code} | Failures: {consecutive_failures}/{max_failures}{Colors.NC}")
                print(f"{Colors.BLUE}└───────────────────────────────────────────────────────────────┘{Colors.NC}")

            # Check completion promise
            if completion_promise:
                if completion_promise in output_buffer.get_all():
                    print(f"{Colors.GREEN}━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━{Colors.NC}")
                    print(f"{Colors.GREEN}COMPLETION PROMISE DETECTED{Colors.NC}")
                    print(f"Found: {completion_promise}")
                    print(f"{Colors.GREEN}━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━{Colors.NC}")
                    break

            # Check for spec complete signals - but verify against actual state
            output_text = output_buffer.get_all()
            if '[RALPH] SPEC_COMPLETE' in output_text or '[RALPH] SPEC_VERIFIED' in output_text:
                # Reload state to verify - don't trust AI output alone
                current_state = load_state(config)
                if current_state.issues:
                    # AI said complete but there are issues - continue to INVESTIGATE
                    print(f"{Colors.YELLOW}━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━{Colors.NC}")
                    print(f"{Colors.YELLOW}SPEC_COMPLETE signal ignored - {len(current_state.issues)} issues pending{Colors.NC}")
                    print(f"{Colors.YELLOW}Continuing to INVESTIGATE stage...{Colors.NC}")
                    print(f"{Colors.YELLOW}━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━{Colors.NC}")
                    # Don't break - let loop continue
                elif current_state.pending or current_state.done:
                    # AI said complete but there are still tasks
                    print(f"{Colors.YELLOW}━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━{Colors.NC}")
                    print(f"{Colors.YELLOW}SPEC_COMPLETE signal ignored - tasks still pending/done{Colors.NC}")
                    print(f"{Colors.YELLOW}━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━{Colors.NC}")
                    # Don't break - let loop continue
                else:
                    # Actually complete
                    spec_match = re.search(r'\[RALPH\] SPEC_(?:COMPLETE|VERIFIED):?\s*(\S+)?', output_text)
                    spec_name = spec_match.group(1) if spec_match and spec_match.group(1) else spec_file or 'unknown'
                    print(f"{Colors.GREEN}━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━{Colors.NC}")
                    print(f"{Colors.GREEN}SPEC COMPLETE: {spec_name}{Colors.NC}")
                    print(f"Total cost: ${metrics.total_cost:.4f}")
                    print(f"Iterations: {metrics.total_iterations}")
                    print(f"{Colors.GREEN}━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━{Colors.NC}")
                    break
            
            # Check for plan complete signal - commit the plan
            if '[RALPH] PLAN_COMPLETE' in output_text and mode == 'plan':
                # Auto-prioritize tasks before committing
                # cmd_task outputs JSON, so we capture stdout to show a cleaner message
                f = io.StringIO()
                with redirect_stdout(f):
                    prioritize_result = cmd_task(config, 'prioritize')
                prioritize_output = f.getvalue().strip()
                if prioritize_result is None or prioritize_result == 0:
                    try:
                        pdata = json.loads(prioritize_output)
                        print(f"{Colors.GREEN}Auto-prioritized {pdata.get('prioritized', 0)} tasks (high: {pdata.get('high', 0)}, medium: {pdata.get('medium', 0)}, low: {pdata.get('low', 0)}){Colors.NC}")
                    except json.JSONDecodeError:
                        print(f"{Colors.GREEN}Auto-prioritized tasks{Colors.NC}")
                
                # Commit the plan.jsonl with all added tasks
                if has_uncommitted_plan(config):
                    task_count_match = re.search(r'\[RALPH\] PLAN_COMPLETE: Added (\d+) tasks', output_text)
                    task_count = task_count_match.group(1) if task_count_match else "?"
                    subprocess.run(['git', 'add', str(config.plan_file)], 
                                  cwd=config.repo_root, capture_output=True)
                    subprocess.run(['git', 'commit', '-m', f'ralph: plan {spec_file} ({task_count} tasks)'],
                                  cwd=config.repo_root, capture_output=True)
                    print(f"{Colors.GREEN}Committed plan with {task_count} tasks{Colors.NC}")
                break

            # Check for spec incomplete signal (VALIDATE created new tasks)
            if '[RALPH] SPEC_INCOMPLETE' in output_text:
                # Auto-prioritize new tasks before next iteration
                f = io.StringIO()
                with redirect_stdout(f):
                    prioritize_result = cmd_task(config, 'prioritize')
                prioritize_output = f.getvalue().strip()
                if prioritize_result is None or prioritize_result == 0:
                    try:
                        pdata = json.loads(prioritize_output)
                        print(f"{Colors.GREEN}Auto-prioritized {pdata.get('prioritized', 0)} tasks (high: {pdata.get('high', 0)}, medium: {pdata.get('medium', 0)}, low: {pdata.get('low', 0)}){Colors.NC}")
                    except json.JSONDecodeError:
                        print(f"{Colors.GREEN}Auto-prioritized tasks{Colors.NC}")

            # Push changes
            try:
                subprocess.run(['git', 'push', 'origin', branch], 
                             capture_output=True, cwd=config.repo_root)
            except Exception:
                try:
                    subprocess.run(['git', 'push', '-u', 'origin', branch],
                                 capture_output=True, cwd=config.repo_root)
                except Exception:
                    pass

            if not interactive:
                # Show recent commits
                print()
                print("Recent commits:")
                try:
                    result = subprocess.run(
                        ['git', '--no-pager', 'log', '--oneline', '-3'],
                        capture_output=True, text=True, cwd=config.repo_root
                    )
                    print(result.stdout)
                except Exception:
                    pass

    except KeyboardInterrupt:
        print(f"\n{Colors.YELLOW}Interrupted by user{Colors.NC}")
    finally:
        # Summary with success/failure status
        if metrics.failures == 0 and metrics.successes > 0:
            status = f"{Colors.GREEN}SUCCESS{Colors.NC}"
        elif metrics.failures > 0 and metrics.successes == 0:
            status = f"{Colors.RED}FAILED{Colors.NC}"
        elif metrics.failures > 0:
            status = f"{Colors.YELLOW}PARTIAL{Colors.NC} ({metrics.successes} ok, {metrics.failures} failed)"
        else:
            status = f"{Colors.YELLOW}NO RUNS{Colors.NC}"
        
        print(f"{Colors.BLUE}━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━{Colors.NC}")
        print(f"{status} | ${metrics.total_cost:.4f} | {metrics.total_iterations} iterations")
        
        # Show current plan state
        final_state = load_state(config)
        if final_state.tasks or final_state.issues:
            print_plan_report(final_state, mode)
        print(f"{Colors.BLUE}━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━{Colors.NC}")


# =============================================================================
# State CLI Commands
# =============================================================================

def cmd_query(config: RalphConfig, subquery: Optional[str] = None):
    """Query current state."""
    state = load_state(config)
    
    if subquery == 'stage':
        print(state.get_stage())
    elif subquery == 'next':
        print(json.dumps(state.get_next(), indent=2))
    elif subquery == 'tasks':
        print(json.dumps({
            "pending": [task_to_query_dict(t) for t in state.pending],
            "done": [task_to_query_dict(t) for t in state.done],
        }, indent=2))
    elif subquery == 'issues':
        print(json.dumps([{"id": i.id, "desc": i.desc} for i in state.issues], indent=2))
    else:
        # Full state with computed fields
        output = state.to_dict()
        output["stage"] = state.get_stage()
        output["next"] = state.get_next()
        print(json.dumps(output, indent=2))


def cmd_task(config: RalphConfig, action: str, desc: Optional[str] = None):
    """Task mutations: done, add, accept."""
    state = load_state(config)
    
    if action == 'done':
        pending = state.pending
        if not pending:
            print(f"{Colors.YELLOW}No pending tasks{Colors.NC}")
            return 1
        # Find the first pending task and mark it done
        task = pending[0]
        task.status = "d"
        task.done_at = get_current_commit(config)  # Record current HEAD before committing
        
        # Stage all tracked file changes (code changes made by AI)
        subprocess.run(['git', 'add', '-u'], cwd=config.repo_root, capture_output=True)
        
        # Save plan state and stage it
        save_state(config, state)
        subprocess.run(['git', 'add', str(config.plan_file)], cwd=config.repo_root, capture_output=True)
        
        # Commit all staged changes (code + plan) together
        commit_msg = f"ralph: task done - {task.name[:50]}"
        subprocess.run(['git', 'commit', '-m', commit_msg], cwd=config.repo_root, capture_output=True)
        
        print(f"{Colors.GREEN}Task done:{Colors.NC} {task.name}")
        print(json.dumps(state.to_dict(), indent=2))
        
    elif action == 'add':
        if not desc:
            print(f"{Colors.RED}Usage: ralph task add \"name\" or ralph task add '{{\"name\": ..., \"notes\": ..., \"accept\": ...}}'{Colors.NC}")
            return 1
        if not state.spec:
            print(f"{Colors.RED}No spec set. Run 'ralph set-spec <file>' first.{Colors.NC}")
            return 1
        
        # Try parsing as JSON for structured task, otherwise treat as simple name
        try:
            if desc.startswith('{'):
                d = json.loads(desc)
                name = d.get("name", "")
                notes = d.get("notes")
                accept = d.get("accept")
                deps = d.get("deps")  # List of task IDs
            else:
                name = desc
                notes = None
                accept = None
                deps = None
        except json.JSONDecodeError:
            name = desc
            notes = None
            accept = None
            deps = None
        
        if not name:
            print(f"{Colors.RED}Task name is required{Colors.NC}")
            return 1
            
        task = Task(id=_generate_id('t'), name=name, spec=state.spec, notes=notes, accept=accept, deps=deps, status="p")
        state.tasks.append(task)
        save_state(config, state)  # No auto-commit, let caller batch
        print(f"{Colors.GREEN}Task added:{Colors.NC} {task.id} - {name}")
        if deps:
            print(f"  {Colors.DIM}Depends on: {', '.join(deps)}{Colors.NC}")
        
    elif action == 'accept':
        done = state.done
        if not done:
            print(f"{Colors.YELLOW}No done tasks to accept{Colors.NC}")
            return 1
        count = len(done)
        # Remove all done tasks from state.tasks
        done_ids = {t.id for t in done}
        state.tasks = [t for t in state.tasks if t.id not in done_ids]
        save_state(config, state)  # No auto-commit, let caller batch
        print(f"{Colors.GREEN}Accepted {count} tasks{Colors.NC}")
        
    elif action == 'reject':
        if not desc:
            print(f"{Colors.RED}Usage: ralph task reject \"reason\"{Colors.NC}")
            return 1
        done = state.done
        if not done:
            print(f"{Colors.YELLOW}No done tasks to reject{Colors.NC}")
            return 1
        task = done[0]
        tombstone = Tombstone(id=task.id, done_at=task.done_at or "unknown", reason=desc)
        state.tombstones.append(tombstone)
        task.status = "p"
        task.done_at = None
        save_state(config, state, f"ralph: task reject - {task.name[:50]}")
        print(f"{Colors.YELLOW}Task rejected:{Colors.NC} {task.name}")
        print(f"  {Colors.DIM}Reason: {desc}{Colors.NC}")
        print(json.dumps(state.to_dict(), indent=2))
    
    elif action == 'delete':
        if not desc:
            print(f"{Colors.RED}Usage: ralph task delete <task-id>{Colors.NC}")
            return 1
        task_id = desc
        task = next((t for t in state.tasks if t.id == task_id), None)
        if not task:
            print(f"{Colors.RED}Task not found: {task_id}{Colors.NC}")
            return 1
        task_name = task.name
        state.tasks = [t for t in state.tasks if t.id != task_id]
        save_state(config, state)
        print(f"{Colors.GREEN}Task deleted:{Colors.NC} {task_id} - {task_name}")
    
    elif action == 'prioritize':
        pending = state.pending
        if not pending:
            print(json.dumps({"prioritized": 0, "high": 0, "medium": 0, "low": 0}))
            return 0
        
        blocking_count = {}
        for task in pending:
            blocking_count[task.id] = 0
        for task in pending:
            if task.deps:
                for dep_id in task.deps:
                    if dep_id in blocking_count:
                        blocking_count[dep_id] += 1
        
        def estimate_complexity(task: Task) -> str:
            text = (task.name + " " + (task.notes or "")).lower()
            large_indicators = ["refactor", "redesign", "rewrite", "implement", "overhaul", "migrate", "architecture"]
            small_indicators = ["rename", "fix typo", "update", "add flag", "add field", "change", "alias", "tweak"]
            for ind in large_indicators:
                if ind in text:
                    return "large"
            for ind in small_indicators:
                if ind in text:
                    return "small"
            return "medium"
        
        def is_docs_cleanup(task: Task) -> bool:
            text = (task.name + " " + (task.notes or "")).lower()
            indicators = ["doc", "readme", "comment", "cleanup", "clean up", "lint", "format", "typo"]
            for ind in indicators:
                if ind in text:
                    return True
            return False
        
        counts = {"high": 0, "medium": 0, "low": 0}
        prioritized = 0
        
        for task in pending:
            if task.priority:
                counts[task.priority] += 1
                continue
            
            complexity = estimate_complexity(task)
            blocks = blocking_count[task.id]
            
            if is_docs_cleanup(task):
                task.priority = "low"
            elif complexity == "small" and blocks >= 2:
                task.priority = "high"
            elif blocks >= 3:
                task.priority = "high"
            elif complexity == "small" and blocks >= 1:
                task.priority = "high"
            elif complexity == "large":
                task.priority = "medium"
            else:
                task.priority = "medium"
            
            counts[task.priority] += 1
            prioritized += 1
        
        save_state(config, state)
        print(json.dumps({"prioritized": prioritized, "high": counts["high"], "medium": counts["medium"], "low": counts["low"]}))
        
    else:
        print(f"{Colors.RED}Unknown task action: {action}{Colors.NC}")
        print("Usage: ralph task [done|add|accept|reject|delete|prioritize]")
        return 1


def cmd_issue(config: RalphConfig, action: str, desc: Optional[str] = None):
    """Issue mutations: done, add."""
    state = load_state(config)
    
    if action == 'done':
        if not state.issues:
            print(f"{Colors.YELLOW}No issues{Colors.NC}")
            return 1
        issue = state.issues.pop(0)
        save_state(config, state)  # No auto-commit, issues are transient
        print(f"{Colors.GREEN}Issue resolved:{Colors.NC} {issue.desc}")
    
    elif action == 'done-all':
        if not state.issues:
            print(f"{Colors.YELLOW}No issues{Colors.NC}")
            return 1
        count = len(state.issues)
        state.issues = []
        save_state(config, state)
        print(f"{Colors.GREEN}All issues resolved:{Colors.NC} {count} issues cleared")
    
    elif action == 'done-ids':
        # Batch resolve specific issues by ID: ralph issue done-ids i-abc1 i-def2 i-ghi3
        if not desc:
            print(f"{Colors.RED}Usage: ralph issue done-ids <id1> <id2> ...{Colors.NC}")
            return 1
        ids_to_remove = set(desc.split())
        if not state.issues:
            print(f"{Colors.YELLOW}No issues{Colors.NC}")
            return 1
        original_count = len(state.issues)
        state.issues = [i for i in state.issues if i.id not in ids_to_remove]
        removed_count = original_count - len(state.issues)
        if removed_count > 0:
            save_state(config, state)
            print(f"{Colors.GREEN}Issues resolved:{Colors.NC} {removed_count} issues cleared")
        else:
            print(f"{Colors.YELLOW}No matching issue IDs found{Colors.NC}")
            return 1
        
    elif action == 'add':
        if not desc:
            print(f"{Colors.RED}Usage: ralph issue add \"description\"{Colors.NC}")
            return 1
        if not state.spec:
            print(f"{Colors.RED}No spec set. Run 'ralph set-spec <file>' first.{Colors.NC}")
            return 1
        issue = Issue(id=_generate_id('i'), desc=desc, spec=state.spec)
        state.issues.append(issue)
        save_state(config, state)  # No auto-commit, issues are transient
        print(f"{Colors.GREEN}Issue added:{Colors.NC} {issue.id} - {desc}")
        
    else:
        print(f"{Colors.RED}Unknown issue action: {action}{Colors.NC}")
        print("Usage: ralph issue [done|done-all|done-ids|add]")
        return 1


def cmd_set_spec(config: RalphConfig, spec_file: str):
    """Set current spec."""
    # Validate spec exists - handle full path, relative path, or just filename
    spec_path = Path(spec_file)
    if spec_path.is_absolute() or spec_path.exists():
        # Full or relative path provided
        if not spec_path.exists():
            print(f"{Colors.RED}Spec not found: {spec_file}{Colors.NC}")
            return 1
    else:
        # Just filename - look in specs_dir
        spec_path = config.specs_dir / spec_file
        if not spec_path.exists():
            if not spec_file.endswith('.md'):
                spec_path = config.specs_dir / f"{spec_file}.md"
            if not spec_path.exists():
                print(f"{Colors.RED}Spec not found: {spec_file}{Colors.NC}")
                return 1
    
    state = load_state(config)
    state.spec = spec_path.name
    # Clear tasks when switching specs
    state.tasks = []
    # Clear tombstones - they served their audit purpose for the previous spec
    state.tombstones = []
    # Keep issues - they may be relevant across specs
    save_state(config, state, f"ralph: set spec {spec_path.name}")
    print(f"{Colors.GREEN}Spec set:{Colors.NC} {spec_path.name}")


def cmd_log(config: RalphConfig, show_all: bool = False, spec_filter: Optional[str] = None, 
            branch_filter: Optional[str] = None, since: Optional[str] = None):
    """Query git history for task lifecycle data."""
    cmd = ['git', 'log', '--format=%H|%aI|%an <%ae>|%s', '--reverse', '--follow', '--', 'ralph/plan.jsonl']
    
    if since:
        cmd.insert(2, f'--since={since}')
    if branch_filter:
        cmd.insert(2, branch_filter)
    
    result = subprocess.run(cmd, capture_output=True, text=True, cwd=config.repo_root)
    
    if result.returncode != 0 or not result.stdout.strip():
        print(json.dumps({"tasks": []}, indent=2))
        return
    
    tasks: Dict[str, dict] = {}
    tombstones: Dict[str, dict] = {}  # task_id -> {commit, date, reason}
    prev_task_ids: set = set()
    
    for line in result.stdout.strip().split('\n'):
        if not line or '|' not in line:
            continue
        parts = line.split('|', 3)
        if len(parts) != 4:
            continue
        
        full_commit = parts[0]
        commit = full_commit[:7]
        date = parts[1].strip()
        author = parts[2].strip()
        
        plan_result = subprocess.run(
            ['git', 'show', f'{full_commit}:ralph/plan.jsonl'],
            capture_output=True, text=True, cwd=config.repo_root
        )
        
        if plan_result.returncode != 0:
            continue
        
        current_tasks: Dict[str, dict] = {}
        for plan_line in plan_result.stdout.strip().split('\n'):
            if not plan_line:
                continue
            try:
                entry = json.loads(plan_line)
                if entry.get('t') == 'task':
                    task_id = entry.get('id')
                    if task_id:
                        current_tasks[task_id] = entry
                elif entry.get('t') == 'reject':
                    task_id = entry.get('id')
                    if task_id and task_id not in tombstones:
                        tombstones[task_id] = {
                            "commit": commit,
                            "date": date,
                            "reason": entry.get("reason", "")
                        }
            except json.JSONDecodeError:
                continue
        
        current_task_ids = set(current_tasks.keys())
        
        for task_id, task_data in current_tasks.items():
            if task_id not in tasks:
                branch_result = subprocess.run(
                    ['git', 'branch', '--contains', full_commit, '--format=%(refname:short)'],
                    capture_output=True, text=True, cwd=config.repo_root
                )
                branch = branch_result.stdout.strip().split('\n')[0] if branch_result.returncode == 0 else None
                
                tasks[task_id] = {
                    "id": task_id,
                    "desc": task_data.get("name", ""),
                    "notes": task_data.get("notes"),
                    "accept": task_data.get("accept"),
                    "deps": task_data.get("deps"),
                    "spec": task_data.get("spec"),
                    "branch": branch,
                    "author": author,
                    "created": {"commit": commit, "date": date},
                    "done": None,
                    "accepted": None,
                    "rejected": None
                }
            
            if task_data.get("s") == "d" and task_data.get("done_at"):
                if tasks[task_id]["done"] is None:
                    tasks[task_id]["done"] = {"commit": task_data["done_at"][:7], "date": date}
        
        removed_ids = prev_task_ids - current_task_ids
        for task_id in removed_ids:
            if task_id in tasks and tasks[task_id]["accepted"] is None:
                tasks[task_id]["accepted"] = {"commit": commit, "date": date}
        
        prev_task_ids = current_task_ids
    
    for task_id, tombstone_data in tombstones.items():
        if task_id in tasks:
            tasks[task_id]["rejected"] = tombstone_data
    
    task_list = list(tasks.values())
    
    if spec_filter:
        task_list = [t for t in task_list if t.get("spec") == spec_filter]
    
    if not show_all:
        current_state = load_state(config)
        current_ids = {t.id for t in current_state.tasks}
        task_list = [t for t in task_list if t["id"] in current_ids]
    
    print(json.dumps({"tasks": task_list}, indent=2))


def main():
    parser = argparse.ArgumentParser(
        description='Ralph Wiggum - Autonomous AI Development Loop',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog='''
Examples:
  ralph init                    Initialize in current repo
  ralph plan spec.md            Plan tasks for a specific spec
  ralph construct               Construct mode, unlimited (Ctrl+C to stop)
  ralph construct 10            Construct mode, max 10 iterations
  ralph query                   Show current state as JSON
  ralph query stage             Show current stage (PLAN/BUILD/VERIFY/etc)
  ralph task done               Mark first pending task as done
  ralph task add "description"  Add a new task
  ralph task accept             Accept all done tasks (after verification)
  ralph issue add "description" Add a discovered issue
  ralph issue done              Resolve first issue
  ralph set-spec spec.md        Set current spec
  ralph log                     Show state change history
  ralph watch                   Live progress dashboard
  ralph stream                  Pipe opencode JSON for pretty output
        '''
    )
    
    parser.add_argument('command', nargs='?', default='construct',
                       help='Command: init, plan, construct, query, task, issue, set-spec, log, status, watch, stream (build is alias for construct)')
    parser.add_argument('arg', nargs='?', default=None,
                       help='Subcommand or argument')
    parser.add_argument('arg2', nargs='?', default=None,
                       help='Additional argument (e.g., task description)')
    parser.add_argument('--max-cost', type=float, default=0,
                       help='Stop when cost exceeds $N')
    parser.add_argument('--max-failures', type=int, default=3,
                       help='Circuit breaker: stop after N consecutive failures')
    parser.add_argument('--completion-promise', type=str, default='',
                       help='Stop when output contains this text')
    parser.add_argument('--timeout', type=int, default=DEFAULT_ITERATION_TIMEOUT,
                       help=f'Kill iteration after N seconds (default: {DEFAULT_ITERATION_TIMEOUT}s)')
    parser.add_argument('--context-limit', type=int, default=DEFAULT_CONTEXT_WINDOW,
                       help=f'Context window size in tokens (default: {DEFAULT_CONTEXT_WINDOW})')
    parser.add_argument('--no-ui', action='store_true',
                       help='Disable interactive dashboard, show streaming output')
    parser.add_argument('--all', action='store_true',
                       help='For log: show all history')
    parser.add_argument('--spec', type=str, default=None,
                       help='For log: filter by spec')
    parser.add_argument('--branch', type=str, default=None,
                       help='For log: filter by branch')
    parser.add_argument('--since', type=str, default=None,
                        help='For log: filter since date/commit')
    parser.add_argument('--max-iterations', type=int, default=None,
                        help='For construct: max iterations (0 = unlimited)')

    args = parser.parse_args()

    # Handle numeric first arg (e.g., "ralph 10")
    if args.command and args.command.isdigit():
        args.arg = args.command
        args.command = 'construct'

    # Parse iterations: --max-iterations flag takes precedence, then positional arg
    iterations = 0
    if args.max_iterations is not None:
        iterations = args.max_iterations
    elif args.arg and args.arg.isdigit():
        iterations = int(args.arg)

    # Stream command doesn't need a repo
    if args.command == 'stream':
        cmd_stream()
        return

    # Find repo
    repo_root = find_repo_root()
    if not repo_root:
        print(f"{Colors.RED}Error: Not in a git repository{Colors.NC}")
        sys.exit(1)

    config = RalphConfig.from_repo(repo_root)

    # Dispatch command
    if args.command == 'init':
        cmd_init(config)
    elif args.command == 'status':
        cmd_status(config)
    elif args.command == 'watch':
        cmd_watch(config)
    elif args.command == 'query':
        cmd_query(config, args.arg)
    elif args.command == 'task':
        if not args.arg:
            print(f"{Colors.RED}Usage: ralph task [done|add|accept]{Colors.NC}")
            sys.exit(1)
        cmd_task(config, args.arg, args.arg2)
    elif args.command == 'issue':
        if not args.arg:
            print(f"{Colors.RED}Usage: ralph issue [done|add]{Colors.NC}")
            sys.exit(1)
        cmd_issue(config, args.arg, args.arg2)
    elif args.command == 'set-spec':
        if not args.arg:
            print(f"{Colors.RED}Usage: ralph set-spec <spec.md>{Colors.NC}")
            sys.exit(1)
        cmd_set_spec(config, args.arg)
    elif args.command == 'log':
        cmd_log(config, show_all=args.all, spec_filter=args.spec, 
                branch_filter=args.branch, since=args.since)
    elif args.command == 'plan':
        # Plan requires a spec file
        spec_file = args.arg
        if not spec_file:
            # List available specs
            specs = list(config.specs_dir.glob('*.md')) if config.specs_dir.exists() else []
            if not specs:
                print(f"{Colors.RED}No specs found in ralph/specs/{Colors.NC}")
                print("Create a spec file first, e.g.: ralph/specs/my-feature.md")
                sys.exit(1)
            print(f"{Colors.YELLOW}Usage: ralph plan <spec.md>{Colors.NC}")
            print()
            print("Available specs:")
            for spec in sorted(specs):
                print(f"  {spec.name}")
            sys.exit(1)
        
        # Validate spec exists - handle full path, relative path, or just filename
        spec_path = Path(spec_file)
        if spec_path.is_absolute() or spec_path.exists():
            # Full or relative path provided
            if not spec_path.exists():
                print(f"{Colors.RED}Spec not found: {spec_file}{Colors.NC}")
                sys.exit(1)
        else:
            # Just filename - look in specs_dir
            spec_path = config.specs_dir / spec_file
            if not spec_path.exists():
                # Try without .md extension
                if not spec_file.endswith('.md'):
                    spec_path = config.specs_dir / f"{spec_file}.md"
                if not spec_path.exists():
                    print(f"{Colors.RED}Spec not found: {spec_file}{Colors.NC}")
                    print(f"Expected at: {config.specs_dir / spec_file}")
                    sys.exit(1)
        
        # Check for unfinished tasks before switching specs
        if not check_unfinished_tasks(config, spec_path.name):
            sys.exit(0)
        
        # Set the spec in state before running plan
        cmd_set_spec(config, spec_path.name)
        
        cmd_run(config, 'plan', 1, args.max_cost, args.max_failures, 
                args.completion_promise, args.no_ui, spec_file=spec_path.name,
                iteration_timeout=args.timeout, context_limit=args.context_limit)
    elif args.command in ('construct', 'build', ''):
        # Note: 'build' is supported as an alias for backward compatibility
        
        # Check if a spec file was provided as argument
        spec_arg = args.arg
        if spec_arg and not spec_arg.isdigit():
            # Looks like a spec file argument - validate and switch to it
            spec_path = Path(spec_arg)
            if spec_path.is_absolute() or spec_path.exists():
                if not spec_path.exists():
                    print(f"{Colors.RED}Spec not found: {spec_arg}{Colors.NC}")
                    sys.exit(1)
            else:
                spec_path = config.specs_dir / spec_arg
                if not spec_path.exists():
                    if not spec_arg.endswith('.md'):
                        spec_path = config.specs_dir / f"{spec_arg}.md"
                    if not spec_path.exists():
                        print(f"{Colors.RED}Spec not found: {spec_arg}{Colors.NC}")
                        print(f"Expected at: {config.specs_dir / spec_arg}")
                        sys.exit(1)
            
            # Check for unfinished tasks before switching specs
            if not check_unfinished_tasks(config, spec_path.name):
                sys.exit(0)
            
            # Load current state to check if this spec has tasks
            state = load_state(config)
            
            # Check if we're switching specs or using current spec
            if state.spec != spec_path.name:
                # Switching to a different spec - set it (this clears tasks)
                cmd_set_spec(config, spec_path.name)
                state = load_state(config)  # Reload after set
            
            # Check if there are any tasks for this spec
            if not state.tasks:
                print(f"{Colors.YELLOW}No tasks found for spec: {spec_path.name}{Colors.NC}")
                print()
                print("To generate tasks, run:")
                print(f"  {Colors.CYAN}ralph plan {spec_path.name}{Colors.NC}")
                sys.exit(1)
        
        # Ensure plan.jsonl is committed before starting construct mode
        if has_uncommitted_plan(config):
            print(f"{Colors.YELLOW}plan.jsonl has uncommitted changes.{Colors.NC}")
            try:
                response = input(f"Commit now? [Y/n] ").strip().lower()
                if response in ('', 'y', 'yes'):
                    subprocess.run(['git', 'add', str(config.plan_file)], 
                                  cwd=config.repo_root, check=True)
                    subprocess.run(['git', 'commit', '-m', 'ralph: update plan'],
                                  cwd=config.repo_root, check=True)
                    print(f"{Colors.GREEN}Committed.{Colors.NC}")
                else:
                    print(f"{Colors.RED}Aborted.{Colors.NC}")
                    sys.exit(1)
            except KeyboardInterrupt:
                print(f"\n{Colors.RED}Aborted.{Colors.NC}")
                sys.exit(1)
        
        cmd_run(config, 'build', iterations, args.max_cost, args.max_failures, 
                args.completion_promise, args.no_ui,
                iteration_timeout=args.timeout, context_limit=args.context_limit)
    elif args.command == 'help':
        parser.print_help()
    else:
        print(f"{Colors.RED}Unknown command: {args.command}{Colors.NC}")
        parser.print_help()
        sys.exit(1)


if __name__ == '__main__':
    main()
