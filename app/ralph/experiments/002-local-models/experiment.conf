# 002-local-models: How far can local-only models go on a complex C spec?
#
# Zero cloud dependency. Zero quota burn. Pure local GPU inference.
# Backend: LM Studio (auto-loads models on demand, no manual swapping)
#
# Target: Valkyria system-architecture-refactor (same as 001)
# Machine: redbox (Ryzen 9 9900X, 64GB RAM, RTX 5090 32GB VRAM)
#
# Models under test (all served via LM Studio on port 1234):
#   devstral        - Devstral Small 2 (24B dense, tool-use trained)
#   qwen3-coder     - Qwen3-Coder-Flash (30B MoE/3B active, agentic coding)
#   glm-flash       - GLM-4.7-Flash (~16B, fast general purpose)
#   gpt-oss         - GPT-OSS 20B (reasoning mode)
#   local-hybrid    - Qwen3-Coder reasoning + Devstral BUILD
#   local-hybrid-inv - Devstral reasoning + Qwen3-Coder BUILD

# ─────────────────────────────────────────────────────────────────────
# TARGET PROJECT
# ─────────────────────────────────────────────────────────────────────

TARGET_REPO="$HOME/src/valkyria"
BASE_REF="networking"
SPEC="system-architecture-refactor.md"

# ─────────────────────────────────────────────────────────────────────
# PROFILES TO TEST
# ─────────────────────────────────────────────────────────────────────

PROFILES="devstral qwen3-coder glm-flash gpt-oss local-hybrid local-hybrid-inv"

# ─────────────────────────────────────────────────────────────────────
# EXPERIMENT PARAMETERS
# ─────────────────────────────────────────────────────────────────────

# More iterations for local models -- they're free
MAX_ITERATIONS=40
MAX_WALL_TIME=10800
MAX_FAILURES=5

# ─────────────────────────────────────────────────────────────────────
# CORRECTNESS CHECKS (valkyria-specific)
# ─────────────────────────────────────────────────────────────────────

BUILD_CMD="make build"
TEST_CMD="make test"
TEST_TIMEOUT=300

GATE_CHECKS="Phase0-OldSymbols|grep -rcE 'heap2_|tlab2_|page2_|stats2_|mark_ctx2_|valk_gc_malloc_' src/ test/ && exit 1 || exit 0"
